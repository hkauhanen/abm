[
  {
    "objectID": "bric-a-brac.html",
    "href": "bric-a-brac.html",
    "title": "Bric-a-brac",
    "section": "",
    "text": "A compendium of sundry miscellanea.\n\nplot_birds_fixed.jl – A Julia Plots recipe, used to plot birds in the homework Making birds fly\nVariationalLearning.jl – A Julia module that defines the VariationalLearner type and some functions to deal with such learners. See, in particular, this homework solution. To use this, execute the following (don’t forget the dot before the module name, as this is a local module):\n\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning\n\nGridVL.jl – A Julia module that implements a VariationalLearner on a grid space in Agents.jl. To use:\n\ninclude(\"GridVL.jl\")\nusing .GridVL\n\nIf Julia complains about an “invalid redefinition of type VariationalLearner”, this is because you have the older (non-spatial) type in memory. Exit your Julia session (or VSCode) and try again. Once the module has been successfully loaded, you can run the commands in the lecture on structured populations.\nVL.jl – Updated version of our variational learning module. Defines VariationalLearner as an abstract type, plus two non-abstract daughter types, SimpleVL (corresponding to our old variational learning code) and GridVL (a variational learner on a 2D grid). Load like this:\n\ninclude(\"VL.jl\")\nusing .VL\n\nIf VSCode gives you module-related troubles, delete the first and last lines of the file VL.jl and load it using just:\n\ninclude(\"VL.jl\")\n\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Note\n\n\n\nThe syllabus is tentative – topics may get rearranged as the course proceeds.\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "syllabus.html#timetable",
    "href": "syllabus.html#timetable",
    "title": "Syllabus",
    "section": "Timetable",
    "text": "Timetable\n\n\n\nDate\nTopic\nHomework\nReading\n\n\n\n\n9.4.\nWelcome + Intro to ABMs\nInstalling Julia\nGilbert (2020), chapter 1\n\n\n16.4.\nProgramming basics\nMaking birds fly\nGilbert (2020), chapter 2\n\n\n23.4.\nA model of language learning\nVariational learning\nYang (2000), pages 231–236\n\n\n30.4.\nSpeaking and listening\nModules and packages\nIntroducing Julia/Modules and packages\n\n\n7.5.\nModels of language change\nLanguage change: parameter exploration\nNone\n\n\n14.5.\nStructured populations\nThinking about your project\nOne paper of your choice from readings/projects on ILIAS\n\n\n21.5.\nProgramming best practices\n(keep thinking about your project)\nSmaldino (2023), chapter 10\n\n\n28.5.\nNo lecture (Vorlesungsfreie Zeit)\n\n\n\n\n4.6.\nNo lecture (Vertiefungswoche)\n\n\n\n\n11.6.\nExemplar dynamics\n\n\n\n\n18.6.\nConformity\n\n\n\n\n25.6.\nRoaming in space\n\n\n\n\n2.7.\nPresentations 1\n\n\n\n\n9.7.\nPresentations 2\n\n\n\n\n16.7.\nExam\n\n\n\n\n25.8.\nDeadline for project written reports"
  },
  {
    "objectID": "syllabus.html#course-requirements",
    "href": "syllabus.html#course-requirements",
    "title": "Syllabus",
    "section": "Course requirements",
    "text": "Course requirements\nTo pass this course, you will need to satisfactorily complete both:\n\nThe final exam\nSmall programming project + in-class presentation + written report, either solo or in small group (depending on your preference)\n\nThe examination will be based on the following materials:\n\nLectures and associated lecture notes (on this website)\nHomework contents (on this website)\nReadings (on ILIAS)\n\nProgramming project topics need to be decided before the Vorlesungsfreie Zeit. However, I encourage you to start thinking about potential topics as soon as possible, and, if you want to work in a group, also to form your group as early as possible."
  },
  {
    "objectID": "solutions/change.html",
    "href": "solutions/change.html",
    "title": "Language change: parameter exploration",
    "section": "",
    "text": "First, we load the module we have already written:\n\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning\n\n\n\n\n\n\n\nNote\n\n\n\nIf VSCode complains about the module, remove the line module VariationalLearning and the last end statement from the source file VariationalLearning.jl. Then load the contents of the file by simply issuing include(\"VariationalLearning.jl\") (without the using command).\n\n\nWe also need to load Plots to be able to do the visualizations:\n\nusing Plots\n\nAnd we also need StatsBase for the mean function, which we will use to calculate population averages:\n\nusing StatsBase\n\nIn the lecture, we noted that, in order to both carry out an interaction between two agents and summarize the population’s state over one time step, we had to use a begin ... end block. Like this:\n\nhistory = [begin\n             interact!(rand(pop), rand(pop))\n             average_p(pop)\n           end for t in 1:1_000_000]\n\nAlternatively, we can wrap the contents of the block in a function, and then call that function. This leads to neater code for the array comprehensions later, so that’s the strategy I will follow in this solution. Accordingly, I define:\n\nfunction average_p(x::Array{VariationalLearner})\n  return mean([a.p for a in x])\nend\n\nfunction step!(x::Array{VariationalLearner})\n  interact!(rand(x), rand(x))\n  return average_p(x)\nend\n\nOur goal in this exercise is to see what varying a number of model parameters does. Since the steps for running the simulation stay the same, it makes sense to define a function that takes the model parameters as arguments and then runs a whole simulation for a desired number of steps, returning the population’s history (defined as the sequence of average values of p over time). So that we don’t get confused over which argument to this function represents which model parameter, I am going to use keyword arguments here. You can read more about them in this week’s lecture.\n\nfunction simulate(; N, p, gamma, P1, P2, maxtime)\n  # initialize a population\n  pop = [VariationalLearner(p, gamma, P1, P2) for i in 1:N]\n\n  # step the population until maxtime\n  history = [step!(pop) for t in 1:maxtime]\n\n  # return history\n  return history\nend\n\nI am also going to wrap my plotting code in a custom function, for similar reasons:\n\nfunction my_plot(x)\n  plot(1:100:length(x), x[begin:100:end], label=false)\n  ylims!(0.0, 1.0)\nend\n\nmy_plot (generic function with 1 method)\n\n\nThis function is set up so that we plot every 100th time step (otherwise there will be so much stuff to plot that both plotting and displaying the figures will be very slow). Additionally, the function sets the y-axis limits to 0 and 1.\n\n\n\n\n\n\nTip\n\n\n\nWhenever there is something that needs to be repeated a number of times in your code, it is very probably a good idea to wrap that something in a function! The benefits are:\n\nYou only need to write the function definition once\nPartly because of the above, you are less likely to make mistakes (compare alternative strategy: you copy-paste a block of code, then later decide that the code needs to be modified somehow, but forget to modify all instances of the same block of code)\nYou can use arguments to modulate how the function does its thing\n\nMake a habit of writing functions whenever the opportunity arises.\n\n\nUnless otherwise noted, I am going to run each simulation for 100,000 steps, and set that with the following global variable:\n\nmaxt = 100_000\n\n100000\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions/change.html#setting-up",
    "href": "solutions/change.html#setting-up",
    "title": "Language change: parameter exploration",
    "section": "",
    "text": "First, we load the module we have already written:\n\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning\n\n\n\n\n\n\n\nNote\n\n\n\nIf VSCode complains about the module, remove the line module VariationalLearning and the last end statement from the source file VariationalLearning.jl. Then load the contents of the file by simply issuing include(\"VariationalLearning.jl\") (without the using command).\n\n\nWe also need to load Plots to be able to do the visualizations:\n\nusing Plots\n\nAnd we also need StatsBase for the mean function, which we will use to calculate population averages:\n\nusing StatsBase\n\nIn the lecture, we noted that, in order to both carry out an interaction between two agents and summarize the population’s state over one time step, we had to use a begin ... end block. Like this:\n\nhistory = [begin\n             interact!(rand(pop), rand(pop))\n             average_p(pop)\n           end for t in 1:1_000_000]\n\nAlternatively, we can wrap the contents of the block in a function, and then call that function. This leads to neater code for the array comprehensions later, so that’s the strategy I will follow in this solution. Accordingly, I define:\n\nfunction average_p(x::Array{VariationalLearner})\n  return mean([a.p for a in x])\nend\n\nfunction step!(x::Array{VariationalLearner})\n  interact!(rand(x), rand(x))\n  return average_p(x)\nend\n\nOur goal in this exercise is to see what varying a number of model parameters does. Since the steps for running the simulation stay the same, it makes sense to define a function that takes the model parameters as arguments and then runs a whole simulation for a desired number of steps, returning the population’s history (defined as the sequence of average values of p over time). So that we don’t get confused over which argument to this function represents which model parameter, I am going to use keyword arguments here. You can read more about them in this week’s lecture.\n\nfunction simulate(; N, p, gamma, P1, P2, maxtime)\n  # initialize a population\n  pop = [VariationalLearner(p, gamma, P1, P2) for i in 1:N]\n\n  # step the population until maxtime\n  history = [step!(pop) for t in 1:maxtime]\n\n  # return history\n  return history\nend\n\nI am also going to wrap my plotting code in a custom function, for similar reasons:\n\nfunction my_plot(x)\n  plot(1:100:length(x), x[begin:100:end], label=false)\n  ylims!(0.0, 1.0)\nend\n\nmy_plot (generic function with 1 method)\n\n\nThis function is set up so that we plot every 100th time step (otherwise there will be so much stuff to plot that both plotting and displaying the figures will be very slow). Additionally, the function sets the y-axis limits to 0 and 1.\n\n\n\n\n\n\nTip\n\n\n\nWhenever there is something that needs to be repeated a number of times in your code, it is very probably a good idea to wrap that something in a function! The benefits are:\n\nYou only need to write the function definition once\nPartly because of the above, you are less likely to make mistakes (compare alternative strategy: you copy-paste a block of code, then later decide that the code needs to be modified somehow, but forget to modify all instances of the same block of code)\nYou can use arguments to modulate how the function does its thing\n\nMake a habit of writing functions whenever the opportunity arises.\n\n\nUnless otherwise noted, I am going to run each simulation for 100,000 steps, and set that with the following global variable:\n\nmaxt = 100_000\n\n100000"
  },
  {
    "objectID": "solutions/change.html#effect-of-n-population-size",
    "href": "solutions/change.html#effect-of-n-population-size",
    "title": "Language change: parameter exploration",
    "section": "Effect of N (population size)",
    "text": "Effect of N (population size)\nPopulation of 100 agents:\n\nsimu1 = simulate(N = 100, p = 0.1, gamma = 0.01, P1 = 0.4, P2 = 0.1, maxtime = maxt)\nmy_plot(simu1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation of 10 agents:\n\nsimu2 = simulate(N = 10, p = 0.1, gamma = 0.01, P1 = 0.4, P2 = 0.1, maxtime = maxt)\nmy_plot(simu2)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation: in both populations, the average of p increases along an S-shaped curve. However, in the smaller population, this happens faster."
  },
  {
    "objectID": "solutions/change.html#effect-of-p-initial-value-of-p",
    "href": "solutions/change.html#effect-of-p-initial-value-of-p",
    "title": "Language change: parameter exploration",
    "section": "Effect of p (initial value of p)",
    "text": "Effect of p (initial value of p)\nAll learners start with \\(p = 0.5\\):\n\nsimu3 = simulate(N = 50, p = 0.5, gamma = 0.01, P1 = 0.4, P2 = 0.1, maxtime = maxt)\nmy_plot(simu3)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll learners start with \\(p = 0.8\\):\n\nsimu4 = simulate(N = 50, p = 0.8, gamma = 0.01, P1 = 0.4, P2 = 0.1, maxtime = maxt)\nmy_plot(simu4)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation: in both cases, the average of p increases over time. This behaviour does not seem dependent on the initial value of p in the learners."
  },
  {
    "objectID": "solutions/change.html#effect-of-p1-and-p2-the-amounts-of-evidence-for-grammars-g_1-and-g_2",
    "href": "solutions/change.html#effect-of-p1-and-p2-the-amounts-of-evidence-for-grammars-g_1-and-g_2",
    "title": "Language change: parameter exploration",
    "section": "Effect of P1 and P2 (the amounts of evidence for grammars \\(G_1\\) and \\(G_2\\))",
    "text": "Effect of P1 and P2 (the amounts of evidence for grammars \\(G_1\\) and \\(G_2\\))\nThe values of P1 and P2 reversed:\n\nsimu5 = simulate(N = 50, p = 0.1, gamma = 0.01, P1 = 0.1, P2 = 0.4, maxtime = maxt)\nmy_plot(simu5)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting from \\(p = 0.9\\):\n\nsimu6 = simulate(N = 50, p = 0.9, gamma = 0.01, P1 = 0.1, P2 = 0.4, maxtime = maxt)\nmy_plot(simu6)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation: average p decreases. This makes sense, because now \\(G_2\\) has more evidence for it than \\(G_1\\) (P2 = 0.4 and P1 = 0.1)."
  },
  {
    "objectID": "solutions/change.html#effect-of-gamma-learning-rate",
    "href": "solutions/change.html#effect-of-gamma-learning-rate",
    "title": "Language change: parameter exploration",
    "section": "Effect of \\(\\gamma\\) (learning rate)",
    "text": "Effect of \\(\\gamma\\) (learning rate)\n\nEverybody with equal \\(\\gamma\\)\nHigher value of \\(\\gamma\\):\n\nsimu7 = simulate(N = 50, p = 0.9, gamma = 0.1, P1 = 0.1, P2 = 0.4, maxtime = maxt)\nmy_plot(simu7)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLower value:\n\nsimu8 = simulate(N = 50, p = 0.9, gamma = 0.001, P1 = 0.1, P2 = 0.4, maxtime = maxt)\nmy_plot(simu8)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation: higher \\(\\gamma\\)s lead to faster change.\n\n\nRandom \\(\\gamma\\)\nNew simulation function:\n\nfunction simulate(; N, p, P1, P2, maxtime)\n  # initialize a population\n  pop = [VariationalLearner(p, rand(), P1, P2) for i in 1:N]\n\n  # step the population until maxtime\n  history = [step!(pop) for t in 1:maxtime]\n\n  # return history\n  return history\nend\n\nTry it:\n\nsimu9 = simulate(N = 50, p = 0.9, P1 = 0.1, P2 = 0.4, maxtime = maxt)\nmy_plot(simu9)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChange is again faster, with some added noise (possibly?)."
  },
  {
    "objectID": "solutions/fly.html",
    "href": "solutions/fly.html",
    "title": "Making birds fly",
    "section": "",
    "text": "Our blueprint for Birds looks like this. Notice that we declare it to be mutable – when a Bird flies, its position coordinates must change.\n\nmutable struct Bird\n  x::Float64\n  y::Float64\n  dir_x::Float64\n  dir_y::Float64\nend\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions/fly.html#the-bird-object",
    "href": "solutions/fly.html#the-bird-object",
    "title": "Making birds fly",
    "section": "",
    "text": "Our blueprint for Birds looks like this. Notice that we declare it to be mutable – when a Bird flies, its position coordinates must change.\n\nmutable struct Bird\n  x::Float64\n  y::Float64\n  dir_x::Float64\n  dir_y::Float64\nend"
  },
  {
    "objectID": "solutions/fly.html#the-population",
    "href": "solutions/fly.html#the-population",
    "title": "Making birds fly",
    "section": "2. The population",
    "text": "2. The population\nTo create a population of Birds, it is easiest to use an array comprehension. Notice how we use the rand() function to give each bird a random position and random direction. (The number of birds in the population wasn’t specified in the homework assignment – my mistake. Here, I’ve decided to create 10 birds.)\n\npopulation = [Bird(rand(), rand(), rand(), rand()) for i in 1:10]\n\n10-element Vector{Bird}:\n Bird(0.521213795535383, 0.5868067574533484, 0.8908786980927811, 0.19090669902576285)\n Bird(0.5256623915420473, 0.3905882754313441, 0.044818005017491114, 0.933353287277165)\n Bird(0.5805599818745412, 0.32723787925628356, 0.5269959187969865, 0.8362285750521512)\n Bird(0.04090613602769255, 0.4652015053812224, 0.3626493264184424, 0.10220460648875951)\n Bird(0.7201025594903295, 0.5736192424686392, 0.6644684787269287, 0.29536650475479964)\n Bird(0.2765974461749666, 0.9834357111198399, 0.8808974908158065, 0.23401680577405504)\n Bird(0.3809493792861086, 0.13194373253949954, 0.08829101913227844, 0.31350491450772877)\n Bird(0.4636097443249143, 0.7136359224862079, 0.20592490948670994, 0.09055116421778064)\n Bird(0.5819123423876457, 0.3114475007050529, 0.12114752051812694, 0.20452981732035946)\n Bird(0.38669016290895364, 0.018571999589938493, 0.07218072370140682, 0.9142465859437933)"
  },
  {
    "objectID": "solutions/fly.html#sourcing-the-plotting-code",
    "href": "solutions/fly.html#sourcing-the-plotting-code",
    "title": "Making birds fly",
    "section": "3. Sourcing the plotting code",
    "text": "3. Sourcing the plotting code\nWe now include the source code in the file plot_birds.jl which allows us to plot the population. (I store my scripts in a folder named jl in the parent directory of the current working directory, hence the ../jl/ construction before the filename.) Since this code requires the presence of the Plots package, we also first load that package using using.\n\nusing Plots\ninclude(\"../jl/plot_birds.jl\")"
  },
  {
    "objectID": "solutions/fly.html#plotting-the-population",
    "href": "solutions/fly.html#plotting-the-population",
    "title": "Making birds fly",
    "section": "4. Plotting the population",
    "text": "4. Plotting the population\nWe can now plot:\n\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy are all our birds pointing in more or less the same direction? Recall that we used rand() to initialize the birds’ positions and directions, and recall that rand() returns a random number between 0 and 1. But we can also quite easily generate a random float between -1 and 1; see:\n\n[2*rand() - 1 for i in 1:10]\n\n10-element Vector{Float64}:\n -0.22525187549286851\n  0.5438327116895545\n -0.24523348113449273\n  0.7511099991192371\n -0.4708637192761387\n  0.8037546490608298\n  0.7293861840623399\n  0.4644763024359402\n -0.7936063069983399\n  0.1751698724177022\n\n\nWith this idea in mind, let’s re-initialize our population:\n\npopulation = [Bird(2*rand() - 1, 2*rand() - 1, 2*rand() - 1, 2*rand() - 1) for i in 1:10]\n\n10-element Vector{Bird}:\n Bird(0.618865511882924, -0.5523183945589438, 0.7170489219693619, -0.24916615259097208)\n Bird(0.3534141180790922, 0.8417688482534209, 0.4129222831361803, 0.3919753816200593)\n Bird(0.7579538838754145, -0.16543176889487166, -0.12700639607293884, -0.6063073498246891)\n Bird(0.17059453226859533, 0.12660681452801836, -0.07117384268707516, 0.6495748680565732)\n Bird(0.1591833330768717, 0.6077337180274938, 0.08377142581999197, 0.5523786724183681)\n Bird(-0.8566393842375593, 0.8653672763283604, 0.6817832906156263, 0.590731985726523)\n Bird(0.5890138703978984, 0.280887894872357, -0.10813826831817863, -0.9059532971107356)\n Bird(0.2775156760816275, 0.41475391462741396, 0.9860955611224076, -0.6907174051634926)\n Bird(-0.7656879482170376, -0.8057846770570476, -0.8824796694661512, 0.24197793679586144)\n Bird(0.3464419510792771, -0.4091392851668356, 0.2423652677929784, -0.33347994991774543)\n\n\nAnd plot it:\n\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nClearly my plotting code has a bug in it: look at the four birds which have arrows pointing to them rather than away from them. (This is because when writing the code, I only tested it with birds that had positive positions and positive directions… important lesson to be learned here: when deploying code, especially code for other people to use, always test it under all imaginable circumstances!) We’ll ignore this little problem for now. A patched version of the plotting code is provided at the end of this solution."
  },
  {
    "objectID": "solutions/fly.html#the-fly-function",
    "href": "solutions/fly.html#the-fly-function",
    "title": "Making birds fly",
    "section": "5. The fly! function",
    "text": "5. The fly! function\nWe now get to the meat of the exercise: making these birds fly. The instruction was to\n\nmove x in the direction of dir_x by a little amount – let’s call that little amount delta – and […] move y in the direction of dir_y by the same amount.\n\nHow do we do this?\nOne way is to imagine that dir_x and dir_y define a local coordinate system – local to the bird. (In fact, this is what my plotting code implicitly does in order to draw the direction arrows.) Hence, for example, if dir_x is 0 and dir_y is 1, this would mean that the bird is pointing directly northwards. You can then think of the bird’s position as a vector, an arrow from the origin (0,0) to (x,y), and you can similarly think of the birds’s direction as a vector, an arrow from (x,y) to (dir_x, dir_y); see this illustration:\n\nTo make the bird move from (x,y) for (dir_x, dir_y), we perform vector summation: we set the new value of x to be x + dir_x and the new value of y to be y + dir_y.\n\nThe only thing that remains is that “little amount delta”. If we replace the direction vector (dir_x, dir_y) with (delta*dir_x, delta*dir_y), then we are effectively scaling it down (assuming delta has a value between 0 and 1):\n\nPutting all of the above together, we can now define our function for flying a bird:\n\nfunction fly!(b::Bird, delta::Float64)\n  b.x = b.x + delta*b.dir_x\n  b.y = b.y + delta*b.dir_y\nend\n\nfly! (generic function with 1 method)\n\n\nSimple! (In fact, this is the usual state of affairs: writing the code itself is not so difficult, the difficult thing is the thinking that has to be done first…)"
  },
  {
    "objectID": "solutions/fly.html#testing",
    "href": "solutions/fly.html#testing",
    "title": "Making birds fly",
    "section": "6. Testing",
    "text": "6. Testing\nLet’s now finally test the fly! function. This is what our population looked like initially:\n\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s now apply fly! to the first bird in the population a few times. (I’m choosing a very large value for delta so that we see the effects more clearly.)\n\ndelta = 0.9\nfly!(population[1], delta)\nfly!(population[1], delta)\nfly!(population[1], delta)\n\n-1.2250670065545686\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat is this number that is returned? Recall that Julia functions automatically return the results of the last expression evaluated inside a function body, in this case, the value of b.y. If you want to disable this, add return nothing as the last line of your function definition, like this:\n\nfunction fly!(b::Bird, delta::Float64)\n  b.x = b.x + delta*b.dir_x\n  b.y = b.y + delta*b.dir_y\n  return nothing\nend\n\n\n\nLet’s see what happened:\n\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne bird is flying away from the population, in the direction of its direction arrow, exactly as expected."
  },
  {
    "objectID": "solutions/fly.html#bonus-making-the-entire-population-fly",
    "href": "solutions/fly.html#bonus-making-the-entire-population-fly",
    "title": "Making birds fly",
    "section": "Bonus: making the entire population fly",
    "text": "Bonus: making the entire population fly\nRecall that in Julia, functions can be broadcast over arrays, meaning the function gets applied elementwise to each element of the array. Since our population of birds is an array, we can now very easily make each bird fly:\n\nfly!.(population, 0.9)\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurthermore, we can use an array comprehension to make each bird fly some specified number of times. For example here 20 times:\n\n[fly!.(population, 0.1) for t in 1:20]\nplot(population)"
  },
  {
    "objectID": "solutions/fly.html#updated-plotting-code",
    "href": "solutions/fly.html#updated-plotting-code",
    "title": "Making birds fly",
    "section": "Updated plotting code",
    "text": "Updated plotting code\nThere are really three problems with the code in plot_birds.jl:\n\nSometimes the direction arrow points towards the bird rather than away from it, as expected.\nWhen the birds have flown numerous times, the direction arrows become so small that they can barely be seen (cf. the above population plot).\nFinally, I forgot to include a line in the code that specifies that the presence of the Plots package is required, leading to error messages in case the end-user hasn’t loaded Plots before attempting to use the code.\n\nI have fixed these problems in an updated plot_birds_fixed.jl script which you can download here.\nApplied to our population’s current state, the bug-fixed plotting code now gives:\n\ninclude(\"../jl/plot_birds_fixed.jl\")\nplot(population)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooks much better, doesn’t it?"
  },
  {
    "objectID": "lectures/basics-slides.html#programming-in-julia",
    "href": "lectures/basics-slides.html#programming-in-julia",
    "title": "Programming basics",
    "section": "Programming in Julia",
    "text": "Programming in Julia\n\nWe will now dive straight into programming in Julia, starting with simple examples and concepts, progressing step-by-step to more complicated topics\nTo follow this lecture, you need to have a working Julia installation: see the homework on Installing Julia\nFor today, don’t worry too much about whether what we do is useful – what we are doing is establishing a foundation for later for the actually useful stuff…"
  },
  {
    "objectID": "lectures/basics-slides.html#plan",
    "href": "lectures/basics-slides.html#plan",
    "title": "Programming basics",
    "section": "Plan",
    "text": "Plan\n\nVariables and types\nArrays and broadcasting\nFunctions\nCustom types\nFirst look at random numbers\nInterpreted vs. compiled languages"
  },
  {
    "objectID": "lectures/basics-slides.html#variables-and-assignments",
    "href": "lectures/basics-slides.html#variables-and-assignments",
    "title": "Programming basics",
    "section": "Variables and assignments",
    "text": "Variables and assignments\n\nIn programming, a variable is a “storage box” that stores data for later use\nThe data is assigned to the variable using the = operator\nHere, we assign the number 5 to a variable named my_number:\n\n\nmy_number = 5\n\n\nWe can now do things such as:\n\n\nmy_number + my_number\n\n10"
  },
  {
    "objectID": "lectures/basics-slides.html#fundamental-types",
    "href": "lectures/basics-slides.html#fundamental-types",
    "title": "Programming basics",
    "section": "Fundamental types",
    "text": "Fundamental types\n\nVariables can store different types of data:\n\nIntegers: 1, 2, -100, …\nFloating-point numbers (“floats”): 3.14, pi, 1.0, …\nBooleans: true, false\nStrings: \"John\", \"Mary\"\nArrays: [1, 2, 3, 4], [1 2 3 4]\nAnd some others… we’ll meet them later"
  },
  {
    "objectID": "lectures/basics-slides.html#arithmetic-operations",
    "href": "lectures/basics-slides.html#arithmetic-operations",
    "title": "Programming basics",
    "section": "Arithmetic operations",
    "text": "Arithmetic operations\n\nArithmetic operations are mostly self-explanatory. For example:\n\n\nnumber1 = 15\nnumber2 = 20\nnumber3 = 10*(number1 + number2) - number1/number2\nnumber3\n\n349.25"
  },
  {
    "objectID": "lectures/basics-slides.html#string-concatenation",
    "href": "lectures/basics-slides.html#string-concatenation",
    "title": "Programming basics",
    "section": "String concatenation",
    "text": "String concatenation\n\nJulia overloads the * operator for strings too:\n\n\nstring1 = \"This \"\nstring2 = \"is a\"\nstring3 = \" sentence\"\nstring1 * string2 * string3 * \"!\"\n\n\"This is a sentence!\""
  },
  {
    "objectID": "lectures/basics-slides.html#arrays",
    "href": "lectures/basics-slides.html#arrays",
    "title": "Programming basics",
    "section": "Arrays",
    "text": "Arrays\n\nAn array is a (possibly multidimensional) collection of objects\n\nA one-dimensional array is a vector, a two-dimensional array is a matrix, and so on\n\nUsually we work with arrays of numbers. They are easy to create:\n\n\nmy_array = [10, 20, 30, 40]\n\n4-element Vector{Int64}:\n 10\n 20\n 30\n 40"
  },
  {
    "objectID": "lectures/basics-slides.html#accessing-array-contents",
    "href": "lectures/basics-slides.html#accessing-array-contents",
    "title": "Programming basics",
    "section": "Accessing array contents",
    "text": "Accessing array contents\n\nThe elements of an array can be accessed one-by-one by referencing their location or index in the array:\n\n\nmy_array = [10, 20, 30, 40]\nmy_array[1]\n\n10\n\n\nor\n\nmy_array[2]\n\n20"
  },
  {
    "objectID": "lectures/basics-slides.html#accessing-array-contents-1",
    "href": "lectures/basics-slides.html#accessing-array-contents-1",
    "title": "Programming basics",
    "section": "Accessing array contents",
    "text": "Accessing array contents\n\nThe special keyword end fetches the last element:\n\n\nmy_array[end]\n\n40\n\n\n\nArrays can also be subsetted:\n\n\nmy_array[2:3]\n\n2-element Vector{Int64}:\n 20\n 30"
  },
  {
    "objectID": "lectures/basics-slides.html#broadcasting",
    "href": "lectures/basics-slides.html#broadcasting",
    "title": "Programming basics",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nSuppose I want to add 1 to each number in my_array\nThe following will not work:\n\n\nmy_array + 1"
  },
  {
    "objectID": "lectures/basics-slides.html#broadcasting-1",
    "href": "lectures/basics-slides.html#broadcasting-1",
    "title": "Programming basics",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nWhy? Because mathematically the operation “add a scalar into a vector” is undefined\nTo apply an operator elementwise to each element in an array, we can prefix the operator with a period. In Julia-speak, this is called broadcasting.\n\n\nmy_array .+ 1\n\n4-element Vector{Int64}:\n 11\n 21\n 31\n 41"
  },
  {
    "objectID": "lectures/basics-slides.html#type-mismatch",
    "href": "lectures/basics-slides.html#type-mismatch",
    "title": "Programming basics",
    "section": "Type mismatch",
    "text": "Type mismatch\n\nWhy does the following not work?\n\n\nmy_string = \"My shoe size is: \"\nmy_number = 41\nmy_string * my_number"
  },
  {
    "objectID": "lectures/basics-slides.html#type-conversion",
    "href": "lectures/basics-slides.html#type-conversion",
    "title": "Programming basics",
    "section": "Type conversion",
    "text": "Type conversion\n\nTo make it work, we need to explicitly convert the integer into a string:\n\n\nmy_string = \"My shoe size is: \"\nmy_number = 41\nmy_string * string(my_number)\n\n\"My shoe size is: 41\""
  },
  {
    "objectID": "lectures/basics-slides.html#functions",
    "href": "lectures/basics-slides.html#functions",
    "title": "Programming basics",
    "section": "Functions",
    "text": "Functions\n\nA function, sometimes also known as a subroutine, is a reusable piece of code that performs, well, some function…\nWe define it once and then can use it as many times as we like\nA function can (but need not) take inputs – these are known as the function’s arguments\nA function can (but need not) give an output – this is known as the function’s return value"
  },
  {
    "objectID": "lectures/basics-slides.html#functions-example",
    "href": "lectures/basics-slides.html#functions-example",
    "title": "Programming basics",
    "section": "Functions: example",
    "text": "Functions: example\n\nHere is a function that takes two arguments, an array and a scalar number, and adds the scalar to each element of the array\nI’m calling the function add_elementwise\n\n\nfunction add_elementwise(array, scalar)\n  result = array .+ scalar\n  return result\nend\n\nadd_elementwise (generic function with 1 method)"
  },
  {
    "objectID": "lectures/basics-slides.html#functions-example-1",
    "href": "lectures/basics-slides.html#functions-example-1",
    "title": "Programming basics",
    "section": "Functions: example",
    "text": "Functions: example\n\nWe can now call the function on particular arrays and numbers:\n\n\nmy_array = [10, 20, 30, 40]\nadd_elementwise(my_array, 1)\n\n4-element Vector{Int64}:\n 11\n 21\n 31\n 41"
  },
  {
    "objectID": "lectures/basics-slides.html#functions-example-2",
    "href": "lectures/basics-slides.html#functions-example-2",
    "title": "Programming basics",
    "section": "Functions: example",
    "text": "Functions: example\n\nadd_elementwise(my_array, -23.5)\n\n4-element Vector{Float64}:\n -13.5\n  -3.5\n   6.5\n  16.5"
  },
  {
    "objectID": "lectures/basics-slides.html#exercise",
    "href": "lectures/basics-slides.html#exercise",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nWrite a function with the following properties:\n\nThe function’s name is announce_age\nThe function takes two arguments, the first a person’s name, the second a number that is that person’s age\nThe function’s return value is a string which announces the person’s age in this format: \"John is 40 years old\""
  },
  {
    "objectID": "lectures/basics-slides.html#exercise-1",
    "href": "lectures/basics-slides.html#exercise-1",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nHere is the function definition:\n\nfunction announce_age(name, age)\n  return name * \" is \" * string(age) * \" years old\"\nend\n\nannounce_age (generic function with 1 method)\n\n\nLet’s test it:\n\nannounce_age(\"John\", 40)\n\n\"John is 40 years old\""
  },
  {
    "objectID": "lectures/basics-slides.html#custom-types-classes-and-objects",
    "href": "lectures/basics-slides.html#custom-types-classes-and-objects",
    "title": "Programming basics",
    "section": "Custom types (“classes” and “objects”)",
    "text": "Custom types (“classes” and “objects”)\n\nIdea of object-oriented programming (OOP): we can make custom types (classes) which are instantiated as objects\n\nProgramming ABMs in a language that does not support this would be very cumbersome\n\nIn Julia, custom types are defined by way of a special keyword, struct\nA custom type is effectively a combination of variables called the type’s fields\nIf the fields need to be modifiable later in the program, we use mutable struct instead of struct"
  },
  {
    "objectID": "lectures/basics-slides.html#custom-types-example",
    "href": "lectures/basics-slides.html#custom-types-example",
    "title": "Programming basics",
    "section": "Custom types: example",
    "text": "Custom types: example\n\nSuppose we want to represent a person by way of their name, their age and their shoe size\nSince these fields (at least age) need to be modifiable, we use a mutable struct:\n\n\nmutable struct Person\n  name::String\n  age::Int\n  shoesize::Float64\nend"
  },
  {
    "objectID": "lectures/basics-slides.html#custom-types-example-1",
    "href": "lectures/basics-slides.html#custom-types-example-1",
    "title": "Programming basics",
    "section": "Custom types: example",
    "text": "Custom types: example\n\nmutable struct Person\n  name::String\n  age::Int\n  shoesize::Float64\nend\n\n\nHere,\n\nname::String means the field called name is of type string, etc.\nInt is an integer\nin Float64, the number specifies the precision of the floating-point number (related to how many decimals it can store)"
  },
  {
    "objectID": "lectures/basics-slides.html#custom-types-example-2",
    "href": "lectures/basics-slides.html#custom-types-example-2",
    "title": "Programming basics",
    "section": "Custom types: example",
    "text": "Custom types: example\n\nWe can now construct an instance of the Person custom type, a Person object, and store it in a variable:\n\n\njane = Person(\"Jane\", 35, 39.5)\n\nPerson(\"Jane\", 35, 39.5)\n\n\n\nTo access the fields of an object, we use the following dot syntax:\n\n\njane.name\n\n\"Jane\""
  },
  {
    "objectID": "lectures/basics-slides.html#exercise-2",
    "href": "lectures/basics-slides.html#exercise-2",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nWrite three functions:\n\nA function that takes a Person object as argument and returns their shoe size\nA function that takes a Person object and a string as argument, and sets the person’s name to be the string supplied as argument\nA function that increments a Person object’s age by one"
  },
  {
    "objectID": "lectures/basics-slides.html#exercise-3",
    "href": "lectures/basics-slides.html#exercise-3",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\n\nfunction get_shoesize(x)\n  return x.shoesize\nend\n\nfunction set_name(x, y)\n  x.name = y\nend\n\nfunction become_older(x)\n  x.age = x.age + 1\nend"
  },
  {
    "objectID": "lectures/basics-slides.html#explicit-type-specifications",
    "href": "lectures/basics-slides.html#explicit-type-specifications",
    "title": "Programming basics",
    "section": "Explicit type specifications",
    "text": "Explicit type specifications\nNote that it is possible (and often good practice) to explicitly set the types of function arguments:\n\nfunction get_shoesize(x::Person)\n  return x.shoesize\nend\n\nfunction set_name(x::Person, y::String)\n  x.name = y\nend\n\nfunction become_older(x::Person)\n  x.age = x.age + 1\nend"
  },
  {
    "objectID": "lectures/basics-slides.html#getters-and-setters",
    "href": "lectures/basics-slides.html#getters-and-setters",
    "title": "Programming basics",
    "section": "Getters and setters",
    "text": "Getters and setters\n\nFunctions that return an object’s field are sometimes known as getters. Functions that set a field are known as setters.\nIn Julia, it is customary to append an exclamation point to the name of every setter function. This is to warn users of the function that the function modifies something in the object.\nThus, we would rather write:\n\n\nfunction set_name!(x::Person, y::String)\n  x.name = y\nend"
  },
  {
    "objectID": "lectures/basics-slides.html#array-comprehensions",
    "href": "lectures/basics-slides.html#array-comprehensions",
    "title": "Programming basics",
    "section": "Array comprehensions",
    "text": "Array comprehensions\n\nWhat if we wanted to create 3 Persons? Easy:\n\n\nperson1 = Person(\"Jane\", 35, 39.5)\nperson2 = Person(\"John\", 44, 43.0)\nperson3 = Person(\"Bob\", 65, 42.33)\n\n\nWhat if we wanted to create 1000 Persons?"
  },
  {
    "objectID": "lectures/basics-slides.html#array-comprehensions-1",
    "href": "lectures/basics-slides.html#array-comprehensions-1",
    "title": "Programming basics",
    "section": "Array comprehensions",
    "text": "Array comprehensions\n\nHere we can use a powerful feature known as an array comprehension. The following creates 1000 persons, each with the same default fields (we’ll later see how to modify this), and places them in an array. The array is returned and stored in the population variable:\n\n\npopulation = [Person(\"M. Musterperson\", 0, 0.0) for i in 1:1000]\n\n\nThe i variable is a dummy variable that only exists for the duration of the array comprehension."
  },
  {
    "objectID": "lectures/basics-slides.html#array-comprehensions-2",
    "href": "lectures/basics-slides.html#array-comprehensions-2",
    "title": "Programming basics",
    "section": "Array comprehensions",
    "text": "Array comprehensions\n\nWe can now access individual persons by indexing them from the array:\n\n\npopulation[1]\n\nPerson(\"M. Musterperson\", 0, 0.0)\n\n\n\nWe can also access their fields:\n\n\npopulation[1].name\n\n\"M. Musterperson\"\n\n\n\nAnd we can set them:\n\n\nset_name(population[1], \"Bob the Builder\")\npopulation[1].name\n\n\"Bob the Builder\""
  },
  {
    "objectID": "lectures/basics-slides.html#broadcasting-functions",
    "href": "lectures/basics-slides.html#broadcasting-functions",
    "title": "Programming basics",
    "section": "Broadcasting functions",
    "text": "Broadcasting functions\n\nEarlier, we saw how operators such as + can be broadcast over arrays\nThe same can be done with functions, for example:\n\n\nalice = Person(\"Alice\", 25, 40.0)\nbob = Person(\"Robert\", 55, 45.0)\ncarly = Person(\"Carly\", 55, 39.0)\n\nspeakers = [alice, bob, carly]\n\nget_shoesize.(speakers)\n\n3-element Vector{Float64}:\n 40.0\n 45.0\n 39.0"
  },
  {
    "objectID": "lectures/basics-slides.html#random-numbers",
    "href": "lectures/basics-slides.html#random-numbers",
    "title": "Programming basics",
    "section": "Random numbers",
    "text": "Random numbers\n\nTo get a (pseudo)random number from between 0 and 1, simply call:\n\n\nrand()\n\n0.30435077510509545"
  },
  {
    "objectID": "lectures/basics-slides.html#exercise-4",
    "href": "lectures/basics-slides.html#exercise-4",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nHow can you obtain a random number from between 0 and 50?\nHow about between 50 and 100?"
  },
  {
    "objectID": "lectures/basics-slides.html#exercise-5",
    "href": "lectures/basics-slides.html#exercise-5",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nRandom number from between 0 and 50:\n\n50*rand()\n\n4.729371853710718\n\n\nRandom number from between 50 and 100:\n\n50 + 50*rand()\n\n96.05387965487533"
  },
  {
    "objectID": "lectures/basics-slides.html#comments",
    "href": "lectures/basics-slides.html#comments",
    "title": "Programming basics",
    "section": "Comments",
    "text": "Comments\n\nTo improve code readability, we insert comments (these are ignored by the compiler)\nSingle-line comment:\n\n\n# the following variable stores my shoe size\nshoesize = 41.5\n\n\nMulti-line comment:\n\n\n#=\nThe following variable\nstores my shoe size\n=#\nshoesize = 41.5"
  },
  {
    "objectID": "lectures/basics-slides.html#packages",
    "href": "lectures/basics-slides.html#packages",
    "title": "Programming basics",
    "section": "Packages",
    "text": "Packages\n\nBasic Julia functionality is extended by packages\nThese are installed through a package manager called Pkg\nE.g. to install the Agents package (and all its dependencies), we issue these commands:\n\n\nusing Pkg\nPkg.add(\"Agents\")\n\n\nOnce the package has been installed, we can load it by:\n\n\nusing Agents"
  },
  {
    "objectID": "lectures/basics-slides.html#why-is-julia-sometimes-slow",
    "href": "lectures/basics-slides.html#why-is-julia-sometimes-slow",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\n\n\n\n\nCPUs and computer memory consist of binary devices, they are either “on” or “off”1\n\n\n\nPhoto of replica of the first transistor from Wikimedia Commons. Public domain."
  },
  {
    "objectID": "lectures/basics-slides.html#why-is-julia-sometimes-slow-1",
    "href": "lectures/basics-slides.html#why-is-julia-sometimes-slow-1",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\n\n\nBut humans write source code which is understandable to humans (well, mostly anyway…)1\n\n\n\n\n\nCartoon from geek & poke. CC-BY-3.0."
  },
  {
    "objectID": "lectures/basics-slides.html#why-is-julia-sometimes-slow-2",
    "href": "lectures/basics-slides.html#why-is-julia-sometimes-slow-2",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\nSo translation is needed.\nImagine you need to translate cooking recipes (algorithms) from English (source code) to Spanish (machine code). You have roughly two options:\n\nEvery time a particular instruction is called for, you translate it anew (interpreted languages)\nYou translate the entire recipe and give it to the cook (the CPU) (compiled languages)"
  },
  {
    "objectID": "lectures/basics-slides.html#why-is-julia-sometimes-slow-3",
    "href": "lectures/basics-slides.html#why-is-julia-sometimes-slow-3",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\nJulia is a just-in-time (JIT) compiled language\nMeaning roughly: code blocks are compiled as they are encountered\nCompiled code is stored for later use\nInitial compilation takes time"
  },
  {
    "objectID": "lectures/basics-slides.html#why-is-julia-sometimes-fast",
    "href": "lectures/basics-slides.html#why-is-julia-sometimes-fast",
    "title": "Programming basics",
    "section": "Why is Julia sometimes fast?",
    "text": "Why is Julia sometimes fast?\n\nHowever, all subsequent executions are fast!\nThis is because the translations have already been made and stored\nFurthermore, code can be optimized during the initial compilation\n\nSince your Spanish cook (the CPU) knows that “cdta.” stands for “cucharadita” (teaspoon), the compiler can use the shorter translation instead of the long one"
  },
  {
    "objectID": "lectures/basics-slides.html#speed-in-practice",
    "href": "lectures/basics-slides.html#speed-in-practice",
    "title": "Programming basics",
    "section": "Speed in practice",
    "text": "Speed in practice\n\nIn practice, these differences mean that:\n\nRunning a function once may be quicker in Python\nRunning the same function 1000 times will be quicker in Julia\n\nA lot of the attractiveness of Julia for ABM comes from this fact – that it compiles into fast machine code on many different processor architectures"
  },
  {
    "objectID": "lectures/basics-slides.html#summary",
    "href": "lectures/basics-slides.html#summary",
    "title": "Programming basics",
    "section": "Summary",
    "text": "Summary\n\nHere you’ve learned some of the basics of the Julia language\nThere is much more… we will learn it as we go along\nWe will make heavy use of array comprehensions, functions and custom types, so make sure you understand these concepts\nYou get to practice them in this week’s homework"
  },
  {
    "objectID": "lectures/basics.html",
    "href": "lectures/basics.html",
    "title": "Programming basics",
    "section": "",
    "text": "We will now dive straight into programming in Julia, starting with simple examples and concepts, progressing step-by-step to more complicated topics\nTo follow this lecture, you need to have a working Julia installation: see the homework on Installing Julia\nFor today, don’t worry too much about whether what we do is useful – what we are doing is establishing a foundation for later for the actually useful stuff…\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/basics.html#programming-in-julia",
    "href": "lectures/basics.html#programming-in-julia",
    "title": "Programming basics",
    "section": "",
    "text": "We will now dive straight into programming in Julia, starting with simple examples and concepts, progressing step-by-step to more complicated topics\nTo follow this lecture, you need to have a working Julia installation: see the homework on Installing Julia\nFor today, don’t worry too much about whether what we do is useful – what we are doing is establishing a foundation for later for the actually useful stuff…"
  },
  {
    "objectID": "lectures/basics.html#plan",
    "href": "lectures/basics.html#plan",
    "title": "Programming basics",
    "section": "Plan",
    "text": "Plan\n\nVariables and types\nArrays and broadcasting\nFunctions\nCustom types\nFirst look at random numbers\nInterpreted vs. compiled languages"
  },
  {
    "objectID": "lectures/basics.html#variables-and-assignments",
    "href": "lectures/basics.html#variables-and-assignments",
    "title": "Programming basics",
    "section": "Variables and assignments",
    "text": "Variables and assignments\n\nIn programming, a variable is a “storage box” that stores data for later use\nThe data is assigned to the variable using the = operator\nHere, we assign the number 5 to a variable named my_number:\n\n\nmy_number = 5\n\n\nWe can now do things such as:\n\n\nmy_number + my_number\n\n10"
  },
  {
    "objectID": "lectures/basics.html#fundamental-types",
    "href": "lectures/basics.html#fundamental-types",
    "title": "Programming basics",
    "section": "Fundamental types",
    "text": "Fundamental types\n\nVariables can store different types of data:\n\nIntegers: 1, 2, -100, …\nFloating-point numbers (“floats”): 3.14, pi, 1.0, …\nBooleans: true, false\nStrings: \"John\", \"Mary\"\nArrays: [1, 2, 3, 4], [1 2 3 4]\nAnd some others… we’ll meet them later"
  },
  {
    "objectID": "lectures/basics.html#arithmetic-operations",
    "href": "lectures/basics.html#arithmetic-operations",
    "title": "Programming basics",
    "section": "Arithmetic operations",
    "text": "Arithmetic operations\n\nArithmetic operations are mostly self-explanatory. For example:\n\n\nnumber1 = 15\nnumber2 = 20\nnumber3 = 10*(number1 + number2) - number1/number2\nnumber3\n\n349.25"
  },
  {
    "objectID": "lectures/basics.html#string-concatenation",
    "href": "lectures/basics.html#string-concatenation",
    "title": "Programming basics",
    "section": "String concatenation",
    "text": "String concatenation\n\nJulia overloads the * operator for strings too:\n\n\nstring1 = \"This \"\nstring2 = \"is a\"\nstring3 = \" sentence\"\nstring1 * string2 * string3 * \"!\"\n\n\"This is a sentence!\""
  },
  {
    "objectID": "lectures/basics.html#arrays",
    "href": "lectures/basics.html#arrays",
    "title": "Programming basics",
    "section": "Arrays",
    "text": "Arrays\n\nAn array is a (possibly multidimensional) collection of objects\n\nA one-dimensional array is a vector, a two-dimensional array is a matrix, and so on\n\nUsually we work with arrays of numbers. They are easy to create:\n\n\nmy_array = [10, 20, 30, 40]\n\n4-element Vector{Int64}:\n 10\n 20\n 30\n 40"
  },
  {
    "objectID": "lectures/basics.html#accessing-array-contents",
    "href": "lectures/basics.html#accessing-array-contents",
    "title": "Programming basics",
    "section": "Accessing array contents",
    "text": "Accessing array contents\n\nThe elements of an array can be accessed one-by-one by referencing their location or index in the array:\n\n\nmy_array = [10, 20, 30, 40]\nmy_array[1]\n\n10\n\n\nor\n\nmy_array[2]\n\n20\n\n\n\nThe special keyword end fetches the last element:\n\n\nmy_array[end]\n\n40\n\n\n\nArrays can also be subsetted:\n\n\nmy_array[2:3]\n\n2-element Vector{Int64}:\n 20\n 30"
  },
  {
    "objectID": "lectures/basics.html#broadcasting",
    "href": "lectures/basics.html#broadcasting",
    "title": "Programming basics",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nSuppose I want to add 1 to each number in my_array\nThe following will not work:\n\n\nmy_array + 1\n\n\nWhy? Because mathematically the operation “add a scalar into a vector” is undefined\nTo apply an operator elementwise to each element in an array, we can prefix the operator with a period. In Julia-speak, this is called broadcasting.\n\n\nmy_array .+ 1\n\n4-element Vector{Int64}:\n 11\n 21\n 31\n 41"
  },
  {
    "objectID": "lectures/basics.html#type-mismatch",
    "href": "lectures/basics.html#type-mismatch",
    "title": "Programming basics",
    "section": "Type mismatch",
    "text": "Type mismatch\n\nWhy does the following not work?\n\n\nmy_string = \"My shoe size is: \"\nmy_number = 41\nmy_string * my_number\n\n\nTo make it work, we need to explicitly convert the integer into a string:\n\n\nmy_string = \"My shoe size is: \"\nmy_number = 41\nmy_string * string(my_number)\n\n\"My shoe size is: 41\""
  },
  {
    "objectID": "lectures/basics.html#functions",
    "href": "lectures/basics.html#functions",
    "title": "Programming basics",
    "section": "Functions",
    "text": "Functions\n\nA function, sometimes also known as a subroutine, is a reusable piece of code that performs, well, some function…\nWe define it once and then can use it as many times as we like\nA function can (but need not) take inputs – these are known as the function’s arguments\nA function can (but need not) give an output – this is known as the function’s return value"
  },
  {
    "objectID": "lectures/basics.html#functions-example",
    "href": "lectures/basics.html#functions-example",
    "title": "Programming basics",
    "section": "Functions: example",
    "text": "Functions: example\n\nHere is a function that takes two arguments, an array and a scalar number, and adds the scalar to each element of the array\nI’m calling the function add_elementwise\n\n\nfunction add_elementwise(array, scalar)\n  result = array .+ scalar\n  return result\nend\n\nadd_elementwise (generic function with 1 method)\n\n\n\nWe can now call the function on particular arrays and numbers:\n\n\nmy_array = [10, 20, 30, 40]\nadd_elementwise(my_array, 1)\n\n4-element Vector{Int64}:\n 11\n 21\n 31\n 41\n\n\n\nadd_elementwise(my_array, -23.5)\n\n4-element Vector{Float64}:\n -13.5\n  -3.5\n   6.5\n  16.5"
  },
  {
    "objectID": "lectures/basics.html#exercise",
    "href": "lectures/basics.html#exercise",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nWrite a function with the following properties:\n\nThe function’s name is announce_age\nThe function takes two arguments, the first a person’s name, the second a number that is that person’s age\nThe function’s return value is a string which announces the person’s age in this format: \"John is 40 years old\"\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nHere is the function definition:\n\nfunction announce_age(name, age)\n  return name * \" is \" * string(age) * \" years old\"\nend\n\nannounce_age (generic function with 1 method)\n\n\nLet’s test it:\n\nannounce_age(\"John\", 40)\n\n\"John is 40 years old\""
  },
  {
    "objectID": "lectures/basics.html#custom-types-classes-and-objects",
    "href": "lectures/basics.html#custom-types-classes-and-objects",
    "title": "Programming basics",
    "section": "Custom types (“classes” and “objects”)",
    "text": "Custom types (“classes” and “objects”)\n\nIdea of object-oriented programming (OOP): we can make custom types (classes) which are instantiated as objects\n\nProgramming ABMs in a language that does not support this would be very cumbersome\n\nIn Julia, custom types are defined by way of a special keyword, struct\nA custom type is effectively a combination of variables called the type’s fields\nIf the fields need to be modifiable later in the program, we use mutable struct instead of struct"
  },
  {
    "objectID": "lectures/basics.html#custom-types-example",
    "href": "lectures/basics.html#custom-types-example",
    "title": "Programming basics",
    "section": "Custom types: example",
    "text": "Custom types: example\n\nSuppose we want to represent a person by way of their name, their age and their shoe size\nSince these fields (at least age) need to be modifiable, we use a mutable struct:\n\n\nmutable struct Person\n  name::String\n  age::Int\n  shoesize::Float64\nend\n\n\nHere,\n\nname::String means the field called name is of type string, etc.\nInt is an integer\nin Float64, the number specifies the precision of the floating-point number (related to how many decimals it can store)\n\n\n\nWe can now construct an instance of the Person custom type, a Person object, and store it in a variable:\n\n\njane = Person(\"Jane\", 35, 39.5)\n\nPerson(\"Jane\", 35, 39.5)\n\n\n\nTo access the fields of an object, we use the following dot syntax:\n\n\njane.name\n\n\"Jane\""
  },
  {
    "objectID": "lectures/basics.html#exercise-2",
    "href": "lectures/basics.html#exercise-2",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nWrite three functions:\n\nA function that takes a Person object as argument and returns their shoe size\nA function that takes a Person object and a string as argument, and sets the person’s name to be the string supplied as argument\nA function that increments a Person object’s age by one\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nfunction get_shoesize(x)\n  return x.shoesize\nend\n\nfunction set_name(x, y)\n  x.name = y\nend\n\nfunction become_older(x)\n  x.age = x.age + 1\nend"
  },
  {
    "objectID": "lectures/basics.html#explicit-type-specifications",
    "href": "lectures/basics.html#explicit-type-specifications",
    "title": "Programming basics",
    "section": "Explicit type specifications",
    "text": "Explicit type specifications\nNote that it is possible (and often good practice) to explicitly set the types of function arguments:\n\nfunction get_shoesize(x::Person)\n  return x.shoesize\nend\n\nfunction set_name(x::Person, y::String)\n  x.name = y\nend\n\nfunction become_older(x::Person)\n  x.age = x.age + 1\nend"
  },
  {
    "objectID": "lectures/basics.html#getters-and-setters",
    "href": "lectures/basics.html#getters-and-setters",
    "title": "Programming basics",
    "section": "Getters and setters",
    "text": "Getters and setters\n\nFunctions that return an object’s field are sometimes known as getters. Functions that set a field are known as setters.\nIn Julia, it is customary to append an exclamation point to the name of every setter function. This is to warn users of the function that the function modifies something in the object.\nThus, we would rather write:\n\n\nfunction set_name!(x::Person, y::String)\n  x.name = y\nend"
  },
  {
    "objectID": "lectures/basics.html#array-comprehensions",
    "href": "lectures/basics.html#array-comprehensions",
    "title": "Programming basics",
    "section": "Array comprehensions",
    "text": "Array comprehensions\n\nWhat if we wanted to create 3 Persons? Easy:\n\n\nperson1 = Person(\"Jane\", 35, 39.5)\nperson2 = Person(\"John\", 44, 43.0)\nperson3 = Person(\"Bob\", 65, 42.33)\n\n\nWhat if we wanted to create 1000 Persons?\n\n\nHere we can use a powerful feature known as an array comprehension. The following creates 1000 persons, each with the same default fields (we’ll later see how to modify this), and places them in an array. The array is returned and stored in the population variable:\n\n\npopulation = [Person(\"M. Musterperson\", 0, 0.0) for i in 1:1000]\n\n\nThe i variable is a dummy variable that only exists for the duration of the array comprehension.\n\n\nWe can now access individual persons by indexing them from the array:\n\n\npopulation[1]\n\nPerson(\"M. Musterperson\", 0, 0.0)\n\n\n\nWe can also access their fields:\n\n\npopulation[1].name\n\n\"M. Musterperson\"\n\n\n\nAnd we can set them:\n\n\nset_name(population[1], \"Bob the Builder\")\npopulation[1].name\n\n\"Bob the Builder\""
  },
  {
    "objectID": "lectures/basics.html#broadcasting-functions",
    "href": "lectures/basics.html#broadcasting-functions",
    "title": "Programming basics",
    "section": "Broadcasting functions",
    "text": "Broadcasting functions\n\nEarlier, we saw how operators such as + can be broadcast over arrays\nThe same can be done with functions, for example:\n\n\nalice = Person(\"Alice\", 25, 40.0)\nbob = Person(\"Robert\", 55, 45.0)\ncarly = Person(\"Carly\", 55, 39.0)\n\nspeakers = [alice, bob, carly]\n\nget_shoesize.(speakers)\n\n3-element Vector{Float64}:\n 40.0\n 45.0\n 39.0"
  },
  {
    "objectID": "lectures/basics.html#random-numbers",
    "href": "lectures/basics.html#random-numbers",
    "title": "Programming basics",
    "section": "Random numbers",
    "text": "Random numbers\n\nTo get a (pseudo)random number from between 0 and 1, simply call:\n\n\nrand()\n\n0.39029477137173396"
  },
  {
    "objectID": "lectures/basics.html#exercise-4",
    "href": "lectures/basics.html#exercise-4",
    "title": "Programming basics",
    "section": "Exercise",
    "text": "Exercise\nHow can you obtain a random number from between 0 and 50?\nHow about between 50 and 100?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRandom number from between 0 and 50:\n\n50*rand()\n\n18.916210144988714\n\n\nRandom number from between 50 and 100:\n\n50 + 50*rand()\n\n83.27688476510404"
  },
  {
    "objectID": "lectures/basics.html#comments",
    "href": "lectures/basics.html#comments",
    "title": "Programming basics",
    "section": "Comments",
    "text": "Comments\n\nTo improve code readability, we insert comments (these are ignored by the compiler)\nSingle-line comment:\n\n\n# the following variable stores my shoe size\nshoesize = 41.5\n\n\nMulti-line comment:\n\n\n#=\nThe following variable\nstores my shoe size\n=#\nshoesize = 41.5"
  },
  {
    "objectID": "lectures/basics.html#packages",
    "href": "lectures/basics.html#packages",
    "title": "Programming basics",
    "section": "Packages",
    "text": "Packages\n\nBasic Julia functionality is extended by packages\nThese are installed through a package manager called Pkg\nE.g. to install the Agents package (and all its dependencies), we issue these commands:\n\n\nusing Pkg\nPkg.add(\"Agents\")\n\n\nOnce the package has been installed, we can load it by:\n\n\nusing Agents"
  },
  {
    "objectID": "lectures/basics.html#why-is-julia-sometimes-slow",
    "href": "lectures/basics.html#why-is-julia-sometimes-slow",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\nCPUs and computer memory consist of binary devices, they are either “on” or “off”1\n\n1 Photo of replica of the first transistor from Wikimedia Commons. Public domain.\n\nBut humans write source code which is understandable to humans (well, mostly anyway…)2\n\n2 Cartoon from geek & poke. CC-BY-3.0.\n\nSo translation is needed.\nImagine you need to translate cooking recipes (algorithms) from English (source code) to Spanish (machine code). You have roughly two options:\n\nEvery time a particular instruction is called for, you translate it anew (interpreted languages)\nYou translate the entire recipe and give it to the cook (the CPU) (compiled languages)"
  },
  {
    "objectID": "lectures/basics.html#why-is-julia-sometimes-slow-3",
    "href": "lectures/basics.html#why-is-julia-sometimes-slow-3",
    "title": "Programming basics",
    "section": "Why is Julia sometimes slow?",
    "text": "Why is Julia sometimes slow?\n\nJulia is a just-in-time (JIT) compiled language\nMeaning roughly: code blocks are compiled as they are encountered\nCompiled code is stored for later use\nInitial compilation takes time"
  },
  {
    "objectID": "lectures/basics.html#why-is-julia-sometimes-fast",
    "href": "lectures/basics.html#why-is-julia-sometimes-fast",
    "title": "Programming basics",
    "section": "Why is Julia sometimes fast?",
    "text": "Why is Julia sometimes fast?\n\nHowever, all subsequent executions are fast!\nThis is because the translations have already been made and stored\nFurthermore, code can be optimized during the initial compilation\n\nSince your Spanish cook (the CPU) knows that “cdta.” stands for “cucharadita” (teaspoon), the compiler can use the shorter translation instead of the long one"
  },
  {
    "objectID": "lectures/basics.html#speed-in-practice",
    "href": "lectures/basics.html#speed-in-practice",
    "title": "Programming basics",
    "section": "Speed in practice",
    "text": "Speed in practice\n\nIn practice, these differences mean that:\n\nRunning a function once may be quicker in Python\nRunning the same function 1000 times will be quicker in Julia\n\nA lot of the attractiveness of Julia for ABM comes from this fact – that it compiles into fast machine code on many different processor architectures"
  },
  {
    "objectID": "lectures/basics.html#summary",
    "href": "lectures/basics.html#summary",
    "title": "Programming basics",
    "section": "Summary",
    "text": "Summary\n\nHere you’ve learned some of the basics of the Julia language\nThere is much more… we will learn it as we go along\nWe will make heavy use of array comprehensions, functions and custom types, so make sure you understand these concepts\nYou get to practice them in this week’s homework"
  },
  {
    "objectID": "lectures/speaking-slides.html#plan",
    "href": "lectures/speaking-slides.html#plan",
    "title": "Speaking and listening",
    "section": "Plan",
    "text": "Plan\n\nLast week, we ran out of time\nBetter go slowly and build a solid foundation rather than try to cover as much ground as possible\nHence, today:\n\nFinish last week’s material\nIntroduce a little bit of new material: implementing interactions between variational learners"
  },
  {
    "objectID": "lectures/speaking-slides.html#dropping-the-environment",
    "href": "lectures/speaking-slides.html#dropping-the-environment",
    "title": "Speaking and listening",
    "section": "Dropping the environment",
    "text": "Dropping the environment\n\nSo far, we’ve been working with the abstraction of a LearningEnvironment:"
  },
  {
    "objectID": "lectures/speaking-slides.html#dropping-the-environment-1",
    "href": "lectures/speaking-slides.html#dropping-the-environment-1",
    "title": "Speaking and listening",
    "section": "Dropping the environment",
    "text": "Dropping the environment\n\nWe will now drop this and have two VariationalLearners interacting:"
  },
  {
    "objectID": "lectures/speaking-slides.html#dropping-the-environment-2",
    "href": "lectures/speaking-slides.html#dropping-the-environment-2",
    "title": "Speaking and listening",
    "section": "Dropping the environment",
    "text": "Dropping the environment\n\nThe probabilities P1 and P2 now need to be represented inside the learner:"
  },
  {
    "objectID": "lectures/speaking-slides.html#dropping-the-environment-3",
    "href": "lectures/speaking-slides.html#dropping-the-environment-3",
    "title": "Speaking and listening",
    "section": "Dropping the environment",
    "text": "Dropping the environment\n\nHence we define:\n\n\nmutable struct VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend"
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise",
    "href": "lectures/speaking-slides.html#exercise",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\nWrite three functions:\n\nspeak(x::VariationalLearner): takes a variational learner as argument and returns a string uttered by the learner\nlearn!(x::VariationalLearner, s::String): makes variational learner x learn from string s\ninteract!(x::VariationalLearner, y::VariationalLearner): makes x utter a string and y learn from that string"
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise-1",
    "href": "lectures/speaking-slides.html#exercise-1",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer (speak)\n\n\n\nusing StatsBase\n\nfunction speak(x::VariationalLearner)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\"\n    return sample([\"S1\", \"S12\"], Weights([x.P1, 1 - x.P1]))\n  else\n    return sample([\"S2\", \"S12\"], Weights([x.P2, 1 - x.P2]))\n  end\nend\n\nspeak (generic function with 1 method)"
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise-2",
    "href": "lectures/speaking-slides.html#exercise-2",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer (learn!)\n\n\n\nfunction learn!(x::VariationalLearner, s::String)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\nlearn! (generic function with 1 method)"
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise-3",
    "href": "lectures/speaking-slides.html#exercise-3",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer (interact!)\n\n\n\nfunction interact!(x::VariationalLearner, y::VariationalLearner)\n  s = speak(x)\n  learn!(y, s)\nend\n\ninteract! (generic function with 1 method)"
  },
  {
    "objectID": "lectures/speaking-slides.html#picking-random-agents",
    "href": "lectures/speaking-slides.html#picking-random-agents",
    "title": "Speaking and listening",
    "section": "Picking random agents",
    "text": "Picking random agents\n\nrand() without arguments returns a random float between 0 and 1\nrand(x) with argument x returns a random element of x\nIf we have a population of agents pop, then we can use rand(pop) to pick a random agent\nThis is very useful for evolving an ABM"
  },
  {
    "objectID": "lectures/speaking-slides.html#aside-for-loops",
    "href": "lectures/speaking-slides.html#aside-for-loops",
    "title": "Speaking and listening",
    "section": "Aside: for loops",
    "text": "Aside: for loops\n\nA for loop is used to repeat a code block a number of times\nSimilar to array comprehensions; however, result is not stored in an array\n\n\nfor i in 1:3\n  println(\"Current number is \" * string(i))\nend\n\nCurrent number is 1\nCurrent number is 2\nCurrent number is 3"
  },
  {
    "objectID": "lectures/speaking-slides.html#a-whole-population",
    "href": "lectures/speaking-slides.html#a-whole-population",
    "title": "Speaking and listening",
    "section": "A whole population",
    "text": "A whole population\n\nUsing a for loop and the functions we defined above, it is now very easy to iterate or evolve a population of agents:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\nfor t in 1:100\n  x = rand(pop)\n  y = rand(pop)\n  interact!(x, y)\nend"
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise-4",
    "href": "lectures/speaking-slides.html#exercise-4",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\nWrite the same thing using an array comprehension instead of a for loop."
  },
  {
    "objectID": "lectures/speaking-slides.html#exercise-5",
    "href": "lectures/speaking-slides.html#exercise-5",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n100-element Vector{Float64}:\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n ⋮\n 0.09801\n 0.099\n 0.10900000000000001\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099"
  },
  {
    "objectID": "lectures/speaking-slides.html#next-time",
    "href": "lectures/speaking-slides.html#next-time",
    "title": "Speaking and listening",
    "section": "Next time",
    "text": "Next time\n\nNext week, we will learn how to summarize the state of an entire population\nThis will allow us to track the population’s behaviour over time and hence model potential language change\nThis week’s homework is all about consolidating the ideas we’ve looked at so far – the variational learner and basics of Julia"
  },
  {
    "objectID": "lectures/speaking.html",
    "href": "lectures/speaking.html",
    "title": "Speaking and listening",
    "section": "",
    "text": "Update 7 May 2024\n\n\n\nFixed the buggy learn! function. Also added the missing link to the homework.\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/speaking.html#plan",
    "href": "lectures/speaking.html#plan",
    "title": "Speaking and listening",
    "section": "Plan",
    "text": "Plan\n\nLast week, we ran out of time\nBetter go slowly and build a solid foundation rather than try to cover as much ground as possible\nHence, today:\n\nFinish last week’s material\nIntroduce a little bit of new material: implementing interactions between variational learners"
  },
  {
    "objectID": "lectures/speaking.html#dropping-the-environment",
    "href": "lectures/speaking.html#dropping-the-environment",
    "title": "Speaking and listening",
    "section": "Dropping the environment",
    "text": "Dropping the environment\n\nSo far, we’ve been working with the abstraction of a LearningEnvironment:\n\n\n\nWe will now drop this and have two VariationalLearners interacting:\n\n\n\nThe probabilities P1 and P2 now need to be represented inside the learner:\n\n\n\nHence we define:\n\n\nmutable struct VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend"
  },
  {
    "objectID": "lectures/speaking.html#exercise",
    "href": "lectures/speaking.html#exercise",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\nWrite three functions:\n\nspeak(x::VariationalLearner): takes a variational learner as argument and returns a string uttered by the learner\nlearn!(x::VariationalLearner, s::String): makes variational learner x learn from string s\ninteract!(x::VariationalLearner, y::VariationalLearner): makes x utter a string and y learn from that string\n\n\n\n\n\n\n\nAnswer (speak)\n\n\n\n\n\n\nusing StatsBase\n\nfunction speak(x::VariationalLearner)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\"\n    return sample([\"S1\", \"S12\"], Weights([x.P1, 1 - x.P1]))\n  else\n    return sample([\"S2\", \"S12\"], Weights([x.P2, 1 - x.P2]))\n  end\nend\n\nspeak (generic function with 1 method)\n\n\n\n\n\n\n\n\n\n\n\nAnswer (learn!)\n\n\n\n\n\n\nfunction learn!(x::VariationalLearner, s::String)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\nlearn! (generic function with 1 method)\n\n\n\n\n\n\n\n\n\n\n\nAnswer (interact!)\n\n\n\n\n\n\nfunction interact!(x::VariationalLearner, y::VariationalLearner)\n  s = speak(x)\n  learn!(y, s)\nend\n\ninteract! (generic function with 1 method)"
  },
  {
    "objectID": "lectures/speaking.html#picking-random-agents",
    "href": "lectures/speaking.html#picking-random-agents",
    "title": "Speaking and listening",
    "section": "Picking random agents",
    "text": "Picking random agents\n\nrand() without arguments returns a random float between 0 and 1\nrand(x) with argument x returns a random element of x\nIf we have a population of agents pop, then we can use rand(pop) to pick a random agent\nThis is very useful for evolving an ABM"
  },
  {
    "objectID": "lectures/speaking.html#aside-for-loops",
    "href": "lectures/speaking.html#aside-for-loops",
    "title": "Speaking and listening",
    "section": "Aside: for loops",
    "text": "Aside: for loops\n\nA for loop is used to repeat a code block a number of times\nSimilar to array comprehensions; however, result is not stored in an array\n\n\nfor i in 1:3\n  println(\"Current number is \" * string(i))\nend\n\nCurrent number is 1\nCurrent number is 2\nCurrent number is 3"
  },
  {
    "objectID": "lectures/speaking.html#a-whole-population",
    "href": "lectures/speaking.html#a-whole-population",
    "title": "Speaking and listening",
    "section": "A whole population",
    "text": "A whole population\n\nUsing a for loop and the functions we defined above, it is now very easy to iterate or evolve a population of agents:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\nfor t in 1:100\n  x = rand(pop)\n  y = rand(pop)\n  interact!(x, y)\nend"
  },
  {
    "objectID": "lectures/speaking.html#exercise-4",
    "href": "lectures/speaking.html#exercise-4",
    "title": "Speaking and listening",
    "section": "Exercise",
    "text": "Exercise\nWrite the same thing using an array comprehension instead of a for loop.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n100-element Vector{Float64}:\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n ⋮\n 0.09801\n 0.099\n 0.10900000000000001\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099"
  },
  {
    "objectID": "lectures/speaking.html#next-time",
    "href": "lectures/speaking.html#next-time",
    "title": "Speaking and listening",
    "section": "Next time",
    "text": "Next time\n\nNext week, we will learn how to summarize the state of an entire population\nThis will allow us to track the population’s behaviour over time and hence model potential language change\nThis week’s homework is all about consolidating the ideas we’ve looked at so far – the variational learner and basics of Julia"
  },
  {
    "objectID": "lectures/intro-slides.html#what-is-an-agent-based-model-abm",
    "href": "lectures/intro-slides.html#what-is-an-agent-based-model-abm",
    "title": "Intro to ABMs",
    "section": "What is an agent-based model (ABM)?",
    "text": "What is an agent-based model (ABM)?\n\nNo rigorous definition (like most applied science)\nBut: can characterize as a model consisting of\n\nentities (the agents)…\n…which act1 upon each other…\n…in some kind of environment…\n…to create some emergent outcome\n\n“Emergent” = collective is more than the sum of its parts\nImplemented computationally, sometimes also analysed mathematically\n\nEng. agent &lt; Lat. agens, pres. part. of ago ‘act’"
  },
  {
    "objectID": "lectures/intro-slides.html#what-is-the-benefit-of-abms",
    "href": "lectures/intro-slides.html#what-is-the-benefit-of-abms",
    "title": "Intro to ABMs",
    "section": "What is the benefit of ABMs?",
    "text": "What is the benefit of ABMs?\n\n“Like equation-based modeling, but unlike prose, agent-based models must be complete, consistent, and unambiguous” (Gilbert 2020, xii, my emphasis)\n\n\n\ncomplete: the modeller cannot leave anything out of the model description\nconsistent: no part of the model can logically contradict another part of the same model\nunambiguous: the meaning of every part of the model must be objectively clear"
  },
  {
    "objectID": "lectures/intro-slides.html#what-is-the-benefit-of-abms-1",
    "href": "lectures/intro-slides.html#what-is-the-benefit-of-abms-1",
    "title": "Intro to ABMs",
    "section": "What is the benefit of ABMs?",
    "text": "What is the benefit of ABMs?\n\n“Like equation-based modeling, but unlike prose, agent-based models must be complete, consistent, and unambiguous if they are to be capable of being executed on a computer” (Gilbert 2020, xii, my emphasis)\n\n\ncomplete: the modeller cannot leave anything out of the model description\nconsistent: no part of the model can logically contradict another part of the same model\nunambiguous: the meaning of every part of the model must be objectively clear"
  },
  {
    "objectID": "lectures/intro-slides.html#examples",
    "href": "lectures/intro-slides.html#examples",
    "title": "Intro to ABMs",
    "section": "Examples",
    "text": "Examples\nThese concepts are best explained through the use of examples…\n…so let’s look at a few!1\nThe examples are taken from the Example Zoo of the Agents.jl package (released under the MIT license)."
  },
  {
    "objectID": "lectures/intro-slides.html#example-1-conways-game-of-life",
    "href": "lectures/intro-slides.html#example-1-conways-game-of-life",
    "title": "Intro to ABMs",
    "section": "Example 1: Conway’s Game of Life",
    "text": "Example 1: Conway’s Game of Life\n\nEarly example of a cellular automaton (Gardner 1970)\nLattice; each cell either “live” (L) or “dead” (D)\nRules:\n\n\n\n\nRule\nCell\nNeighbourhood\nResult\n\n\n\n\n“underpopulation”\nL\n&lt; 2 L cells\nL \\(\\to\\) D\n\n\n“sustenance”\nL\n2 or 3 L cells\nL \\(\\to\\) L\n\n\n“overpopulation”\nL\n&gt; 3 L cells\nL \\(\\to\\) D\n\n\n“reproduction”\nD\n3 L cells\nD \\(\\to\\) L"
  },
  {
    "objectID": "lectures/intro-slides.html#question",
    "href": "lectures/intro-slides.html#question",
    "title": "Intro to ABMs",
    "section": "Question",
    "text": "Question\nEarlier we said ABMs are complete, consistent and unambiguous.\nWhat have I left out of the definition of Conway’s Game of Life? (I.e. why is my description so far incomplete?)"
  },
  {
    "objectID": "lectures/intro-slides.html#question-1",
    "href": "lectures/intro-slides.html#question-1",
    "title": "Intro to ABMs",
    "section": "Question",
    "text": "Question\n\n\n\n\n\n\n\nAnswer\n\n\nThree very important things (at least):\n\nIs the lattice finite or infinite? If finite, then what happens at the boundaries? – It is infinite.\nAre the agents (the cells) updated synchronously (all at once) or asynchronously? – Synchronously.\nHow are a cell’s neighbours defined? – It’s the 8 cells surrounding it."
  },
  {
    "objectID": "lectures/intro-slides.html#exercise",
    "href": "lectures/intro-slides.html#exercise",
    "title": "Intro to ABMs",
    "section": "Exercise",
    "text": "Exercise\nWhat happens to the cells in A? What happens to those in B? (Black = live, white = dead)\n\n\nA\n\n\nB"
  },
  {
    "objectID": "lectures/intro-slides.html#exercise-1",
    "href": "lectures/intro-slides.html#exercise-1",
    "title": "Intro to ABMs",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nA is stable, B oscillates:\n\n\nA\n\n\nB"
  },
  {
    "objectID": "lectures/intro-slides.html#species",
    "href": "lectures/intro-slides.html#species",
    "title": "Intro to ABMs",
    "section": "Species",
    "text": "Species\nThe game supports many life forms (“species”), categorized into:1\n\n\n\nStill lifes, e.g.   \n\n\n\nOscillators, e.g.   \n\n\n\nSpaceships, e.g.  \n\n\n\nImages of Game of Life species from Wikimedia Commons (public domain)."
  },
  {
    "objectID": "lectures/intro-slides.html#emergence",
    "href": "lectures/intro-slides.html#emergence",
    "title": "Intro to ABMs",
    "section": "Emergence",
    "text": "Emergence\n\nThe game has simple rules, complex behaviour\nIt is undecidable: given a starting state S and a proposed other state O, we can prove that it is impossible to prove whether O will ever be reached from S!\nNew facts about the game are still being discovered: 2018 discovery of “knightships” (spaceships that move like the knight in chess)"
  },
  {
    "objectID": "lectures/intro-slides.html#example-2-flocking",
    "href": "lectures/intro-slides.html#example-2-flocking",
    "title": "Intro to ABMs",
    "section": "Example 2: Flocking",
    "text": "Example 2: Flocking"
  },
  {
    "objectID": "lectures/intro-slides.html#example-2-flocking-1",
    "href": "lectures/intro-slides.html#example-2-flocking-1",
    "title": "Intro to ABMs",
    "section": "Example 2: Flocking",
    "text": "Example 2: Flocking\n\nA simple model of the emergence of collective behaviour, flocking in birds1\nBirds follow three rules:\n\nCollision avoidance: maintain a minimum distance to other birds\nTracking: fly towards the average position of neighbouring birds\nNavigation: fly in the average direction of your neighbours\n\n\nReynolds (1987), and much research thereafter, importantly Vicsek et al. (1995) and subsequent."
  },
  {
    "objectID": "lectures/intro-slides.html#example-3-social-distancing",
    "href": "lectures/intro-slides.html#example-3-social-distancing",
    "title": "Intro to ABMs",
    "section": "Example 3: Social Distancing",
    "text": "Example 3: Social Distancing\n\nSIR (susceptible-infected-recovered) models are used to model epidemics, e.g. the spread of viruses1\nSuch models can be extended with aspects such as social distancing – implemented here as agents which remain stationary\nIn the following animations,\n\nblack dot = susceptible (healthy) individual\nred dot = infected individual\ngreen dot = recovered individual\n\n\nSee Vynnycky and White (2010) for an overview."
  },
  {
    "objectID": "lectures/intro-slides.html#bounded-rationality-locality",
    "href": "lectures/intro-slides.html#bounded-rationality-locality",
    "title": "Intro to ABMs",
    "section": "Bounded rationality / Locality",
    "text": "Bounded rationality / Locality\n\nCommon to all these examples is the following observation: the agents have bounded rationality\n\nIn Flocking, individual birds follow only three simple rules defined over the bird’s neighbours\nA bird does not know what flocking means, nor does it have a rule to accomplish flocking\nRather, flocking emerges as the collective behaviour of a group of birds\n\nIn other words, global patterns arise from numerous local interactions\nSimilar remarks apply to Game of Life and Social Distancing, indeed to any ABM"
  },
  {
    "objectID": "lectures/intro-slides.html#challenges-in-abm",
    "href": "lectures/intro-slides.html#challenges-in-abm",
    "title": "Intro to ABMs",
    "section": "Challenges in ABM",
    "text": "Challenges in ABM\n\nHow do we know what to model?\nHow do we test our models against empirical data?\nHow do we implement our models computationally?"
  },
  {
    "objectID": "lectures/intro-slides.html#challenges-of-computational-implementation",
    "href": "lectures/intro-slides.html#challenges-of-computational-implementation",
    "title": "Intro to ABMs",
    "section": "Challenges of computational implementation",
    "text": "Challenges of computational implementation\n\nSpeed: we want simulations to be fast\nRandomness: when our code calls for random numbers, we want them to be really random!\nCleanliness: we want our code to be understandable to other users\nReproducibility: when others run our code, they should get the same results we do"
  },
  {
    "objectID": "lectures/intro-slides.html#why-is-speed-an-issue",
    "href": "lectures/intro-slides.html#why-is-speed-an-issue",
    "title": "Intro to ABMs",
    "section": "Why is speed an issue?",
    "text": "Why is speed an issue?\n\nCentral processing units (CPUs) in modern computers carry out billions of instructions each second\nHowever, with ABMs, computational requirements may be significant, and may not scale nicely"
  },
  {
    "objectID": "lectures/intro-slides.html#exampleexercise",
    "href": "lectures/intro-slides.html#exampleexercise",
    "title": "Intro to ABMs",
    "section": "Example/Exercise",
    "text": "Example/Exercise\n\nAssume:\n\nYou have a model such that one simulation run, with a given set of parameter values, takes 1 minute to complete.\nYour model has 2 parameters, each of which can assume 100 different values.\nYou want to replicate the simulation for each parameter combination 100 times for statistical reasons.\n\nHow long will it take for your entire simulation to complete?"
  },
  {
    "objectID": "lectures/intro-slides.html#exampleexercise-1",
    "href": "lectures/intro-slides.html#exampleexercise-1",
    "title": "Intro to ABMs",
    "section": "Example/Exercise",
    "text": "Example/Exercise\n\n\n\n\n\n\n\nAnswer\n\n\n2 parameters with 100 values each results in 100 x 100 = 10,000 parameter combinations. Thus, in total, we have 100 x 10,000 = 1 million simulation runs to complete. If each run takes 1 minute, the total is 1 million minutes. This corresponds to roughly 2 years!"
  },
  {
    "objectID": "lectures/intro-slides.html#how-to-deal-with-issues-of-speed",
    "href": "lectures/intro-slides.html#how-to-deal-with-issues-of-speed",
    "title": "Intro to ABMs",
    "section": "How to deal with issues of speed",
    "text": "How to deal with issues of speed\n\nChoose a suitable programming language\nWrite performant code\nWhenever possible, parallelize your code\n\nThis means running it simultaneously across many CPUs/computers; we will see later how it’s done"
  },
  {
    "objectID": "lectures/intro-slides.html#why-is-randomness-needed",
    "href": "lectures/intro-slides.html#why-is-randomness-needed",
    "title": "Intro to ABMs",
    "section": "Why is randomness needed?",
    "text": "Why is randomness needed?\n\nQuite simple: real-world processes are complex, and to model such complex processes we resort to stochastic processes\nA stochastic process is a sequence of random variables\nFor example, consider a “navigating” agent that turns into a random direction whenever it doesn’t know how to proceed otherwise. In this case, the random direction needs to be generated using a random number.\nOr consider a linguistic example: suppose Mary is friends with Bob, Fiona and Charles. Unless we want to claim that Mary’s interactions with the other people are deterministic (which does not seem particularly sensible), we need some way of selecting interlocutors at random."
  },
  {
    "objectID": "lectures/intro-slides.html#why-is-randomness-an-issue",
    "href": "lectures/intro-slides.html#why-is-randomness-an-issue",
    "title": "Intro to ABMs",
    "section": "Why is randomness an issue?",
    "text": "Why is randomness an issue?\n\nConventional computers are deterministic devices\nSo, if we need, say, a random number between 0 and 1, how is that accomplished?\nThe answer is a pseudorandom number generator (PRNG)\n\nThis is an algorithm that generates a (long, but not infinite!) sequence of numbers which has the appearance of being random\nThe sequence is generated from a seed number. If you give the PRNG the same seed, you will get the same “random” sequence of numbers (this takes care of the reproducibility requirement).\nHowever, there are significant issues…"
  },
  {
    "objectID": "lectures/intro-slides.html#issues-with-prngs",
    "href": "lectures/intro-slides.html#issues-with-prngs",
    "title": "Intro to ABMs",
    "section": "Issues with PRNGs",
    "text": "Issues with PRNGs\n\nSuppose your PRNG generates a sequence of 1M numbers…\n…but in your simulation you need to generate 10M random numbers1\nThen your “random” numbers will repeat 10 times\nThis means that different parts of your simulation are not independent of each other – a major problem!\nFurther issues can arise when we look at parallel processing… but more on that later!\n\nWe’ll see later that this is by no means a crazy requirement!"
  },
  {
    "objectID": "lectures/intro-slides.html#summary",
    "href": "lectures/intro-slides.html#summary",
    "title": "Intro to ABMs",
    "section": "Summary",
    "text": "Summary\n\nABM is a powerful framework for modelling real-world processes\nModels are complete, consistent and unambiguous\nIndividual agents exhibit bounded rationality\nChallenges involve, among other things, simulation speed and proper implementation of randomness"
  },
  {
    "objectID": "lectures/intro-slides.html#the-scientific-community",
    "href": "lectures/intro-slides.html#the-scientific-community",
    "title": "Intro to ABMs",
    "section": "The scientific community",
    "text": "The scientific community\n\nABMs are created and explored by people in all manners of disciplines from physics and chemistry to linguistics and economics\nExamples of professional organisation in social sciences and linguistics:\n\nEuropean Social Simulation Association\nThe Journal of Artificial Societies and Social Simulation\nThe International Society for Computational Social Science (+IC2S2 conference)\nLanguage Dynamics and Change (journal)"
  },
  {
    "objectID": "lectures/intro-slides.html#homework",
    "href": "lectures/intro-slides.html#homework",
    "title": "Intro to ABMs",
    "section": "Homework",
    "text": "Homework\nNext week, we will begin programming. To prepare your computer for this, complete the homework “Installing Julia” on the course website."
  },
  {
    "objectID": "lectures/intro-slides.html#references",
    "href": "lectures/intro-slides.html#references",
    "title": "Intro to ABMs",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nGardner, Martin. 1970. “The Fantastic Combinations of John Conway’s New Solitaire Game ’Life’.” Scientific American 223 (4): 120–23. https://doi.org/10.1038/scientificamerican1070-120.\n\n\nGilbert, Nigel. 2020. Agent-Based Models. Second edition. London: SAGE.\n\n\nReynolds, Craig W. 1987. “Flocks, Herds and Schools: A Distributed Behavioral Model.” ACM SIGRAPH Computer Graphics 21 (4): 25–34. https://doi.org/10.1145/37402.37406.\n\n\nVicsek, Tamás, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. 1995. “Novel Type of Phase Transition in a System of Self-Driven Particles.” Physical Review Letters 75: 1226–29. https://doi.org/10.1103/PhysRevLett.75.1226.\n\n\nVynnycky, Emilia, and Richard G. White. 2010. An Introduction to Infectious Disease Modelling. Oxford: Oxford University Press."
  },
  {
    "objectID": "lectures/intro.html",
    "href": "lectures/intro.html",
    "title": "Intro to ABMs",
    "section": "",
    "text": "No rigorous definition (like most applied science)\nBut: can characterize as a model consisting of\n\nentities (the agents)…\n…which act1 upon each other…\n…in some kind of environment…\n…to create some emergent outcome\n\n“Emergent” = collective is more than the sum of its parts\nImplemented computationally, sometimes also analysed mathematically\n\n1 Eng. agent &lt; Lat. agens, pres. part. of ago ‘act’\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/intro.html#what-is-an-agent-based-model-abm",
    "href": "lectures/intro.html#what-is-an-agent-based-model-abm",
    "title": "Intro to ABMs",
    "section": "",
    "text": "No rigorous definition (like most applied science)\nBut: can characterize as a model consisting of\n\nentities (the agents)…\n…which act1 upon each other…\n…in some kind of environment…\n…to create some emergent outcome\n\n“Emergent” = collective is more than the sum of its parts\nImplemented computationally, sometimes also analysed mathematically\n\n1 Eng. agent &lt; Lat. agens, pres. part. of ago ‘act’"
  },
  {
    "objectID": "lectures/intro.html#what-is-the-benefit-of-abms-1",
    "href": "lectures/intro.html#what-is-the-benefit-of-abms-1",
    "title": "Intro to ABMs",
    "section": "What is the benefit of ABMs?",
    "text": "What is the benefit of ABMs?\n\n“Like equation-based modeling, but unlike prose, agent-based models must be complete, consistent, and unambiguous if they are to be capable of being executed on a computer” (Gilbert 2020, xii, my emphasis)\n\n\ncomplete: the modeller cannot leave anything out of the model description\nconsistent: no part of the model can logically contradict another part of the same model\nunambiguous: the meaning of every part of the model must be objectively clear"
  },
  {
    "objectID": "lectures/intro.html#examples",
    "href": "lectures/intro.html#examples",
    "title": "Intro to ABMs",
    "section": "Examples",
    "text": "Examples\nThese concepts are best explained through the use of examples…\n…so let’s look at a few!2\n2 The examples are taken from the Example Zoo of the Agents.jl package (released under the MIT license)."
  },
  {
    "objectID": "lectures/intro.html#example-1-conways-game-of-life",
    "href": "lectures/intro.html#example-1-conways-game-of-life",
    "title": "Intro to ABMs",
    "section": "Example 1: Conway’s Game of Life",
    "text": "Example 1: Conway’s Game of Life\n\nEarly example of a cellular automaton (Gardner 1970)\nLattice; each cell either “live” (L) or “dead” (D)\nRules:\n\n\n\n\nRule\nCell\nNeighbourhood\nResult\n\n\n\n\n“underpopulation”\nL\n&lt; 2 L cells\nL \\(\\to\\) D\n\n\n“sustenance”\nL\n2 or 3 L cells\nL \\(\\to\\) L\n\n\n“overpopulation”\nL\n&gt; 3 L cells\nL \\(\\to\\) D\n\n\n“reproduction”\nD\n3 L cells\nD \\(\\to\\) L"
  },
  {
    "objectID": "lectures/intro.html#question",
    "href": "lectures/intro.html#question",
    "title": "Intro to ABMs",
    "section": "Question",
    "text": "Question\nEarlier we said ABMs are complete, consistent and unambiguous.\nWhat have I left out of the definition of Conway’s Game of Life? (I.e. why is my description so far incomplete?)\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThree very important things (at least):\n\nIs the lattice finite or infinite? If finite, then what happens at the boundaries? – It is infinite.\nAre the agents (the cells) updated synchronously (all at once) or asynchronously? – Synchronously.\nHow are a cell’s neighbours defined? – It’s the 8 cells surrounding it."
  },
  {
    "objectID": "lectures/intro.html#exercise",
    "href": "lectures/intro.html#exercise",
    "title": "Intro to ABMs",
    "section": "Exercise",
    "text": "Exercise\nWhat happens to the cells in A? What happens to those in B? (Black = live, white = dead)\n\n\nA\n\n\nB\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA is stable, B oscillates:\n\n\nA\n\n\nB"
  },
  {
    "objectID": "lectures/intro.html#species",
    "href": "lectures/intro.html#species",
    "title": "Intro to ABMs",
    "section": "Species",
    "text": "Species\nThe game supports many life forms (“species”), categorized into:3\n3 Images of Game of Life species from Wikimedia Commons (public domain).\n\n\nStill lifes, e.g.   \n\n\n\nOscillators, e.g.   \n\n\n\nSpaceships, e.g."
  },
  {
    "objectID": "lectures/intro.html#emergence",
    "href": "lectures/intro.html#emergence",
    "title": "Intro to ABMs",
    "section": "Emergence",
    "text": "Emergence\n\nThe game has simple rules, complex behaviour\nIt is undecidable: given a starting state S and a proposed other state O, we can prove that it is impossible to prove whether O will ever be reached from S!\nNew facts about the game are still being discovered: 2018 discovery of “knightships” (spaceships that move like the knight in chess)"
  },
  {
    "objectID": "lectures/intro.html#example-2-flocking",
    "href": "lectures/intro.html#example-2-flocking",
    "title": "Intro to ABMs",
    "section": "Example 2: Flocking",
    "text": "Example 2: Flocking"
  },
  {
    "objectID": "lectures/intro.html#example-2-flocking-1",
    "href": "lectures/intro.html#example-2-flocking-1",
    "title": "Intro to ABMs",
    "section": "Example 2: Flocking",
    "text": "Example 2: Flocking\n\nA simple model of the emergence of collective behaviour, flocking in birds4\nBirds follow three rules:\n\nCollision avoidance: maintain a minimum distance to other birds\nTracking: fly towards the average position of neighbouring birds\nNavigation: fly in the average direction of your neighbours\n\n\n4 Reynolds (1987), and much research thereafter, importantly Vicsek et al. (1995) and subsequent."
  },
  {
    "objectID": "lectures/intro.html#example-3-social-distancing",
    "href": "lectures/intro.html#example-3-social-distancing",
    "title": "Intro to ABMs",
    "section": "Example 3: Social Distancing",
    "text": "Example 3: Social Distancing\n\nSIR (susceptible-infected-recovered) models are used to model epidemics, e.g. the spread of viruses5\nSuch models can be extended with aspects such as social distancing – implemented here as agents which remain stationary\nIn the following animations,\n\nblack dot = susceptible (healthy) individual\nred dot = infected individual\ngreen dot = recovered individual\n\n\n5 See Vynnycky and White (2010) for an overview."
  },
  {
    "objectID": "lectures/intro.html#bounded-rationality-locality",
    "href": "lectures/intro.html#bounded-rationality-locality",
    "title": "Intro to ABMs",
    "section": "Bounded rationality / Locality",
    "text": "Bounded rationality / Locality\n\nCommon to all these examples is the following observation: the agents have bounded rationality\n\nIn Flocking, individual birds follow only three simple rules defined over the bird’s neighbours\nA bird does not know what flocking means, nor does it have a rule to accomplish flocking\nRather, flocking emerges as the collective behaviour of a group of birds\n\nIn other words, global patterns arise from numerous local interactions\nSimilar remarks apply to Game of Life and Social Distancing, indeed to any ABM"
  },
  {
    "objectID": "lectures/intro.html#challenges-in-abm",
    "href": "lectures/intro.html#challenges-in-abm",
    "title": "Intro to ABMs",
    "section": "Challenges in ABM",
    "text": "Challenges in ABM\n\nHow do we know what to model?\nHow do we test our models against empirical data?\nHow do we implement our models computationally?"
  },
  {
    "objectID": "lectures/intro.html#challenges-of-computational-implementation",
    "href": "lectures/intro.html#challenges-of-computational-implementation",
    "title": "Intro to ABMs",
    "section": "Challenges of computational implementation",
    "text": "Challenges of computational implementation\n\nSpeed: we want simulations to be fast\nRandomness: when our code calls for random numbers, we want them to be really random!\nCleanliness: we want our code to be understandable to other users\nReproducibility: when others run our code, they should get the same results we do"
  },
  {
    "objectID": "lectures/intro.html#why-is-speed-an-issue",
    "href": "lectures/intro.html#why-is-speed-an-issue",
    "title": "Intro to ABMs",
    "section": "Why is speed an issue?",
    "text": "Why is speed an issue?\n\nCentral processing units (CPUs) in modern computers carry out billions of instructions each second\nHowever, with ABMs, computational requirements may be significant, and may not scale nicely"
  },
  {
    "objectID": "lectures/intro.html#exampleexercise",
    "href": "lectures/intro.html#exampleexercise",
    "title": "Intro to ABMs",
    "section": "Example/Exercise",
    "text": "Example/Exercise\n\nAssume:\n\nYou have a model such that one simulation run, with a given set of parameter values, takes 1 minute to complete.\nYour model has 2 parameters, each of which can assume 100 different values.\nYou want to replicate the simulation for each parameter combination 100 times for statistical reasons.\n\nHow long will it take for your entire simulation to complete?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n2 parameters with 100 values each results in 100 x 100 = 10,000 parameter combinations. Thus, in total, we have 100 x 10,000 = 1 million simulation runs to complete. If each run takes 1 minute, the total is 1 million minutes. This corresponds to roughly 2 years!"
  },
  {
    "objectID": "lectures/intro.html#how-to-deal-with-issues-of-speed",
    "href": "lectures/intro.html#how-to-deal-with-issues-of-speed",
    "title": "Intro to ABMs",
    "section": "How to deal with issues of speed",
    "text": "How to deal with issues of speed\n\nChoose a suitable programming language\nWrite performant code\nWhenever possible, parallelize your code\n\nThis means running it simultaneously across many CPUs/computers; we will see later how it’s done"
  },
  {
    "objectID": "lectures/intro.html#why-is-randomness-needed",
    "href": "lectures/intro.html#why-is-randomness-needed",
    "title": "Intro to ABMs",
    "section": "Why is randomness needed?",
    "text": "Why is randomness needed?\n\nQuite simple: real-world processes are complex, and to model such complex processes we resort to stochastic processes\nA stochastic process is a sequence of random variables\nFor example, consider a “navigating” agent that turns into a random direction whenever it doesn’t know how to proceed otherwise. In this case, the random direction needs to be generated using a random number.\nOr consider a linguistic example: suppose Mary is friends with Bob, Fiona and Charles. Unless we want to claim that Mary’s interactions with the other people are deterministic (which does not seem particularly sensible), we need some way of selecting interlocutors at random."
  },
  {
    "objectID": "lectures/intro.html#why-is-randomness-an-issue",
    "href": "lectures/intro.html#why-is-randomness-an-issue",
    "title": "Intro to ABMs",
    "section": "Why is randomness an issue?",
    "text": "Why is randomness an issue?\n\nConventional computers are deterministic devices\nSo, if we need, say, a random number between 0 and 1, how is that accomplished?\nThe answer is a pseudorandom number generator (PRNG)\n\nThis is an algorithm that generates a (long, but not infinite!) sequence of numbers which has the appearance of being random\nThe sequence is generated from a seed number. If you give the PRNG the same seed, you will get the same “random” sequence of numbers (this takes care of the reproducibility requirement).\nHowever, there are significant issues…"
  },
  {
    "objectID": "lectures/intro.html#issues-with-prngs",
    "href": "lectures/intro.html#issues-with-prngs",
    "title": "Intro to ABMs",
    "section": "Issues with PRNGs",
    "text": "Issues with PRNGs\n\nSuppose your PRNG generates a sequence of 1M numbers…\n…but in your simulation you need to generate 10M random numbers6\nThen your “random” numbers will repeat 10 times\nThis means that different parts of your simulation are not independent of each other – a major problem!\nFurther issues can arise when we look at parallel processing… but more on that later!\n\n6 We’ll see later that this is by no means a crazy requirement!"
  },
  {
    "objectID": "lectures/intro.html#summary",
    "href": "lectures/intro.html#summary",
    "title": "Intro to ABMs",
    "section": "Summary",
    "text": "Summary\n\nABM is a powerful framework for modelling real-world processes\nModels are complete, consistent and unambiguous\nIndividual agents exhibit bounded rationality\nChallenges involve, among other things, simulation speed and proper implementation of randomness"
  },
  {
    "objectID": "lectures/intro.html#the-scientific-community",
    "href": "lectures/intro.html#the-scientific-community",
    "title": "Intro to ABMs",
    "section": "The scientific community",
    "text": "The scientific community\n\nABMs are created and explored by people in all manners of disciplines from physics and chemistry to linguistics and economics\nExamples of professional organisation in social sciences and linguistics:\n\nEuropean Social Simulation Association\nThe Journal of Artificial Societies and Social Simulation\nThe International Society for Computational Social Science (+IC2S2 conference)\nLanguage Dynamics and Change (journal)"
  },
  {
    "objectID": "lectures/intro.html#homework",
    "href": "lectures/intro.html#homework",
    "title": "Intro to ABMs",
    "section": "Homework",
    "text": "Homework\nNext week, we will begin programming. To prepare your computer for this, complete the homework Installing Julia."
  },
  {
    "objectID": "lectures/structured-slides.html#plan",
    "href": "lectures/structured-slides.html#plan",
    "title": "Structured populations",
    "section": "Plan",
    "text": "Plan\n\nSo far, we have had agents interacting randomly\nWe did this by:\n\ninitializing a population, pop, using an array comprehension\nusing rand(pop) to sample random agents\nusing our own function interact! to make two agents interact\n\n\n\n\nToday: using Agents.jl to work with structured populations"
  },
  {
    "objectID": "lectures/structured-slides.html#positional-vs.-keyword-arguments",
    "href": "lectures/structured-slides.html#positional-vs.-keyword-arguments",
    "title": "Structured populations",
    "section": "Positional vs. keyword arguments",
    "text": "Positional vs. keyword arguments\n\nFirst, though, a technical remark about function arguments\nWe’ve seen function calls like this:\n\n\nplot(1:100, (1:100) .^ 2, seriestype = :scatter, color = :blue)\n\n\nHere,\n\n1:100 and (1:100) .^ 2 are positional arguments\nseriestype = :scatter and color = :blue are keyword arguments\n\nYou can swap the order of the latter but not of the former"
  },
  {
    "objectID": "lectures/structured-slides.html#positional-vs.-keyword-arguments-1",
    "href": "lectures/structured-slides.html#positional-vs.-keyword-arguments-1",
    "title": "Structured populations",
    "section": "Positional vs. keyword arguments",
    "text": "Positional vs. keyword arguments\n\nTo create keyword arguments in your own function, you separate the list of keyword and positional arguments with a semicolon (;):\n\n\nfunction my_fun(pos1, pos2; keyword1, keyword2)\n  ...\nend\n\n\nIf you don’t want any positional arguments, you have to write the following!\n\n\nfunction my_fun(; keyword1, keyword2)\n  ...\nend"
  },
  {
    "objectID": "lectures/structured-slides.html#positional-vs.-keyword-arguments-2",
    "href": "lectures/structured-slides.html#positional-vs.-keyword-arguments-2",
    "title": "Structured populations",
    "section": "Positional vs. keyword arguments",
    "text": "Positional vs. keyword arguments\n\nKeyword (but not positional) arguments can have default values:\n\n\nfunction my_fun(; firstname = \"John\", lastname)\n  println(firstname * \" \" * lastname)\nend\n\nmy_fun(firstname = \"Jane\", lastname = \"Doe\")\nmy_fun(lastname = \"Doe\")\n\nJane Doe\nJohn Doe"
  },
  {
    "objectID": "lectures/structured-slides.html#structured-populations",
    "href": "lectures/structured-slides.html#structured-populations",
    "title": "Structured populations",
    "section": "Structured populations",
    "text": "Structured populations\n\nI define a population to be structured whenever speakers do not interact fully at random\n\n\n\nFormally:\n\nlet \\(P(X)\\) = probability of sampling agent \\(X\\) for an interaction\nlet \\(P(Y \\mid X)\\) = (conditional) probability of sampling agent \\(Y\\), given that \\(X\\) was already sampled\nthen population is structured if \\(P(Y \\mid X) \\neq P(Y)\\)\n\n\n\n\n\nExample: \\(P(\\text{D. Trump} \\mid \\text{Henri}) = 0\\) even though \\(P(\\text{D. Trump}) &gt; 0\\)"
  },
  {
    "objectID": "lectures/structured-slides.html#implementation",
    "href": "lectures/structured-slides.html#implementation",
    "title": "Structured populations",
    "section": "Implementation",
    "text": "Implementation\n\nIt would be possible for us to write code for structured populations from scratch\nHowever, this would be more of an exercise in programming than in ABMs…\nWe’re better off, here, using code written by other people\nEnter the Agents.jl package, an ecosystem/framework for ABMs in Julia\nYou should already have Agents installed. If not, now’s the time to:\n\n\nusing Pkg\nPkg.add(\"Agents\")"
  },
  {
    "objectID": "lectures/structured-slides.html#agents.jl-basic-steps",
    "href": "lectures/structured-slides.html#agents.jl-basic-steps",
    "title": "Structured populations",
    "section": "Agents.jl basic steps",
    "text": "Agents.jl basic steps\n\nDecide on model space (e.g. social network)\nDefine agent type(s) (using special @agent keyword)\nDefine rules that evolve the model\nInitialize your model with AgentBasedModel\nEvolve, visualize and collect data\n\n\n\nThis may seem intimidating at first, but is really quite simple!\nLet’s walk through an example: variational learners in space"
  },
  {
    "objectID": "lectures/structured-slides.html#grid-space",
    "href": "lectures/structured-slides.html#grid-space",
    "title": "Structured populations",
    "section": "Grid space",
    "text": "Grid space\n\nFor this, we will reuse (with some modifications) our code for variational learners\nAnd assume that individual learners/agents occupy the nodes of a grid, also known as a two-dimensional regular lattice:\n\n\n\nPoint: interactions only occur along links in this grid"
  },
  {
    "objectID": "lectures/structured-slides.html#grid-space-implementation",
    "href": "lectures/structured-slides.html#grid-space-implementation",
    "title": "Structured populations",
    "section": "Grid space: implementation",
    "text": "Grid space: implementation\n\nTo implement this in Julia with Agents.jl:\n\n\ndims = (50, 50)\nspace = GridSpaceSingle(dims)\n\n\n\n(50, 50) is a data structure known as a tuple\nGridSpaceSingle comes from Agents.jl and defines a grid space in which each node can carry at most one agent (hence, Single)"
  },
  {
    "objectID": "lectures/structured-slides.html#aside-tuples-are-immutable",
    "href": "lectures/structured-slides.html#aside-tuples-are-immutable",
    "title": "Structured populations",
    "section": "Aside: tuples are immutable",
    "text": "Aside: tuples are immutable\n\narr = [10,20]\ntup = (10,20)\narr[1] = 30   # arr is now [30,20]\ntup[1] = 30   # throws an error\n\n\n\n\n\n\n\nNote\n\n\nWhen initializing a GridSpaceSingle, you must use a tuple!"
  },
  {
    "objectID": "lectures/structured-slides.html#agent-redefinition",
    "href": "lectures/structured-slides.html#agent-redefinition",
    "title": "Structured populations",
    "section": "Agent redefinition",
    "text": "Agent redefinition\n\nTo make use of the machinery provided by Agents.jl, we replace:\n\n\nmutable struct VariationalLearner\n  p::Float64\n  gamma::Float64\n  P1::Float64\n  P2::Float64\nend"
  },
  {
    "objectID": "lectures/structured-slides.html#agent-redefinition-1",
    "href": "lectures/structured-slides.html#agent-redefinition-1",
    "title": "Structured populations",
    "section": "Agent redefinition",
    "text": "Agent redefinition\n\nwith this:\n\n\n@agent struct VariationalLearner(GridAgent{2})\n  p::Float64\n  gamma::Float64\n  P1::Float64\n  P2::Float64\nend"
  },
  {
    "objectID": "lectures/structured-slides.html#agent-redefinition-2",
    "href": "lectures/structured-slides.html#agent-redefinition-2",
    "title": "Structured populations",
    "section": "Agent redefinition",
    "text": "Agent redefinition\n\n@agent struct VariationalLearner(GridAgent{2})\n  p::Float64\n  gamma::Float64\n  P1::Float64\n  P2::Float64\nend\n\n\n@agent is a special “macro” (more on these later) that introduces all agents in Agents.jl\nGridAgent{2} instructs Agents.jl that this agent is to be used in a 2-dimensional grid space"
  },
  {
    "objectID": "lectures/structured-slides.html#stepping-rule",
    "href": "lectures/structured-slides.html#stepping-rule",
    "title": "Structured populations",
    "section": "Stepping rule",
    "text": "Stepping rule\n\nWe next need a function that evolves i.e. steps the model\nThis is a function that takes a single agent and the model as arguments\nWe can make use of the interact! function we have already written:\n\n\nfunction VL_step!(agent, model)\n  interlocutor = random_nearby_agent(agent, model)\n  interact!(interlocutor, agent)\nend"
  },
  {
    "objectID": "lectures/structured-slides.html#model-initialization",
    "href": "lectures/structured-slides.html#model-initialization",
    "title": "Structured populations",
    "section": "Model initialization",
    "text": "Model initialization\n\nWe now have all the ingredients we need to initialize the ABM:\n\n\nmodel = StandardABM(VariationalLearner, space; \n                    agent_step! = VL_step!)\n\nStandardABM with 0 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest"
  },
  {
    "objectID": "lectures/structured-slides.html#model-initialization-1",
    "href": "lectures/structured-slides.html#model-initialization-1",
    "title": "Structured populations",
    "section": "Model initialization",
    "text": "Model initialization\n\nThis creates a sort of an “empty” container (it has no agents yet). To add agents, we call:\n\n\nadd_agent_single!(model; p = 0.1, gamma = 0.01, \n                  P1 = 0.4, P2 = 0.1)\n\nVariationalLearner(1, (4, 27), 0.1, 0.01, 0.4, 0.1)\n\n\n\nNote: the values of the agent’s internal fields (p, gamma etc.) are specified as keyword arguments!"
  },
  {
    "objectID": "lectures/structured-slides.html#model-initialization-2",
    "href": "lectures/structured-slides.html#model-initialization-2",
    "title": "Structured populations",
    "section": "Model initialization",
    "text": "Model initialization\n\nWe have a space of 50 x 50 = 2,500 nodes\nLet’s add 2,499 more agents:\n\n\nfor i in 1:2499\n  add_agent_single!(model; p = 0.1, gamma = 0.01, \n                    P1 = 0.4, P2 = 0.1)\nend\n\n\nCheck number of agents:\n\n\nnagents(model)\n\n2500"
  },
  {
    "objectID": "lectures/structured-slides.html#stepping-the-model",
    "href": "lectures/structured-slides.html#stepping-the-model",
    "title": "Structured populations",
    "section": "Stepping the model",
    "text": "Stepping the model\n\nStepping the model is now easy:\n\n\nstep!(model)\n\nStandardABM with 2500 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest\n\n\n\nOr, for a desired number of steps:\n\n\nstep!(model, 10)\n\nStandardABM with 2500 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest"
  },
  {
    "objectID": "lectures/structured-slides.html#stepping-the-model-1",
    "href": "lectures/structured-slides.html#stepping-the-model-1",
    "title": "Structured populations",
    "section": "Stepping the model",
    "text": "Stepping the model\n\n\n\n\n\n\nImportant\n\n\nStepping in Agents.jl is controlled by a so-called scheduler. You can decide which scheduler to use when initializing your model; for now, we will stick to the default scheduler.\nThis is important to know: when the default scheduler steps a model, every agent gets updated. In the case of our model, this means that every agent undergoes exactly one interaction as the “listening” party, i.e. every agent gets to learn from exactly one interaction during one time step."
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population",
    "href": "lectures/structured-slides.html#plotting-the-population",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nWith Agents.jl, we also have access to a number of functions that can be used for purposes of visualization\nabmplot(model) plots model in its current state. It has two return values:\n\nthe first one is the plot itself\nthe second one contains metadata which we usually don’t need to care about\n\nTo actually see the plot, you have to call the first return value explicitly:\n\n\nfig, meta = abmplot(model)\nfig"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-1",
    "href": "lectures/structured-slides.html#plotting-the-population-1",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-2",
    "href": "lectures/structured-slides.html#plotting-the-population-2",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nSo all we get is a purple square… what gives?\nThe problem is that we haven’t yet instructed abmplot how we want our model to be visualized\nWe could in principle be interested in plotting various kinds of things\nFor our model here, it makes sense to plot the value of p, i.e. each learner’s internal “grammatical state”\nThis is done with a function that maps an agent to its p"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-3",
    "href": "lectures/structured-slides.html#plotting-the-population-3",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nIn this case, the function is as simple as:\n\n\nfunction getp(a)\n  return a.p\nend\n\ngetp (generic function with 1 method)"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-4",
    "href": "lectures/structured-slides.html#plotting-the-population-4",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nWe now pass our getp function as the value of the agent_color keyword argument to abmplot:\n\n\nfig, meta = abmplot(model; agent_color = getp)\nfig"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-5",
    "href": "lectures/structured-slides.html#plotting-the-population-5",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nWe can see how the population changes as we evolve the model further (the new as keyword argument specifies the size of the dots that represent the agents):\n\n\nstep!(model, 1000)\nfig2, meta = abmplot(model; agent_color = getp, as = 12)\nfig2"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-6",
    "href": "lectures/structured-slides.html#plotting-the-population-6",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nAnd further:\n\n\nstep!(model, 1000)\nfig3, meta = abmplot(model; agent_color = getp, as = 12)\nfig3"
  },
  {
    "objectID": "lectures/structured-slides.html#plotting-the-population-7",
    "href": "lectures/structured-slides.html#plotting-the-population-7",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nMaking an animation/video allows us to visualize the evolution dynamically\nThis is achieved with the abmvideo function\n\n\nabmvideo(\"vid.mp4\", model; agent_color = getp, as = 12, \n         frames = 100, framerate = 10)"
  },
  {
    "objectID": "lectures/structured-slides.html#a-more-interesting-example",
    "href": "lectures/structured-slides.html#a-more-interesting-example",
    "title": "Structured populations",
    "section": "A more interesting example",
    "text": "A more interesting example\n\nAbove, we initialized the population so that everybody had p = 0.1 in the beginning\nWhat about the following: at time \\(t=0\\),\n\nthree people have p = 1 (uses \\(G_1\\) all the time),\nevery other person has p = 0 (uses \\(G_2\\) all the time)?\n\nWill we see \\(G_1\\) spread across the population?\nLet’s try!"
  },
  {
    "objectID": "lectures/structured-slides.html#a-more-interesting-example-1",
    "href": "lectures/structured-slides.html#a-more-interesting-example-1",
    "title": "Structured populations",
    "section": "A more interesting example",
    "text": "A more interesting example\n\nWe first reinitialize the model:\n\n\nspace2 = GridSpaceSingle((50, 50))\nmodel2 = StandardABM(VariationalLearner, space2;\n                     agent_step! = VL_step!)\n\nfor i in 1:3\n  add_agent_single!(model2; p = 1.0, gamma = 0.1, \n                    P1 = 0.4, P2 = 0.1)\nend\n\nfor i in 4:2500\n  add_agent_single!(model2; p = 0.0, gamma = 0.1, \n                    P1 = 0.4, P2 = 0.1)\nend"
  },
  {
    "objectID": "lectures/structured-slides.html#a-more-interesting-example-2",
    "href": "lectures/structured-slides.html#a-more-interesting-example-2",
    "title": "Structured populations",
    "section": "A more interesting example",
    "text": "A more interesting example\n\nVisualize initial state of population:\n\n\nfig, meta = abmplot(model2; agent_color = getp, as = 12)\nfig"
  },
  {
    "objectID": "lectures/structured-slides.html#a-more-interesting-example-3",
    "href": "lectures/structured-slides.html#a-more-interesting-example-3",
    "title": "Structured populations",
    "section": "A more interesting example",
    "text": "A more interesting example\n\nAnimate for 1,000 iterations (every agent gets to learn 1,000 times):\n\n\nabmvideo(\"interesting.mp4\", model2; agent_color = getp,\n         as = 12, frames = 1000, framerate = 20)"
  },
  {
    "objectID": "lectures/structured-slides.html#next-time",
    "href": "lectures/structured-slides.html#next-time",
    "title": "Structured populations",
    "section": "Next time",
    "text": "Next time\n\nSocial networks, and how to implement them in Agents.jl\nWrapping up some technical topics: modules, abstract types and inheritance"
  },
  {
    "objectID": "lectures/structured.html",
    "href": "lectures/structured.html",
    "title": "Structured populations",
    "section": "",
    "text": "Update 21 May 2024\n\n\n\nFixed definition of structured population. The correct definition is: a population is structured if \\(P(Y \\mid X) \\neq P(Y)\\).\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/structured.html#plan",
    "href": "lectures/structured.html#plan",
    "title": "Structured populations",
    "section": "Plan",
    "text": "Plan\n\nSo far, we have had agents interacting randomly\nWe did this by:\n\ninitializing a population, pop, using an array comprehension\nusing rand(pop) to sample random agents\nusing our own function interact! to make two agents interact\n\n\n\nToday: using Agents.jl to work with structured populations"
  },
  {
    "objectID": "lectures/structured.html#positional-vs.-keyword-arguments",
    "href": "lectures/structured.html#positional-vs.-keyword-arguments",
    "title": "Structured populations",
    "section": "Positional vs. keyword arguments",
    "text": "Positional vs. keyword arguments\n\nFirst, though, a technical remark about function arguments\nWe’ve seen function calls like this:\n\n\nplot(1:100, (1:100) .^ 2, seriestype = :scatter, color = :blue)\n\n\nHere,\n\n1:100 and (1:100) .^ 2 are positional arguments\nseriestype = :scatter and color = :blue are keyword arguments\n\nYou can swap the order of the latter but not of the former\n\n\nTo create keyword arguments in your own function, you separate the list of keyword and positional arguments with a semicolon (;):\n\n\nfunction my_fun(pos1, pos2; keyword1, keyword2)\n  ...\nend\n\n\nIf you don’t want any positional arguments, you have to write the following!\n\n\nfunction my_fun(; keyword1, keyword2)\n  ...\nend\n\n\nKeyword (but not positional) arguments can have default values:\n\n\nfunction my_fun(; firstname = \"John\", lastname)\n  println(firstname * \" \" * lastname)\nend\n\nmy_fun(firstname = \"Jane\", lastname = \"Doe\")\nmy_fun(lastname = \"Doe\")\n\nJane Doe\nJohn Doe"
  },
  {
    "objectID": "lectures/structured.html#structured-populations",
    "href": "lectures/structured.html#structured-populations",
    "title": "Structured populations",
    "section": "Structured populations",
    "text": "Structured populations\n\nI define a population to be structured whenever speakers do not interact fully at random\n\n\nFormally:\n\nlet \\(P(X)\\) = probability of sampling agent \\(X\\) for an interaction\nlet \\(P(Y \\mid X)\\) = (conditional) probability of sampling agent \\(Y\\), given that \\(X\\) was already sampled\nthen population is structured if \\(P(Y \\mid X) \\neq P(Y)\\)\n\n\n\nExample: \\(P(\\text{D. Trump} \\mid \\text{Henri}) = 0\\) even though \\(P(\\text{D. Trump}) &gt; 0\\)"
  },
  {
    "objectID": "lectures/structured.html#implementation",
    "href": "lectures/structured.html#implementation",
    "title": "Structured populations",
    "section": "Implementation",
    "text": "Implementation\n\nIt would be possible for us to write code for structured populations from scratch\nHowever, this would be more of an exercise in programming than in ABMs…\nWe’re better off, here, using code written by other people\nEnter the Agents.jl package, an ecosystem/framework for ABMs in Julia\nYou should already have Agents installed. If not, now’s the time to:\n\n\nusing Pkg\nPkg.add(\"Agents\")"
  },
  {
    "objectID": "lectures/structured.html#agents.jl-basic-steps",
    "href": "lectures/structured.html#agents.jl-basic-steps",
    "title": "Structured populations",
    "section": "Agents.jl basic steps",
    "text": "Agents.jl basic steps\n\nDecide on model space (e.g. social network)\nDefine agent type(s) (using special @agent keyword)\nDefine rules that evolve the model\nInitialize your model with AgentBasedModel\nEvolve, visualize and collect data\n\n\nThis may seem intimidating at first, but is really quite simple!\nLet’s walk through an example: variational learners in space"
  },
  {
    "objectID": "lectures/structured.html#grid-space",
    "href": "lectures/structured.html#grid-space",
    "title": "Structured populations",
    "section": "Grid space",
    "text": "Grid space\n\nFor this, we will reuse (with some modifications) our code for variational learners\nAnd assume that individual learners/agents occupy the nodes of a grid, also known as a two-dimensional regular lattice:\n\n\n\nPoint: interactions only occur along links in this grid"
  },
  {
    "objectID": "lectures/structured.html#grid-space-implementation",
    "href": "lectures/structured.html#grid-space-implementation",
    "title": "Structured populations",
    "section": "Grid space: implementation",
    "text": "Grid space: implementation\n\nTo implement this in Julia with Agents.jl:\n\n\ndims = (50, 50)\nspace = GridSpaceSingle(dims)\n\n\n(50, 50) is a data structure known as a tuple\nGridSpaceSingle comes from Agents.jl and defines a grid space in which each node can carry at most one agent (hence, Single)\n\n\n\n\n\n\n\nTuples and arrays\n\n\n\nTuples are similar to arrays. However, there are important differences. The most important of them is that arrays are mutable (the values of their elements can be changed after creation), while tuples are never mutable. Compare:\n\narr = [10,20]\ntup = (10,20)\narr[1] = 30   # arr is now [30,20]\ntup[1] = 30   # throws an error\n\nThe developers of Agents.jl have decided that the argument of GridSpaceSingle has to be a tuple (this decision makes sense in this case—as an immutable type, a tuple is more efficient than an array of similar size).\nIf you are running into errors trying to initialize a GridSpaceSingle, the problem is probably that you are trying to pass it the wrong type of argument. Compare:\n\nGridSpaceSingle([50, 50])   # trying to pass array; error\nGridSpaceSingle(50, 50)     # trying to pass two separate numbers; error\nGridSpaceSingle((50, 50))   # passing a tuple; works"
  },
  {
    "objectID": "lectures/structured.html#agent-redefinition",
    "href": "lectures/structured.html#agent-redefinition",
    "title": "Structured populations",
    "section": "Agent redefinition",
    "text": "Agent redefinition\n\nTo make use of the machinery provided by Agents.jl, we replace:\n\n\nmutable struct VariationalLearner\n  p::Float64\n  gamma::Float64\n  P1::Float64\n  P2::Float64\nend\n\n\nwith this:\n\n\n@agent struct VariationalLearner(GridAgent{2})\n  p::Float64\n  gamma::Float64\n  P1::Float64\n  P2::Float64\nend\n\n\n@agent is a special “macro” (more on these later) that introduces all agents in Agents.jl\nGridAgent{2} instructs Agents.jl that this agent is to be used in a 2-dimensional grid space"
  },
  {
    "objectID": "lectures/structured.html#stepping-rule",
    "href": "lectures/structured.html#stepping-rule",
    "title": "Structured populations",
    "section": "Stepping rule",
    "text": "Stepping rule\n\nWe next need a function that evolves i.e. steps the model\nThis is a function that takes a single agent and the model as arguments\nWe can make use of the interact! function we have already written:\n\n\nfunction VL_step!(agent, model)\n  interlocutor = random_nearby_agent(agent, model)\n  interact!(interlocutor, agent)\nend"
  },
  {
    "objectID": "lectures/structured.html#model-initialization",
    "href": "lectures/structured.html#model-initialization",
    "title": "Structured populations",
    "section": "Model initialization",
    "text": "Model initialization\n\nWe now have all the ingredients we need to initialize the ABM:\n\n\nmodel = StandardABM(VariationalLearner, space; \n                    agent_step! = VL_step!)\n\nStandardABM with 0 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest\n\n\nIn the above function call, you cannot write agent_step!=VL_step! (i.e. without spaces around the = sign). This is because, if you do so, Julia parses this as agent_step != VL_step!, which is not what we want.\nIn other words, when using keyword arguments with exclamation points in their names, make it a habit to separate the equals sign with spaces.\n\nThis creates a sort of an “empty” container (it has no agents yet). To add agents, we call:\n\n\nadd_agent_single!(model; p = 0.1, gamma = 0.01, \n                  P1 = 0.4, P2 = 0.1)\n\nVariationalLearner(1, (4, 27), 0.1, 0.01, 0.4, 0.1)\n\n\n\nNote: the values of the agent’s internal fields (p, gamma etc.) are specified as keyword arguments!\n\n\nWe have a space of 50 x 50 = 2,500 nodes\nLet’s add 2,499 more agents:\n\n\nfor i in 1:2499\n  add_agent_single!(model; p = 0.1, gamma = 0.01, \n                    P1 = 0.4, P2 = 0.1)\nend\n\n\nCheck number of agents:\n\n\nnagents(model)\n\n2500"
  },
  {
    "objectID": "lectures/structured.html#stepping-the-model",
    "href": "lectures/structured.html#stepping-the-model",
    "title": "Structured populations",
    "section": "Stepping the model",
    "text": "Stepping the model\n\nStepping the model is now easy:\n\n\nstep!(model)\n\nStandardABM with 2500 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest\n\n\n\nOr, for a desired number of steps:\n\n\nstep!(model, 10)\n\nStandardABM with 2500 agents of type VariationalLearner\n agents container: Dict\n space: GridSpaceSingle with size (50, 50), metric=chebyshev, periodic=true\n scheduler: fastest\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStepping in Agents.jl is controlled by a so-called scheduler. You can decide which scheduler to use when initializing your model; for now, we will stick to the default scheduler.\nThis is important to know: when the default scheduler steps a model, every agent gets updated. In the case of our model, this means that every agent undergoes exactly one interaction as the “listening” party, i.e. every agent gets to learn from exactly one interaction during one time step."
  },
  {
    "objectID": "lectures/structured.html#plotting-the-population",
    "href": "lectures/structured.html#plotting-the-population",
    "title": "Structured populations",
    "section": "Plotting the population",
    "text": "Plotting the population\n\nWith Agents.jl, we also have access to a number of functions that can be used for purposes of visualization\nabmplot(model) plots model in its current state. It has two return values:\n\nthe first one is the plot itself\nthe second one contains metadata which we usually don’t need to care about\n\nTo actually see the plot, you have to call the first return value explicitly:\n\n\nfig, meta = abmplot(model)\nfig\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/iRM0c/src/scenes.jl:220\n\n\n\n\n\n\n\n\n\n\nSo all we get is a purple square… what gives?\nThe problem is that we haven’t yet instructed abmplot how we want our model to be visualized\nWe could in principle be interested in plotting various kinds of things\nFor our model here, it makes sense to plot the value of p, i.e. each learner’s internal “grammatical state”\nThis is done with a function that maps an agent to its p\n\n\nIn this case, the function is as simple as:\n\n\nfunction getp(a)\n  return a.p\nend\n\ngetp (generic function with 1 method)\n\n\n\n\n\n\n\n\nTip\n\n\n\nJulia also allows one-liner function definitions. These are often useful when defining very simple functions, like getp. The equivalent one-liner definition here is:\n\ngetp(a) = a.p\n\ngetp (generic function with 1 method)\n\n\n\n\n\nWe now pass our getp function as the value of the agent_color keyword argument to abmplot:\n\n\nfig, meta = abmplot(model; agent_color = getp)\nfig\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/iRM0c/src/scenes.jl:220\n\n\n\n\n\n\n\n\n\n\nWe can see how the population changes as we evolve the model further (the new as keyword argument specifies the size of the dots that represent the agents):\n\n\nstep!(model, 1000)\nfig2, meta = abmplot(model; agent_color = getp, as = 12)\nfig2\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/iRM0c/src/scenes.jl:220\n┌ Warning: Keywords `as, am, ac` has been deprecated in favor of\n│           `agent_size, agent_marker, agent_color`\n└ @ AgentsVisualizations ~/.julia/packages/Agents/8JW8b/ext/AgentsVisualizations/src/abmplot.jl:70\n\n\n\n\n\n\n\n\n\n\nAnd further:\n\n\nstep!(model, 1000)\nfig3, meta = abmplot(model; agent_color = getp, as = 12)\nfig3\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/iRM0c/src/scenes.jl:220\n\n\n\n\n\n\n\n\n\n\nMaking an animation/video allows us to visualize the evolution dynamically\nThis is achieved with the abmvideo function\n\n\nabmvideo(\"vid.mp4\", model; agent_color = getp, as = 12, \n         frames = 100, framerate = 10)"
  },
  {
    "objectID": "lectures/structured.html#a-more-interesting-example",
    "href": "lectures/structured.html#a-more-interesting-example",
    "title": "Structured populations",
    "section": "A more interesting example",
    "text": "A more interesting example\n\nAbove, we initialized the population so that everybody had p = 0.1 in the beginning\nWhat about the following: at time \\(t=0\\),\n\nthree people have p = 1 (uses \\(G_1\\) all the time),\nevery other person has p = 0 (uses \\(G_2\\) all the time)?\n\nWill we see \\(G_1\\) spread across the population?\nLet’s try!\n\n\nWe first reinitialize the model:\n\n\nspace2 = GridSpaceSingle((50, 50))\nmodel2 = StandardABM(VariationalLearner, space2;\n                     agent_step! = VL_step!)\n\nfor i in 1:3\n  add_agent_single!(model2; p = 1.0, gamma = 0.1, \n                    P1 = 0.4, P2 = 0.1)\nend\n\nfor i in 4:2500\n  add_agent_single!(model2; p = 0.0, gamma = 0.1, \n                    P1 = 0.4, P2 = 0.1)\nend\n\n\n\n\n\n\n\nImportant\n\n\n\nHere it is important that we create a new space (I’ve called it space2). Otherwise Agents.jl would try to add agents to our old space, which is already full!\n\n\n\nVisualize initial state of population:\n\n\nfig, meta = abmplot(model2; agent_color = getp, as = 12)\nfig\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/iRM0c/src/scenes.jl:220\n\n\n\n\n\n\n\n\n\n\nAnimate for 1,000 iterations (every agent gets to learn 1,000 times):\n\n\nabmvideo(\"interesting.mp4\", model2; agent_color = getp,\n         as = 12, frames = 1000, framerate = 20)"
  },
  {
    "objectID": "lectures/structured.html#next-time",
    "href": "lectures/structured.html#next-time",
    "title": "Structured populations",
    "section": "Next time",
    "text": "Next time\n\nSocial networks, and how to implement them in Agents.jl\nWrapping up some technical topics: modules, abstract types and inheritance"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nSolution\n\n\n\n\n\n\n9 April 2024\n\n\nInstalling Julia\n\n\nN/A\n\n\n\n\n16 April 2024\n\n\nMaking birds fly\n\n\nHere\n\n\n\n\n23 April 2024\n\n\nVariational learning\n\n\nHere\n\n\n\n\n30 April 2024\n\n\nModules and packages\n\n\nHere\n\n\n\n\n7 May 2024\n\n\nLanguage change: parameter exploration\n\n\nHere\n\n\n\n\n14 May 2024\n\n\nThinking about your project\n\n\nN/A\n\n\n\n\n\nNo matching items\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/project.html",
    "href": "homework/project.html",
    "title": "Thinking about your project",
    "section": "",
    "text": "It’s time to start thinking about your programming project! You don’t need to start coding yet, but I want you to think carefully about all the following questions. Even better if you write down your answers (for your own benefit). :)\n\nWho am I going to work with? Or do I prefer to work on my own? Your team can be either 1 person (you work on your own) or 2 persons (you work with 1 friend), not larger.\nWhat phenomenon am I / are we interested in? What would I like to model? What sorts of things about language excite me that could potentially be approached using an ABM?\nOnce you have a broad answer to the previous question, try to narrow it down. Think about the following:\n\nCan I make use of code already written during the course (such as variational learning) to answer my question? Can I possibly extend that code, to make it better suited to what I’m interested in modelling?\nIf not, then can I still figure out how to implement what I need to implement in Julia code?\nCan I think of specific research questions or predictions? (Example: “Does the rate of language change depend on population size?”)\n\nIf you are working as part of a team, get together for a brainstorming!\nFinally, move on to thinking about the following specific implementation-level questions:\n\nWhat will be the agents in my model?\nWhat is the environment which the agents will occupy?\nHow will the agents interact with each other (e.g. randomly, or in some other way)?\nHow will I summarize the results of a simulation?\nHow many simulations will I need to run?\nHow will I communicate my results to my audience (numbers, plots, perhaps animations)?\n\n\nFor inspiration, read (at least) one paper from the readings/projects folder on ILIAS.\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/change.html",
    "href": "homework/change.html",
    "title": "Language change: parameter exploration",
    "section": "",
    "text": "Following the example set in the lecture, simulate a population of variational learners, obtaining the evolution (=history) of the average value of \\(p\\). Explore how variation in the following model parameters affects the population’s evolution. Use the Plots package to visualize your findings.\n\nN: population size, i.e. the number of agents\np: the initial value of \\(p\\). Set this to the same value for each learner.\nP1: probability of a string that only \\(G_1\\) can parse. Set this to the same value for each learner.\nP2: probability of a string that only \\(G_2\\) can parse. Set this to the same value for each learner.\ngamma: learning rate.\n\nFor the learning rate parameter, do both of the following:\n\nFirst, set gamma to the same value for each learner.\nIn a second set of simulations, initialize your population so that each learner gets a randomly chosen gamma from the interval between 0 and 1.\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/fly.html",
    "href": "homework/fly.html",
    "title": "Making birds fly",
    "section": "",
    "text": "Note\n\n\n\nIn addition to a working Julia installation, you will need the Plots package in order to complete this homework. Run the following commands to install and load it:\n\nusing Pkg\nPkg.add(\"Plots\")\nusing Plots\n\n\n\nIn this week’s lecture, you learned about custom types, functions and array comprehensions. In this homework, you get to put these concepts to practice.\nSpecifically, we will implement a version of the artificial birds that we saw in first week’s lecture’s flocking example. For now, however, we omit the collision avoidance, tracking and navigation rules and only concentrate on figuring out how to make the birds “fly”.\nYour task is to:\n\nWrite a custom type called Bird which has the following fields, each of them of type Float64:\n\nx, the bird’s location coordinate in the horizontal dimension\ny, the bird’s location coordinate in the vertical dimension\ndir_x, the bird’s direction (where its beak is pointing) in the horizontal dimension\ndir_y, the birds’ direction in the vertical dimension\n\nUse an array comprehension to make a population of Bird objects such that each bird gets a random location and random direction in both dimensions. Store this array in a variable named population.\nDownload this file and save it with the filename plot_birds.jl. Then run the following in Julia:\n\ninclude(\"plot_birds.jl\")\n\n(You may need to specify the whole path of the file in the above command if the file is not located in the same directory as your Julia session.)\n\n\n\n\n\n\nTip\n\n\n\nIf the above fails, you can also simply copy-paste the contents of plot_birds.jl into your own file.\n\n\nRun the following command:\n\nplot(population)\n\nThis will draw the bird’s positions and directions in a graphical plot.\nWrite a function called fly! which takes one argument – a Bird object – and makes this bird fly. In this context, to fly means to move x in the direction of dir_x by a little amount – let’s call that little amount delta – and to likewise move y in the direction of dir_y by the same amount. (You can make delta an argument of fly! if you want.)\n\n\n\n\n\n\nTip\n\n\n\nUse pen and paper to visually figure out how to update the x and y values of the Bird object. Use your imagination. Also note that there is no single “correct” answer as to how this function ought to be implemented. We will look at a few different possibilities in next week’s lecture.\n\n\nTest your function by calling it on a few birds in your population of birds. Then re-plot the population. Do the birds’ positions change as you’d expect?\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/installing-julia.html",
    "href": "homework/installing-julia.html",
    "title": "Installing Julia",
    "section": "",
    "text": "In this course, we will conduct all our programming work in the Julia programming language. This homework will guide you through the process of installing Julia on your computer. You will also be installing a few important packages (think of them as “add-ons” to the base Julia installation) that we will need later on. Finally, we will install an editor which will make dealing with source code a bit more convenient compared to just running Julia in a terminal window.\n\nNavigate to https://julialang.org, download the proper installation files for your operating system, and install Julia. Make sure to download version 1.10.2 or newer. (Older versions may not be fully compatible with the code we will be working with in this course.)\nWith installation complete, launch Julia. You should be greeted by a screen such as this:\n\nThis is known as the Julia REPL, which stands for read-eval(uate)-print loop. Here, you can give Julia commands, it will execute them, and you get the output back. For example, try the following commands:\n2+2\nsqrt(2)\n[1, 2, 3, 4]\nsum([1, 2, 3, 4])\nThe REPL can also be used to install packages i.e. extensions. We will now install two packages, Agents and CairoMakie, along with all their dependencies (i.e. further packages required to run those two packages). To do this, execute the following commands in the REPL:\nusing Pkg\nPkg.add(\"Agents\")\nPkg.add(\"CairoMakie\")\nThis will take a long while, as the two packages have many dependencies. Wait patiently. When everything is complete, you may exit the REPL:\nexit()\nIt would be very inconvenient to do all our coding in the REPL. It is much better to use a text editor or an IDE (integrated development environment). Here, you are free to make your own choice, if you already have a favourite editor for coding. For the purposes of this course, however, I recommend Visual Studio Code – this is the editor I will be using in the lectures, and so if you choose to use the same editor, things will be a bit smoother. To get started with VS Code, navigate to https://code.visualstudio.com/download, download the version for your operating system, and follow the instructions to install it.\nOnce VS Code has been successfully installed, we need to install a Julia extension for it. This will allow the editor to interface with your Julia installation, so that you will be able to execute code directly from the editor. Follow the instructions here, in bullet point number 3, to do this.\n\nIf all went well, you now have an up-to-date, working Julia installation, with a number of packages installed, plus a source code editor that interfaces seamlessly with that installation.\nIf something went wrong, try again. Google your problem to see if other users have already run into the same problem and have a solution. If it still refuses to work, bring your problem to the next lecture – we will discuss how to solve it and get you a working system.\n\nBonus\nIf you are already familiar with another programming language such as Python, I recommend you to watch this short video from IBM Technology detailing some of the major differences between Python and Julia. It does go into some technical details which may seem obscure for now (“dynamic typing”, “multiple dispatch”), but worry not – I will explain those concepts next week.\n\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/modules.html",
    "href": "homework/modules.html",
    "title": "Modules and packages",
    "section": "",
    "text": "Read the section on Modules and packages from the Introducing Julia WikiBook, and answer the following questions.\n\nWhat is the difference between using and import in Julia?\nWhen do you use include()?\nWhat does export do?\nFinally, put the code we have written so far for variational learning in a file, turning it into a module called VariationalLearning. Which composite types and which functions would you export?\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "homework/vl.html",
    "href": "homework/vl.html",
    "title": "Variational learning",
    "section": "",
    "text": "Simulate five variational learners for 1000 learning steps with learning rate \\(\\gamma = 0.01\\) in a learning environment characterized by the probabilities P1 = 0.4, P12 = 0.5 and P2 = 0.1 (these are the probabilities that were used in the lecture). Plot the five trajectories in the same plot.\n\n\n\n\n\n\nTip\n\n\n\nTo draw into an already existing plot, use plot!() instead of plot().\n\n\nRepeat the above exercise, but this time with five learners with \\(\\gamma = 0.001\\), and then with five learners with \\(\\gamma = 1\\).\nNow repeat both of the above points, but this time in an environment characterized by probabilities P1 = 0.1, P12 = 0.5 and P2 = 0.4.\nBased on your observations, what would you say is the effect of\n\nthe learning rate parameter?\nthe probabilities of occurrence of the different types of string?\n\nBy consulting the Plots.jl documentation, modify your trajectory plots so that\n\nthe trajectory is represented by points instead of lines\nthe x-axis is labelled “learning iteration”\nthe y-axis is labelled “probability of G1”\nthe plot title is “A variational learning trajectory”\n\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "Solutions to homework",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\n23 April 2024\n\n\nMaking birds fly\n\n\n\n\n30 April 2024\n\n\nVariational learning\n\n\n\n\n7 May 2024\n\n\nModules and packages\n\n\n\n\n14 May 2024\n\n\nLanguage change: parameter exploration\n\n\n\n\n\nNo matching items\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Agent-based modelling",
    "section": "",
    "text": "Welcome to this course on agent-based models (ABMs). Use the top bar to navigate.\nThis website is “alive” – it will update as the course progresses, with new lectures and homework added regularly.\nI strongly recommend that you do the homework. Doing ABMs requires programming, and the best (perhaps only?) way of learning programming is by actually doing some programming.\nI also recommend bringing your laptop, if you have one, to the lectures. We will be doing little programming exercises and explorations in most of the lectures, and it will benefit you if you can do these in real time.\nFinally, if you notice any errors or typos in the course materials, would you be so kind as to point them out to me either at lectures or via email (firstname lastname uni konstanz de). Thank you!\n– Henri\n\n\n\n\n\n\nAcknowledgements\n\n\n\n\n\nThese materials have benefitted immensely from the labours of the open source software movement. Thanks are due to the developers of Julia as well as to developers and contributors of the Agents.jl framework. Quarto made typesetting the materials a breeze – and fun.\n\n\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/change.html",
    "href": "lectures/change.html",
    "title": "Models of language change",
    "section": "",
    "text": "Up to now, we have implemented an agent that\n\nuses \\(G_1\\) with prob. \\(p\\) and \\(G_2\\) with prob. \\(1-p\\)\ncan produce strings from both grammars\ncan receive such strings produced by other agents and update the value of \\(p\\) correspondingly\n\nIt is now time to look more carefully what happens at the population level when multiple such agents interact\n\n\nIn last week’s homework, we encapsulated all our variational learning code in a module (download here)\nTo use this module, we call:1\n\n1 The first line makes Julia aware of the code, i.e. of the module definition. The second one then instructs Julia to use that module. The dot before the module name is required for complex reasons (simple answer: this is a module of our own making, not an “official” one).\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/change.html#plan",
    "href": "lectures/change.html#plan",
    "title": "Models of language change",
    "section": "",
    "text": "Up to now, we have implemented an agent that\n\nuses \\(G_1\\) with prob. \\(p\\) and \\(G_2\\) with prob. \\(1-p\\)\ncan produce strings from both grammars\ncan receive such strings produced by other agents and update the value of \\(p\\) correspondingly\n\nIt is now time to look more carefully what happens at the population level when multiple such agents interact\n\n\nIn last week’s homework, we encapsulated all our variational learning code in a module (download here)\nTo use this module, we call:1\n\n1 The first line makes Julia aware of the code, i.e. of the module definition. The second one then instructs Julia to use that module. The dot before the module name is required for complex reasons (simple answer: this is a module of our own making, not an “official” one).\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning"
  },
  {
    "objectID": "lectures/change.html#population-of-agents",
    "href": "lectures/change.html#population-of-agents",
    "title": "Models of language change",
    "section": "Population of agents",
    "text": "Population of agents\n\nLast time, we also saw how an array comprehension can be used to create a whole population of agents:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\n1000-element Vector{VariationalLearner}:\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n ⋮\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n\n\n\nWe also saw that the rand function can be used to pick random agents from the population:\n\n\nrand(pop)\n\nVariationalLearner(0.1, 0.01, 0.4, 0.1)\n\n\n\nWith an array comprehension, this allows us to undergo random interactions:\n\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n100-element Vector{Float64}:\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n ⋮\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.10900000000000001\n 0.099\n 0.099\n 0.09801\n 0.10900000000000001\n 0.099"
  },
  {
    "objectID": "lectures/change.html#exercise",
    "href": "lectures/change.html#exercise",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nWhat gets returned is an array of 100 numbers (100-element Vector{Float64}).\nWhat are these numbers, and where do they come from?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThey come from learn! via interact!.\nRecall that the last line of the learn! function returns the current (i.e. new, after learning) value of \\(p\\) of the learner:\n\nfunction learn!(x::VariationalLearner, s::String)\n  ...\n  return x.p\nend"
  },
  {
    "objectID": "lectures/change.html#summary-statistics",
    "href": "lectures/change.html#summary-statistics",
    "title": "Models of language change",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nBut this just gives us the current state of a random speaker\nThis is rarely the sort of information we wish to gather\nMore useful would be: average \\(p\\) over all agents in the population\nA quantity like this is known as a summary statistic – it summarizes the state of the entire population"
  },
  {
    "objectID": "lectures/change.html#getting-the-average",
    "href": "lectures/change.html#getting-the-average",
    "title": "Models of language change",
    "section": "Getting the average",
    "text": "Getting the average\n\nThe average, or mean, can be obtained using Julia’s mean function. This is part of the Statistics module:\n\n\nusing Statistics\nmy_vector = [1, 2, 3, 4, 5]\nmean(my_vector)\n\n3.0\n\n\n\nNote that you could also compute this “by hand”!\n\n\nsum(my_vector)/length(my_vector)\n\n3.0"
  },
  {
    "objectID": "lectures/change.html#average-p",
    "href": "lectures/change.html#average-p",
    "title": "Models of language change",
    "section": "Average \\(p\\)",
    "text": "Average \\(p\\)\n\nWith our population, we can’t just do:\n\n\nmean(pop)\n\n\nWhy? Well, mean takes the average over an array of numbers. But pop is not an array of numbers – it is an array of VariationalLearner objects. ☹️"
  },
  {
    "objectID": "lectures/change.html#exercise-2",
    "href": "lectures/change.html#exercise-2",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nHow can we obtain the average \\(p\\) over our pop object?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOnce again, the answer is an array comprehension!\n\nmean([speaker.p for speaker in pop])\n\n0.10006002999999991"
  },
  {
    "objectID": "lectures/change.html#average-p-1",
    "href": "lectures/change.html#average-p-1",
    "title": "Models of language change",
    "section": "Average \\(p\\)",
    "text": "Average \\(p\\)\n\nLet’s wrap this up as a function:\n\n\nfunction average_p(x::Array{VariationalLearner})\n  mean([speaker.p for speaker in x])\nend\n\naverage_p (generic function with 1 method)\n\n\n\nNote: the type of the argument is Array{VariationalLearner}, which means an array of elements all of which are VariationalLearners\n\n\nWe can now simply call:\n\n\naverage_p(pop)\n\n0.10006002999999991"
  },
  {
    "objectID": "lectures/change.html#interacting-and-summarizing",
    "href": "lectures/change.html#interacting-and-summarizing",
    "title": "Models of language change",
    "section": "Interacting and summarizing",
    "text": "Interacting and summarizing\n\nEarlier, we used this to evolve the population:\n\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n\nWhat if we also want to summarize, so that the resulting array stores the average \\(p\\) rather than the \\(p\\) of a random agent?\nProblem: array comprehension takes only a single command to the left of the for block\n\n\nSolution: a begin ... end block:\n\n\nhistory = [begin\n              interact!(rand(pop), rand(pop))\n              average_p(pop)\n           end for t in 1:100]\n\n100-element Vector{Float64}:\n 0.10002888999999995\n 0.10002788999999994\n 0.10002688999999994\n 0.10002588999999994\n 0.10003488999999995\n 0.10003388999999994\n 0.10003288999999996\n 0.10003188999999994\n 0.10003088999999994\n 0.10002989999999994\n 0.10002889999999993\n 0.10002790999999994\n 0.10002690999999994\n ⋮\n 0.10002051079999993\n 0.10001951079999995\n 0.10001851079999996\n 0.10001751079999996\n 0.10001651079999996\n 0.10002551079999997\n 0.10002451079999995\n 0.10002353069999995\n 0.10002253069999996\n 0.10002154069999997\n 0.10002054069999995\n 0.10001955069999996\n\n\n\nWe can finally evolve the population, recording its average state at every iteration, for as many iterations as we wish:2\n\n2 Here, the _ in the upper limit for t is a number separator. It just helps humans read the large number (here, a million); the compiler ignores it. You could also write 1000000 if you wish (but then I, for one, won’t be able to tell how many zeroes you have there!).\nhistory2 = [begin\n              interact!(rand(pop), rand(pop))\n              average_p(pop)\n            end for t in 1:1_000_000]\n\n\nLet’s plot the simulation history (i.e. the evolution of average \\(p\\) over time):\n\n\nusing Plots\nplot(1:1_000_000, history2, color=:black, legend=false)"
  },
  {
    "objectID": "lectures/change.html#free-tip",
    "href": "lectures/change.html#free-tip",
    "title": "Models of language change",
    "section": "Free tip",
    "text": "Free tip\n\nWe have plotted a million points here (and Plots also connects them with veeeeery tiny lines). This is a lot, and may slow your computer down.\nTo plot, say, every 1000th point, try:\n\n\nplot(1:1000:1_100_000, history2[begin:1000:end], color=:black, legend=false)"
  },
  {
    "objectID": "lectures/change.html#exercise-4",
    "href": "lectures/change.html#exercise-4",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nIn our simulation, we see the average value of \\(p\\) steadily going up with time. What do you predict will happen in the future, i.e. if we continued the simulation for, say, another million time steps?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe would expect the average to keep increasing, as the \\(p\\) of every speaker tends to increase over time. Why does it tend to keep increasing? Because of the way we initialized the model: we set the P1 and P2 values for each learner to 0.4 and 0.1, meaning that there is always more evidence for grammar \\(G_1\\) than for grammar \\(G_2\\).\nOf course, the average value of \\(p\\), just like each individual \\(p\\), cannot increase forever. They have a hard maximum at \\(p = 1\\), since probabilities cannot be greater than 1. In fact, the average \\(p\\) plateaus at 1, if we continue the simulation. (Try it!)"
  },
  {
    "objectID": "lectures/change.html#looking-at-individual-learners",
    "href": "lectures/change.html#looking-at-individual-learners",
    "title": "Models of language change",
    "section": "Looking at individual learners",
    "text": "Looking at individual learners\n\nWhat if, instead of summarizing the population, we want to look at the histories of individual learners?\nThis is also very easy, using two-dimensional array comprehensions.\nI will be using a much smaller population, for a much shorter simulation, for clarity:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:20]\nhistory = [interact!(rand(pop), l) for t in 1:100, l in pop]\n\n\nRead this as: for every time step t, for every learner l in the population, make a random speaker speak to l.\n\n\nThe result is a matrix (two-dimensional array), here of 100 rows and 20 columns:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:20]\nhistory = [interact!(rand(pop), l) for t in 1:100, l in pop]\n\n100×20 Matrix{Float64}:\n 0.099      0.109     0.099      0.099      …  0.099      0.099     0.109\n 0.09801    0.10791   0.09801    0.10801       0.09801    0.10801   0.10791\n 0.0970299  0.106831  0.0970299  0.10693       0.0970299  0.10693   0.106831\n 0.0960596  0.105763  0.0960596  0.105861      0.0960596  0.105861  0.105763\n 0.095099   0.104705  0.095099   0.104802      0.095099   0.114802  0.104705\n 0.094148   0.103658  0.094148   0.103754   …  0.094148   0.113654  0.103658\n 0.0932065  0.102621  0.0932065  0.102716      0.103207   0.112517  0.112621\n 0.0922745  0.101595  0.0922745  0.101689      0.102174   0.111392  0.111495\n 0.0913517  0.100579  0.0913517  0.100672      0.101153   0.110278  0.11038\n 0.0904382  0.109573  0.0904382  0.0996657     0.100141   0.119176  0.109276\n 0.0895338  0.108478  0.0895338  0.098669   …  0.10914    0.117984  0.108184\n 0.0986385  0.107393  0.0986385  0.0976823     0.108048   0.116804  0.107102\n 0.0976521  0.106319  0.0976521  0.0967055     0.106968   0.115636  0.106031\n ⋮                                          ⋱                       \n 0.0682832  0.12873   0.129221   0.100333      0.108478   0.177992  0.109783\n 0.0676004  0.127443  0.127929   0.0993302     0.107393   0.176212  0.108685\n 0.0669244  0.136168  0.12665    0.108337   …  0.106319   0.174449  0.107598\n 0.0662551  0.134807  0.125383   0.107253      0.105256   0.182705  0.106522\n 0.0655926  0.133459  0.124129   0.106181      0.104203   0.180878  0.105457\n 0.0649366  0.132124  0.122888   0.105119      0.103161   0.179069  0.114402\n 0.0642873  0.140803  0.121659   0.104068      0.102129   0.177278  0.113258\n 0.0636444  0.139395  0.130442   0.103027   …  0.101108   0.185506  0.112126\n 0.073008   0.138001  0.129138   0.101997      0.100097   0.193651  0.111005\n 0.0722779  0.136621  0.127847   0.100977      0.0990961  0.201714  0.119895\n 0.0715551  0.145255  0.126568   0.0999673     0.0981051  0.209697  0.118696\n 0.0708395  0.143802  0.125303   0.0989676     0.0971241  0.2176    0.127509\n\n\n\nEach column of the matrix represents the history of one learner\nplot() is rather clever and accepts the matrix as argument:\n\n\nplot(history)"
  },
  {
    "objectID": "lectures/change.html#homework",
    "href": "lectures/change.html#homework",
    "title": "Models of language change",
    "section": "Homework",
    "text": "Homework\n\nIn the homework, you get to replicate the above simulations (with the summary statistic of average \\(p\\)), exploring how variation in model parameters such as population size and learning rate affects the population’s evolution\nNext week:\n\nStructured populations (with the help of Agents.jl)\nInfo about the final projects"
  },
  {
    "objectID": "lectures/change-slides.html#plan",
    "href": "lectures/change-slides.html#plan",
    "title": "Models of language change",
    "section": "Plan",
    "text": "Plan\n\nUp to now, we have implemented an agent that\n\nuses \\(G_1\\) with prob. \\(p\\) and \\(G_2\\) with prob. \\(1-p\\)\ncan produce strings from both grammars\ncan receive such strings produced by other agents and update the value of \\(p\\) correspondingly\n\nIt is now time to look more carefully what happens at the population level when multiple such agents interact"
  },
  {
    "objectID": "lectures/change-slides.html#plan-1",
    "href": "lectures/change-slides.html#plan-1",
    "title": "Models of language change",
    "section": "Plan",
    "text": "Plan\n\nIn last week’s homework, we encapsulated all our variational learning code in a module (download here)\nTo use this module, we call:1\n\n\ninclude(\"VariationalLearning.jl\")\nusing .VariationalLearning\n\nThe first line makes Julia aware of the code, i.e. of the module definition. The second one then instructs Julia to use that module. The dot before the module name is required for complex reasons (simple answer: this is a module of our own making, not an “official” one)."
  },
  {
    "objectID": "lectures/change-slides.html#population-of-agents",
    "href": "lectures/change-slides.html#population-of-agents",
    "title": "Models of language change",
    "section": "Population of agents",
    "text": "Population of agents\n\nLast time, we also saw how an array comprehension can be used to create a whole population of agents:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:1000]\n\n1000-element Vector{VariationalLearner}:\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n ⋮\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)\n VariationalLearner(0.1, 0.01, 0.4, 0.1)"
  },
  {
    "objectID": "lectures/change-slides.html#population-of-agents-1",
    "href": "lectures/change-slides.html#population-of-agents-1",
    "title": "Models of language change",
    "section": "Population of agents",
    "text": "Population of agents\n\nWe also saw that the rand function can be used to pick random agents from the population:\n\n\nrand(pop)\n\nVariationalLearner(0.1, 0.01, 0.4, 0.1)"
  },
  {
    "objectID": "lectures/change-slides.html#population-of-agents-2",
    "href": "lectures/change-slides.html#population-of-agents-2",
    "title": "Models of language change",
    "section": "Population of agents",
    "text": "Population of agents\n\nWith an array comprehension, this allows us to undergo random interactions:\n\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n100-element Vector{Float64}:\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n ⋮\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.099\n 0.10900000000000001\n 0.099\n 0.099\n 0.09801\n 0.10900000000000001\n 0.099"
  },
  {
    "objectID": "lectures/change-slides.html#exercise",
    "href": "lectures/change-slides.html#exercise",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nWhat gets returned is an array of 100 numbers (100-element Vector{Float64}).\nWhat are these numbers, and where do they come from?"
  },
  {
    "objectID": "lectures/change-slides.html#exercise-1",
    "href": "lectures/change-slides.html#exercise-1",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nThey come from learn! via interact!.\nRecall that the last line of the learn! function returns the current (i.e. new, after learning) value of \\(p\\) of the learner:\n\nfunction learn!(x::VariationalLearner, s::String)\n  ...\n  return x.p\nend"
  },
  {
    "objectID": "lectures/change-slides.html#summary-statistics",
    "href": "lectures/change-slides.html#summary-statistics",
    "title": "Models of language change",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nBut this just gives us the current state of a random speaker\nThis is rarely the sort of information we wish to gather\nMore useful would be: average \\(p\\) over all agents in the population\nA quantity like this is known as a summary statistic – it summarizes the state of the entire population"
  },
  {
    "objectID": "lectures/change-slides.html#getting-the-average",
    "href": "lectures/change-slides.html#getting-the-average",
    "title": "Models of language change",
    "section": "Getting the average",
    "text": "Getting the average\n\nThe average, or mean, can be obtained using Julia’s mean function. This is part of the Statistics module:\n\n\nusing Statistics\nmy_vector = [1, 2, 3, 4, 5]\nmean(my_vector)\n\n3.0\n\n\n\nNote that you could also compute this “by hand”!\n\n\nsum(my_vector)/length(my_vector)\n\n3.0"
  },
  {
    "objectID": "lectures/change-slides.html#average-p",
    "href": "lectures/change-slides.html#average-p",
    "title": "Models of language change",
    "section": "Average \\(p\\)",
    "text": "Average \\(p\\)\n\nWith our population, we can’t just do:\n\n\nmean(pop)\n\n\nWhy? Well, mean takes the average over an array of numbers. But pop is not an array of numbers – it is an array of VariationalLearner objects. ☹️"
  },
  {
    "objectID": "lectures/change-slides.html#exercise-2",
    "href": "lectures/change-slides.html#exercise-2",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nHow can we obtain the average \\(p\\) over our pop object?"
  },
  {
    "objectID": "lectures/change-slides.html#exercise-3",
    "href": "lectures/change-slides.html#exercise-3",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nOnce again, the answer is an array comprehension!\n\nmean([speaker.p for speaker in pop])\n\n0.10006002999999991"
  },
  {
    "objectID": "lectures/change-slides.html#average-p-1",
    "href": "lectures/change-slides.html#average-p-1",
    "title": "Models of language change",
    "section": "Average \\(p\\)",
    "text": "Average \\(p\\)\n\nLet’s wrap this up as a function:\n\n\nfunction average_p(x::Array{VariationalLearner})\n  mean([speaker.p for speaker in x])\nend\n\naverage_p (generic function with 1 method)\n\n\n\nNote: the type of the argument is Array{VariationalLearner}, which means an array of elements all of which are VariationalLearners"
  },
  {
    "objectID": "lectures/change-slides.html#average-p-2",
    "href": "lectures/change-slides.html#average-p-2",
    "title": "Models of language change",
    "section": "Average \\(p\\)",
    "text": "Average \\(p\\)\n\nWe can now simply call:\n\n\naverage_p(pop)\n\n0.10006002999999991"
  },
  {
    "objectID": "lectures/change-slides.html#interacting-and-summarizing",
    "href": "lectures/change-slides.html#interacting-and-summarizing",
    "title": "Models of language change",
    "section": "Interacting and summarizing",
    "text": "Interacting and summarizing\n\nEarlier, we used this to evolve the population:\n\n\n[interact!(rand(pop), rand(pop)) for t in 1:100]\n\n\nWhat if we also want to summarize, so that the resulting array stores the average \\(p\\) rather than the \\(p\\) of a random agent?\nProblem: array comprehension takes only a single command to the left of the for block"
  },
  {
    "objectID": "lectures/change-slides.html#interacting-and-summarizing-1",
    "href": "lectures/change-slides.html#interacting-and-summarizing-1",
    "title": "Models of language change",
    "section": "Interacting and summarizing",
    "text": "Interacting and summarizing\n\nSolution: a begin ... end block:\n\n\nhistory = [begin\n              interact!(rand(pop), rand(pop))\n              average_p(pop)\n           end for t in 1:100]\n\n100-element Vector{Float64}:\n 0.10002888999999995\n 0.10002788999999994\n 0.10002688999999994\n 0.10002588999999994\n 0.10003488999999995\n 0.10003388999999994\n 0.10003288999999996\n 0.10003188999999994\n 0.10003088999999994\n 0.10002989999999994\n 0.10002889999999993\n 0.10002790999999994\n 0.10002690999999994\n ⋮\n 0.10002051079999993\n 0.10001951079999995\n 0.10001851079999996\n 0.10001751079999996\n 0.10001651079999996\n 0.10002551079999997\n 0.10002451079999995\n 0.10002353069999995\n 0.10002253069999996\n 0.10002154069999997\n 0.10002054069999995\n 0.10001955069999996"
  },
  {
    "objectID": "lectures/change-slides.html#interacting-and-summarizing-2",
    "href": "lectures/change-slides.html#interacting-and-summarizing-2",
    "title": "Models of language change",
    "section": "Interacting and summarizing",
    "text": "Interacting and summarizing\n\nWe can finally evolve the population, recording its average state at every iteration, for as many iterations as we wish:1\n\n\nhistory2 = [begin\n              interact!(rand(pop), rand(pop))\n              average_p(pop)\n            end for t in 1:1_000_000]\n\nHere, the _ in the upper limit for t is a number separator. It just helps humans read the large number (here, a million); the compiler ignores it. You could also write 1000000 if you wish (but then I, for one, won’t be able to tell how many zeroes you have there!)."
  },
  {
    "objectID": "lectures/change-slides.html#interacting-and-summarizing-3",
    "href": "lectures/change-slides.html#interacting-and-summarizing-3",
    "title": "Models of language change",
    "section": "Interacting and summarizing",
    "text": "Interacting and summarizing\n\nLet’s plot the simulation history (i.e. the evolution of average \\(p\\) over time):\n\n\nusing Plots\nplot(1:1_000_000, history2, color=:black, legend=false)"
  },
  {
    "objectID": "lectures/change-slides.html#free-tip",
    "href": "lectures/change-slides.html#free-tip",
    "title": "Models of language change",
    "section": "Free tip",
    "text": "Free tip\n\nWe have plotted a million points here (and Plots also connects them with veeeeery tiny lines). This is a lot, and may slow your computer down.\nTo plot, say, every 1000th point, try:\n\n\nplot(1:1000:1_100_000, history2[begin:1000:end], color=:black, legend=false)"
  },
  {
    "objectID": "lectures/change-slides.html#exercise-4",
    "href": "lectures/change-slides.html#exercise-4",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\nIn our simulation, we see the average value of \\(p\\) steadily going up with time. What do you predict will happen in the future, i.e. if we continued the simulation for, say, another million time steps?"
  },
  {
    "objectID": "lectures/change-slides.html#exercise-5",
    "href": "lectures/change-slides.html#exercise-5",
    "title": "Models of language change",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nWe would expect the average to keep increasing, as the \\(p\\) of every speaker tends to increase over time. Why does it tend to keep increasing? Because of the way we initialized the model: we set the P1 and P2 values for each learner to 0.4 and 0.1, meaning that there is always more evidence for grammar \\(G_1\\) than for grammar \\(G_2\\).\nOf course, the average value of \\(p\\), just like each individual \\(p\\), cannot increase forever. They have a hard maximum at \\(p = 1\\), since probabilities cannot be greater than 1. In fact, the average \\(p\\) plateaus at 1, if we continue the simulation. (Try it!)"
  },
  {
    "objectID": "lectures/change-slides.html#looking-at-individual-learners",
    "href": "lectures/change-slides.html#looking-at-individual-learners",
    "title": "Models of language change",
    "section": "Looking at individual learners",
    "text": "Looking at individual learners\n\nWhat if, instead of summarizing the population, we want to look at the histories of individual learners?\nThis is also very easy, using two-dimensional array comprehensions.\nI will be using a much smaller population, for a much shorter simulation, for clarity:"
  },
  {
    "objectID": "lectures/change-slides.html#looking-at-individual-learners-1",
    "href": "lectures/change-slides.html#looking-at-individual-learners-1",
    "title": "Models of language change",
    "section": "Looking at individual learners",
    "text": "Looking at individual learners\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:20]\nhistory = [interact!(rand(pop), l) for t in 1:100, l in pop]\n\n\nRead this as: for every time step t, for every learner l in the population, make a random speaker speak to l."
  },
  {
    "objectID": "lectures/change-slides.html#looking-at-individual-learners-2",
    "href": "lectures/change-slides.html#looking-at-individual-learners-2",
    "title": "Models of language change",
    "section": "Looking at individual learners",
    "text": "Looking at individual learners\n\nThe result is a matrix (two-dimensional array), here of 100 rows and 20 columns:\n\n\npop = [VariationalLearner(0.1, 0.01, 0.4, 0.1) for i in 1:20]\nhistory = [interact!(rand(pop), l) for t in 1:100, l in pop]\n\n100×20 Matrix{Float64}:\n 0.099      0.109     0.099      0.099      …  0.099      0.099     0.109\n 0.09801    0.10791   0.09801    0.10801       0.09801    0.10801   0.10791\n 0.0970299  0.106831  0.0970299  0.10693       0.0970299  0.10693   0.106831\n 0.0960596  0.105763  0.0960596  0.105861      0.0960596  0.105861  0.105763\n 0.095099   0.104705  0.095099   0.104802      0.095099   0.114802  0.104705\n 0.094148   0.103658  0.094148   0.103754   …  0.094148   0.113654  0.103658\n 0.0932065  0.102621  0.0932065  0.102716      0.103207   0.112517  0.112621\n 0.0922745  0.101595  0.0922745  0.101689      0.102174   0.111392  0.111495\n 0.0913517  0.100579  0.0913517  0.100672      0.101153   0.110278  0.11038\n 0.0904382  0.109573  0.0904382  0.0996657     0.100141   0.119176  0.109276\n 0.0895338  0.108478  0.0895338  0.098669   …  0.10914    0.117984  0.108184\n 0.0986385  0.107393  0.0986385  0.0976823     0.108048   0.116804  0.107102\n 0.0976521  0.106319  0.0976521  0.0967055     0.106968   0.115636  0.106031\n ⋮                                          ⋱                       \n 0.0682832  0.12873   0.129221   0.100333      0.108478   0.177992  0.109783\n 0.0676004  0.127443  0.127929   0.0993302     0.107393   0.176212  0.108685\n 0.0669244  0.136168  0.12665    0.108337   …  0.106319   0.174449  0.107598\n 0.0662551  0.134807  0.125383   0.107253      0.105256   0.182705  0.106522\n 0.0655926  0.133459  0.124129   0.106181      0.104203   0.180878  0.105457\n 0.0649366  0.132124  0.122888   0.105119      0.103161   0.179069  0.114402\n 0.0642873  0.140803  0.121659   0.104068      0.102129   0.177278  0.113258\n 0.0636444  0.139395  0.130442   0.103027   …  0.101108   0.185506  0.112126\n 0.073008   0.138001  0.129138   0.101997      0.100097   0.193651  0.111005\n 0.0722779  0.136621  0.127847   0.100977      0.0990961  0.201714  0.119895\n 0.0715551  0.145255  0.126568   0.0999673     0.0981051  0.209697  0.118696\n 0.0708395  0.143802  0.125303   0.0989676     0.0971241  0.2176    0.127509"
  },
  {
    "objectID": "lectures/change-slides.html#looking-at-individual-learners-3",
    "href": "lectures/change-slides.html#looking-at-individual-learners-3",
    "title": "Models of language change",
    "section": "Looking at individual learners",
    "text": "Looking at individual learners\n\nEach column of the matrix represents the history of one learner\nplot() is rather clever and accepts the matrix as argument:\n\n\nplot(history)"
  },
  {
    "objectID": "lectures/change-slides.html#homework",
    "href": "lectures/change-slides.html#homework",
    "title": "Models of language change",
    "section": "Homework",
    "text": "Homework\n\nIn the homework, you get to replicate the above simulations (with the summary statistic of average \\(p\\)), exploring how variation in model parameters such as population size and learning rate affects the population’s evolution\nNext week:\n\nStructured populations (with the help of Agents.jl)\nInfo about the final projects"
  },
  {
    "objectID": "lectures/learning.html",
    "href": "lectures/learning.html",
    "title": "A model of language learning",
    "section": "",
    "text": "Update 7 May 2024\n\n\n\nFixed bug in the learn! function so that learning also occurs on strings in the intersection \\(L_1 \\cap L_2\\) of the two languages.\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/learning.html#plan",
    "href": "lectures/learning.html#plan",
    "title": "A model of language learning",
    "section": "Plan",
    "text": "Plan\n\nStarting this week, we will put programming to good use\nWe’ll start with a simple model of language learning\n\nHere, learning = process of updating a linguistic representation\nDoesn’t matter whether child or adult"
  },
  {
    "objectID": "lectures/learning.html#grammar-competition",
    "href": "lectures/learning.html#grammar-competition",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nAssume two grammars \\(G_1\\) and \\(G_2\\) that generate languages \\(L_1\\) and \\(L_2\\)\n\nlanguage = set of strings (e.g. sentences)\n\nIn general, \\(L_1\\) and \\(L_2\\) will be different but may overlap:"
  },
  {
    "objectID": "lectures/learning.html#grammar-competition-1",
    "href": "lectures/learning.html#grammar-competition-1",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nThree sets of interest: \\(L_1 \\setminus L_2\\), \\(L_1 \\cap L_2\\) and \\(L_2 \\setminus L_1\\)"
  },
  {
    "objectID": "lectures/learning.html#concrete-example",
    "href": "lectures/learning.html#concrete-example",
    "title": "A model of language learning",
    "section": "Concrete example",
    "text": "Concrete example\n\nSVO (\\(G_1\\)) vs. V2 (\\(G_2\\))"
  },
  {
    "objectID": "lectures/learning.html#grammar-competition-4",
    "href": "lectures/learning.html#grammar-competition-4",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nSuppose learner receives randomly chosen strings from \\(L_1\\) and \\(L_2\\)\nLearner uses either \\(G_1\\) or \\(G_2\\) to parse incoming string\nDefine \\(p =\\) probability of use of \\(G_1\\)\nHow should the learner update \\(p\\) in response to interactions with his/her environment?"
  },
  {
    "objectID": "lectures/learning.html#variational-learning",
    "href": "lectures/learning.html#variational-learning",
    "title": "A model of language learning",
    "section": "Variational learning",
    "text": "Variational learning\n\nSuppose learner receives string/sentence \\(s\\)\nThen update is:\n\n\n\n\nLearner’s grammar\nString received\nUpdate\n\n\n\n\n\\(G_1\\)\n\\(s \\in L_1\\)\nincrease \\(p\\)\n\n\n\\(G_1\\)\n\\(s \\in L_2 \\setminus L_1\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_2\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_1 \\setminus L_2\\)\nincrease \\(p\\)"
  },
  {
    "objectID": "lectures/learning.html#exercise",
    "href": "lectures/learning.html#exercise",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\nHow can we increase/decrease \\(p\\) in practice? What is the update formula?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOne possibility (which we will stick to):\n\nIncrease: \\(p\\) becomes \\(p + \\gamma (1 - p)\\)\nDecrease: \\(p\\) becomes \\(p - \\gamma p\\)\n\nThe parameter \\(0 &lt; \\gamma &lt; 1\\) is a learning rate"
  },
  {
    "objectID": "lectures/learning.html#why-this-form-of-update-formula",
    "href": "lectures/learning.html#why-this-form-of-update-formula",
    "title": "A model of language learning",
    "section": "Why this form of update formula?",
    "text": "Why this form of update formula?\n\nNeed to make sure that always \\(0 \\leq p \\leq 1\\) (it is a probability)\nAlso notice:\n\nWhen \\(p\\) is increased, what is added is \\(\\gamma (1-p)\\). Since \\(1-p\\) is the probability of \\(G_2\\), this means transferring an amount of the probability mass of \\(G_2\\) onto \\(G_1\\).\nWhen \\(p\\) is decreased, what is removed is \\(\\gamma p\\). Since \\(p\\) is the probability of \\(G_1\\), this means transferring an amount of the probability mass of \\(G_1\\) onto \\(G_2\\).\nLearning rate \\(\\gamma\\) determines how much probability mass is transferred."
  },
  {
    "objectID": "lectures/learning.html#plan-1",
    "href": "lectures/learning.html#plan-1",
    "title": "A model of language learning",
    "section": "Plan",
    "text": "Plan\n\nTo implement a variational learner computationally, we need:\n\nA representation of a learner who embodies a single probability, \\(p\\), and a learning rate, \\(\\gamma\\)\nA way to sample strings from \\(L_1 \\setminus L_2\\) and from \\(L_2 \\setminus L_1\\)\nA function that updates the learner’s \\(p\\)\n\nLet’s attempt this now!"
  },
  {
    "objectID": "lectures/learning.html#the-struct",
    "href": "lectures/learning.html#the-struct",
    "title": "A model of language learning",
    "section": "The struct",
    "text": "The struct\n\nThe first point is very easy:\n\n\nmutable struct VariationalLearner\n  p::Float64\n  gamma::Float64\nend"
  },
  {
    "objectID": "lectures/learning.html#sampling-strings",
    "href": "lectures/learning.html#sampling-strings",
    "title": "A model of language learning",
    "section": "Sampling strings",
    "text": "Sampling strings\n\nFor the second point, note we have three types of strings which occur with three corresponding probabilities\nLet’s refer to the string types as \"S1\", \"S12\" and \"S2\", and to the probabilities as P1, P12 and P2:\n\n\n\n\nString type\nProbability\nExplanation\n\n\n\n\n\"S1\"\nP1\n\\(s \\in L_1 \\setminus L_2\\)\n\n\n\"S12\"\nP12\n\\(s \\in L_1 \\cap L_2\\)\n\n\n\"S2\"\nP2\n\\(s \\in L_2 \\setminus L_1\\)\n\n\n\n\nIn Julia, sampling from a finite number of options (here, three string types) with corresponding probabilities is handled by a function called sample() which lives in the StatsBase package\nFirst, install and load the package:\n\n\nusing Pkg\nPkg.add(\"StatsBase\")\nusing StatsBase\n\nNow to sample a string, you can do the following:\n\n# the three probabilities (just some numbers I invented)\nP1 = 0.4\nP12 = 0.5\nP2 = 0.1\n\n# sample one string\nsample([\"S1\", \"S12\", \"S2\"], Weights([P1, P12, P2]))\n\n\"S12\""
  },
  {
    "objectID": "lectures/learning.html#tidying-up",
    "href": "lectures/learning.html#tidying-up",
    "title": "A model of language learning",
    "section": "Tidying up",
    "text": "Tidying up\n\nThe above works but is a bit cumbersome – for example, every time you want to sample a string, you need to refer to the three probabilities\nLet’s carry out a bit of software engineering to make this nicer to use\nFirst, we encapsulate the probabilities in a struct of their own:\n\n\nstruct LearningEnvironment\n  P1::Float64\n  P12::Float64\n  P2::Float64\nend\n\n\nWe then define the following function:\n\n\nfunction sample_string(x::LearningEnvironment)\n  sample([\"S1\", \"S12\", \"S2\"], Weights([x.P1, x.P12, x.P2]))\nend\n\nsample_string (generic function with 1 method)\n\n\n\nTest the function:\n\n\nparis = LearningEnvironment(0.4, 0.5, 0.1)\nsample_string(paris)\n\n\"S12\""
  },
  {
    "objectID": "lectures/learning.html#implementing-learning",
    "href": "lectures/learning.html#implementing-learning",
    "title": "A model of language learning",
    "section": "Implementing learning",
    "text": "Implementing learning\n\nWe now need to tackle point 3, the learning function which updates the learner’s state\nThis needs to do three things:\n\nSample a string from the learning environment\nPick a grammar to try and parse the string with\nUpdate \\(p\\) in response to whether parsing was successful or not"
  },
  {
    "objectID": "lectures/learning.html#exercise-2",
    "href": "lectures/learning.html#exercise-2",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\nHow would you implement point 2, i.e. picking a grammar to try and parse the incoming string?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can again use the sample() function from StatsBase, and define:\n\nfunction pick_grammar(x::VariationalLearner)\n  sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\nend\n\npick_grammar (generic function with 1 method)"
  },
  {
    "objectID": "lectures/learning.html#implementing-learning-1",
    "href": "lectures/learning.html#implementing-learning-1",
    "title": "A model of language learning",
    "section": "Implementing learning",
    "text": "Implementing learning\n\nNow it is easy to implement the first two points of the learning function:\n\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\nend\n\nlearn! (generic function with 1 method)\n\n\n\nHow to implement the last point, i.e. updating \\(p\\)?"
  },
  {
    "objectID": "lectures/learning.html#aside-conditional-statements",
    "href": "lectures/learning.html#aside-conditional-statements",
    "title": "A model of language learning",
    "section": "Aside: conditional statements",
    "text": "Aside: conditional statements\n\nHere, we will be helped by conditionals:\n\n\nif COND1\n  # this is executed if COND1 is true\nelseif COND2\n  # this is executed if COND1 is false but COND2 is true\nelse\n  # this is executed otherwise\nend\n\n\nNote: only the if block is necessary; elseif and else are optional, and there may be more than one elseif block"
  },
  {
    "objectID": "lectures/learning.html#aside-conditional-statements-1",
    "href": "lectures/learning.html#aside-conditional-statements-1",
    "title": "A model of language learning",
    "section": "Aside: conditional statements",
    "text": "Aside: conditional statements\n\nTry this for different values of number:\n\n\nnumber = 1\n\nif number &gt; 0\n  println(\"Your number is positive!\")\nelseif number &lt; 0\n  println(\"Your number is negative!\")\nelse\n  println(\"Your number is zero!\")\nend"
  },
  {
    "objectID": "lectures/learning.html#comparison-neq-assignment",
    "href": "lectures/learning.html#comparison-neq-assignment",
    "title": "A model of language learning",
    "section": "Comparison \\(\\neq\\) assignment",
    "text": "Comparison \\(\\neq\\) assignment\n\n\n\n\n\n\nImportant\n\n\n\nTo compare equality of two values inside a condition, you must use a double equals sign, ==. This is because the single equals sign, =, is already reserved for assigning values to variables.\n\nif 0 = 1    # throws an error!\n  println(\"The world is topsy-turvy\")\nend\n\nif 0 == 1   # works as expected\n  println(\"The world is topsy-turvy\")\nend"
  },
  {
    "objectID": "lectures/learning.html#exercise-4",
    "href": "lectures/learning.html#exercise-4",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\nUse an if ... elseif ... else ... end block to finish off our learn! function\nTip: logical “and” is &&, logical “or” is ||\nRecall:\n\n\n\n\nLearner’s grammar\nString received\nUpdate\n\n\n\n\n\\(G_1\\)\n\\(s \\in L_1\\)\nincrease \\(p\\)\n\n\n\\(G_1\\)\n\\(s \\in L_2 \\setminus L_1\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_2\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_1 \\setminus L_2\\)\nincrease \\(p\\)\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nImportant! The following function, which we originally used, has a bug! It does not update the learner’s state with input strings from \\(L_1 \\cap L_2\\). See below for fixed version.\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\n\n  if g == \"G1\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\nlearn! (generic function with 1 method)"
  },
  {
    "objectID": "lectures/learning.html#testing-our-code",
    "href": "lectures/learning.html#testing-our-code",
    "title": "A model of language learning",
    "section": "Testing our code",
    "text": "Testing our code\n\nLet’s test our code!\n\n\nbob = VariationalLearner(0.5, 0.01)\nparis = LearningEnvironment(0.4, 0.5, 0.1)\n\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\n\n0.51489901495\n\n\n\ntrajectory = [learn!(bob, paris) for t in 1:1000]\n\n1000-element Vector{Float64}:\n 0.5097500248005\n 0.514652524552495\n 0.5195059993069701\n 0.5143109393139004\n 0.5191678299207614\n 0.5239761516215538\n 0.5287363901053382\n 0.5334490262042848\n 0.5381145359422419\n 0.5327333905828194\n 0.5374060566769913\n 0.5420319961102213\n 0.5466116761491191\n ⋮\n 0.8043883364948524\n 0.7963444531299039\n 0.7983810085986048\n 0.7903971985126188\n 0.7924932265274927\n 0.7945682942622178\n 0.7966226113195956\n 0.7986563852063996\n 0.7906698213543356\n 0.7927631231407922\n 0.7948354919093843\n 0.7968871369902905"
  },
  {
    "objectID": "lectures/learning.html#plotting-the-learning-trajectory",
    "href": "lectures/learning.html#plotting-the-learning-trajectory",
    "title": "A model of language learning",
    "section": "Plotting the learning trajectory",
    "text": "Plotting the learning trajectory\n\nusing Plots\nplot(1:1000, trajectory)"
  },
  {
    "objectID": "lectures/learning.html#bibliographical-remarks",
    "href": "lectures/learning.html#bibliographical-remarks",
    "title": "A model of language learning",
    "section": "Bibliographical remarks",
    "text": "Bibliographical remarks\n\nFor more about the notion of grammar competition, see Kroch (1989), Kroch (1994)\nVariational learner originally from Yang (2000), Yang (2002)\nLearning algorithm itself is old: Bush and Mosteller (1955)"
  },
  {
    "objectID": "lectures/learning.html#summary",
    "href": "lectures/learning.html#summary",
    "title": "A model of language learning",
    "section": "Summary",
    "text": "Summary\n\nYou’ve learned a few important concepts today:\n\nGrammar competition and variational learning\nHow to sample objects according to a discrete probability distribution\nHow to use conditional statements\nHow to make a simple plot of a learning trajectory\n\nYou get to practice these in the homework\nNext week, we’ll take the model to a new level and consider what happens when several variational learners interact"
  },
  {
    "objectID": "lectures/learning-slides.html#plan",
    "href": "lectures/learning-slides.html#plan",
    "title": "A model of language learning",
    "section": "Plan",
    "text": "Plan\n\nStarting this week, we will put programming to good use\nWe’ll start with a simple model of language learning\n\nHere, learning = process of updating a linguistic representation\nDoesn’t matter whether child or adult"
  },
  {
    "objectID": "lectures/learning-slides.html#grammar-competition",
    "href": "lectures/learning-slides.html#grammar-competition",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nAssume two grammars \\(G_1\\) and \\(G_2\\) that generate languages \\(L_1\\) and \\(L_2\\)\n\nlanguage = set of strings (e.g. sentences)\n\nIn general, \\(L_1\\) and \\(L_2\\) will be different but may overlap:"
  },
  {
    "objectID": "lectures/learning-slides.html#grammar-competition-1",
    "href": "lectures/learning-slides.html#grammar-competition-1",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nThree sets of interest: \\(L_1 \\setminus L_2\\), \\(L_1 \\cap L_2\\) and \\(L_2 \\setminus L_1\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#grammar-competition-2",
    "href": "lectures/learning-slides.html#grammar-competition-2",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nThree sets of interest: \\(L_1 \\setminus L_2\\), \\(L_1 \\cap L_2\\) and \\(L_2 \\setminus L_1\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#grammar-competition-3",
    "href": "lectures/learning-slides.html#grammar-competition-3",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nThree sets of interest: \\(L_1 \\setminus L_2\\), \\(L_1 \\cap L_2\\) and \\(L_2 \\setminus L_1\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#concrete-example",
    "href": "lectures/learning-slides.html#concrete-example",
    "title": "A model of language learning",
    "section": "Concrete example",
    "text": "Concrete example\n\nSVO (\\(G_1\\)) vs. V2 (\\(G_2\\))"
  },
  {
    "objectID": "lectures/learning-slides.html#grammar-competition-4",
    "href": "lectures/learning-slides.html#grammar-competition-4",
    "title": "A model of language learning",
    "section": "Grammar competition",
    "text": "Grammar competition\n\nSuppose learner receives randomly chosen strings from \\(L_1\\) and \\(L_2\\)\nLearner uses either \\(G_1\\) or \\(G_2\\) to parse incoming string\nDefine \\(p =\\) probability of use of \\(G_1\\)\nHow should the learner update \\(p\\) in response to interactions with his/her environment?"
  },
  {
    "objectID": "lectures/learning-slides.html#variational-learning",
    "href": "lectures/learning-slides.html#variational-learning",
    "title": "A model of language learning",
    "section": "Variational learning",
    "text": "Variational learning\n\nSuppose learner receives string/sentence \\(s\\)\nThen update is:\n\n\n\n\nLearner’s grammar\nString received\nUpdate\n\n\n\n\n\\(G_1\\)\n\\(s \\in L_1\\)\nincrease \\(p\\)\n\n\n\\(G_1\\)\n\\(s \\in L_2 \\setminus L_1\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_2\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_1 \\setminus L_2\\)\nincrease \\(p\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise",
    "href": "lectures/learning-slides.html#exercise",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\nHow can we increase/decrease \\(p\\) in practice? What is the update formula?"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-1",
    "href": "lectures/learning-slides.html#exercise-1",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nOne possibility (which we will stick to):\n\nIncrease: \\(p\\) becomes \\(p + \\gamma (1 - p)\\)\nDecrease: \\(p\\) becomes \\(p - \\gamma p\\)\n\nThe parameter \\(0 &lt; \\gamma &lt; 1\\) is a learning rate"
  },
  {
    "objectID": "lectures/learning-slides.html#why-this-form-of-update-formula",
    "href": "lectures/learning-slides.html#why-this-form-of-update-formula",
    "title": "A model of language learning",
    "section": "Why this form of update formula?",
    "text": "Why this form of update formula?\n\nNeed to make sure that always \\(0 \\leq p \\leq 1\\) (it is a probability)\nAlso notice:\n\nWhen \\(p\\) is increased, what is added is \\(\\gamma (1-p)\\). Since \\(1-p\\) is the probability of \\(G_2\\), this means transferring an amount of the probability mass of \\(G_2\\) onto \\(G_1\\).\nWhen \\(p\\) is decreased, what is removed is \\(\\gamma p\\). Since \\(p\\) is the probability of \\(G_1\\), this means transferring an amount of the probability mass of \\(G_1\\) onto \\(G_2\\).\nLearning rate \\(\\gamma\\) determines how much probability mass is transferred."
  },
  {
    "objectID": "lectures/learning-slides.html#plan-1",
    "href": "lectures/learning-slides.html#plan-1",
    "title": "A model of language learning",
    "section": "Plan",
    "text": "Plan\n\nTo implement a variational learner computationally, we need:\n\nA representation of a learner who embodies a single probability, \\(p\\), and a learning rate, \\(\\gamma\\)\nA way to sample strings from \\(L_1 \\setminus L_2\\) and from \\(L_2 \\setminus L_1\\)\nA function that updates the learner’s \\(p\\)\n\nLet’s attempt this now!"
  },
  {
    "objectID": "lectures/learning-slides.html#the-struct",
    "href": "lectures/learning-slides.html#the-struct",
    "title": "A model of language learning",
    "section": "The struct",
    "text": "The struct\n\nThe first point is very easy:\n\n\nmutable struct VariationalLearner\n  p::Float64\n  gamma::Float64\nend"
  },
  {
    "objectID": "lectures/learning-slides.html#sampling-strings",
    "href": "lectures/learning-slides.html#sampling-strings",
    "title": "A model of language learning",
    "section": "Sampling strings",
    "text": "Sampling strings\n\nFor the second point, note we have three types of strings which occur with three corresponding probabilities\nLet’s refer to the string types as \"S1\", \"S12\" and \"S2\", and to the probabilities as P1, P12 and P2:\n\n\n\n\nString type\nProbability\nExplanation\n\n\n\n\n\"S1\"\nP1\n\\(s \\in L_1 \\setminus L_2\\)\n\n\n\"S12\"\nP12\n\\(s \\in L_1 \\cap L_2\\)\n\n\n\"S2\"\nP2\n\\(s \\in L_2 \\setminus L_1\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#sampling-strings-1",
    "href": "lectures/learning-slides.html#sampling-strings-1",
    "title": "A model of language learning",
    "section": "Sampling strings",
    "text": "Sampling strings\n\nIn Julia, sampling from a finite number of options (here, three string types) with corresponding probabilities is handled by a function called sample() which lives in the StatsBase package\nFirst, install and load the package:\n\n\nusing Pkg\nPkg.add(\"StatsBase\")\nusing StatsBase"
  },
  {
    "objectID": "lectures/learning-slides.html#sampling-strings-2",
    "href": "lectures/learning-slides.html#sampling-strings-2",
    "title": "A model of language learning",
    "section": "Sampling strings",
    "text": "Sampling strings\nNow to sample a string, you can do the following:\n\n# the three probabilities (just some numbers I invented)\nP1 = 0.4\nP12 = 0.5\nP2 = 0.1\n\n# sample one string\nsample([\"S1\", \"S12\", \"S2\"], Weights([P1, P12, P2]))\n\n\"S12\""
  },
  {
    "objectID": "lectures/learning-slides.html#tidying-up",
    "href": "lectures/learning-slides.html#tidying-up",
    "title": "A model of language learning",
    "section": "Tidying up",
    "text": "Tidying up\n\nThe above works but is a bit cumbersome – for example, every time you want to sample a string, you need to refer to the three probabilities\nLet’s carry out a bit of software engineering to make this nicer to use\nFirst, we encapsulate the probabilities in a struct of their own:\n\n\nstruct LearningEnvironment\n  P1::Float64\n  P12::Float64\n  P2::Float64\nend"
  },
  {
    "objectID": "lectures/learning-slides.html#tidying-up-1",
    "href": "lectures/learning-slides.html#tidying-up-1",
    "title": "A model of language learning",
    "section": "Tidying up",
    "text": "Tidying up\n\nWe then define the following function:\n\n\nfunction sample_string(x::LearningEnvironment)\n  sample([\"S1\", \"S12\", \"S2\"], Weights([x.P1, x.P12, x.P2]))\nend\n\nsample_string (generic function with 1 method)\n\n\n\nTest the function:\n\n\nparis = LearningEnvironment(0.4, 0.5, 0.1)\nsample_string(paris)\n\n\"S12\""
  },
  {
    "objectID": "lectures/learning-slides.html#implementing-learning",
    "href": "lectures/learning-slides.html#implementing-learning",
    "title": "A model of language learning",
    "section": "Implementing learning",
    "text": "Implementing learning\n\nWe now need to tackle point 3, the learning function which updates the learner’s state\nThis needs to do three things:\n\nSample a string from the learning environment\nPick a grammar to try and parse the string with\nUpdate \\(p\\) in response to whether parsing was successful or not"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-2",
    "href": "lectures/learning-slides.html#exercise-2",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\nHow would you implement point 2, i.e. picking a grammar to try and parse the incoming string?"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-3",
    "href": "lectures/learning-slides.html#exercise-3",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nWe can again use the sample() function from StatsBase, and define:\n\nfunction pick_grammar(x::VariationalLearner)\n  sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\nend\n\npick_grammar (generic function with 1 method)"
  },
  {
    "objectID": "lectures/learning-slides.html#implementing-learning-1",
    "href": "lectures/learning-slides.html#implementing-learning-1",
    "title": "A model of language learning",
    "section": "Implementing learning",
    "text": "Implementing learning\n\nNow it is easy to implement the first two points of the learning function:\n\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\nend\n\nlearn! (generic function with 1 method)\n\n\n\nHow to implement the last point, i.e. updating \\(p\\)?"
  },
  {
    "objectID": "lectures/learning-slides.html#aside-conditional-statements",
    "href": "lectures/learning-slides.html#aside-conditional-statements",
    "title": "A model of language learning",
    "section": "Aside: conditional statements",
    "text": "Aside: conditional statements\n\nHere, we will be helped by conditionals:\n\n\nif COND1\n  # this is executed if COND1 is true\nelseif COND2\n  # this is executed if COND1 is false but COND2 is true\nelse\n  # this is executed otherwise\nend\n\n\nNote: only the if block is necessary; elseif and else are optional, and there may be more than one elseif block"
  },
  {
    "objectID": "lectures/learning-slides.html#aside-conditional-statements-1",
    "href": "lectures/learning-slides.html#aside-conditional-statements-1",
    "title": "A model of language learning",
    "section": "Aside: conditional statements",
    "text": "Aside: conditional statements\n\nTry this for different values of number:\n\n\nnumber = 1\n\nif number &gt; 0\n  println(\"Your number is positive!\")\nelseif number &lt; 0\n  println(\"Your number is negative!\")\nelse\n  println(\"Your number is zero!\")\nend"
  },
  {
    "objectID": "lectures/learning-slides.html#comparison-neq-assignment",
    "href": "lectures/learning-slides.html#comparison-neq-assignment",
    "title": "A model of language learning",
    "section": "Comparison \\(\\neq\\) assignment",
    "text": "Comparison \\(\\neq\\) assignment\n\n\n\n\n\n\nImportant\n\n\nTo compare equality of two values inside a condition, you must use a double equals sign, ==. This is because the single equals sign, =, is already reserved for assigning values to variables.\n\nif 0 = 1    # throws an error!\n  println(\"The world is topsy-turvy\")\nend\n\nif 0 == 1   # works as expected\n  println(\"The world is topsy-turvy\")\nend"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-4",
    "href": "lectures/learning-slides.html#exercise-4",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\nUse an if ... elseif ... else ... end block to finish off our learn! function\nTip: logical “and” is &&, logical “or” is ||\nRecall:\n\n\n\n\nLearner’s grammar\nString received\nUpdate\n\n\n\n\n\\(G_1\\)\n\\(s \\in L_1\\)\nincrease \\(p\\)\n\n\n\\(G_1\\)\n\\(s \\in L_2 \\setminus L_1\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_2\\)\ndecrease \\(p\\)\n\n\n\\(G_2\\)\n\\(s \\in L_1 \\setminus L_2\\)\nincrease \\(p\\)"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-5",
    "href": "lectures/learning-slides.html#exercise-5",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\nImportant! The following function, which we originally used, has a bug! It does not update the learner’s state with input strings from \\(L_1 \\cap L_2\\). See below for fixed version.\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\n\n  if g == \"G1\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend"
  },
  {
    "objectID": "lectures/learning-slides.html#exercise-6",
    "href": "lectures/learning-slides.html#exercise-6",
    "title": "A model of language learning",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\n\nAnswer\n\n\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\nlearn! (generic function with 1 method)"
  },
  {
    "objectID": "lectures/learning-slides.html#testing-our-code",
    "href": "lectures/learning-slides.html#testing-our-code",
    "title": "A model of language learning",
    "section": "Testing our code",
    "text": "Testing our code\n\nLet’s test our code!\n\n\nbob = VariationalLearner(0.5, 0.01)\nparis = LearningEnvironment(0.4, 0.5, 0.1)\n\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\nlearn!(bob, paris)\n\n0.51489901495"
  },
  {
    "objectID": "lectures/learning-slides.html#testing-our-code-1",
    "href": "lectures/learning-slides.html#testing-our-code-1",
    "title": "A model of language learning",
    "section": "Testing our code",
    "text": "Testing our code\n\ntrajectory = [learn!(bob, paris) for t in 1:1000]\n\n1000-element Vector{Float64}:\n 0.5097500248005\n 0.514652524552495\n 0.5195059993069701\n 0.5143109393139004\n 0.5191678299207614\n 0.5239761516215538\n 0.5287363901053382\n 0.5334490262042848\n 0.5381145359422419\n 0.5327333905828194\n 0.5374060566769913\n 0.5420319961102213\n 0.5466116761491191\n ⋮\n 0.8043883364948524\n 0.7963444531299039\n 0.7983810085986048\n 0.7903971985126188\n 0.7924932265274927\n 0.7945682942622178\n 0.7966226113195956\n 0.7986563852063996\n 0.7906698213543356\n 0.7927631231407922\n 0.7948354919093843\n 0.7968871369902905"
  },
  {
    "objectID": "lectures/learning-slides.html#plotting-the-learning-trajectory",
    "href": "lectures/learning-slides.html#plotting-the-learning-trajectory",
    "title": "A model of language learning",
    "section": "Plotting the learning trajectory",
    "text": "Plotting the learning trajectory\n\nusing Plots\nplot(1:1000, trajectory)"
  },
  {
    "objectID": "lectures/learning-slides.html#bibliographical-remarks",
    "href": "lectures/learning-slides.html#bibliographical-remarks",
    "title": "A model of language learning",
    "section": "Bibliographical remarks",
    "text": "Bibliographical remarks\n\nFor more about the notion of grammar competition, see Kroch (1989), Kroch (1994)\nVariational learner originally from Yang (2000), Yang (2002)\nLearning algorithm itself is old: Bush and Mosteller (1955)"
  },
  {
    "objectID": "lectures/learning-slides.html#summary",
    "href": "lectures/learning-slides.html#summary",
    "title": "A model of language learning",
    "section": "Summary",
    "text": "Summary\n\nYou’ve learned a few important concepts today:\n\nGrammar competition and variational learning\nHow to sample objects according to a discrete probability distribution\nHow to use conditional statements\nHow to make a simple plot of a learning trajectory\n\nYou get to practice these in the homework\nNext week, we’ll take the model to a new level and consider what happens when several variational learners interact"
  },
  {
    "objectID": "lectures/learning-slides.html#references",
    "href": "lectures/learning-slides.html#references",
    "title": "A model of language learning",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nBush, Robert R., and Frederick Mosteller. 1955. Stochastic Models for Learning. New York, NY: Wiley.\n\n\nKroch, Anthony S. 1989. “Reflexes of Grammar in Patterns of Language Change.” Language Variation and Change 1 (3): 199–244. https://doi.org/10.1017/S0954394500000168.\n\n\n———. 1994. “Morphosyntactic Variation.” In Proceedings of the 30th Annual Meeting of the Chicago Linguistic Society, edited by K. Beals, 180–201. Chicago, IL: Chicago Linguistic Society.\n\n\nYang, Charles D. 2000. “Internal and External Forces in Language Change.” Language Variation and Change 12: 231–50. https://doi.org/10.1017/S0954394500123014.\n\n\n———. 2002. Knowledge and Learning in Natural Language. Oxford: Oxford University Press."
  },
  {
    "objectID": "lectures/bestpractices.html",
    "href": "lectures/bestpractices.html",
    "title": "Programming best practices",
    "section": "",
    "text": "This week, we will look at a few practices that have the potential to make your code better\nHere, “better” can mean:\n\nmore logical organization of code\nbetter performance (faster running, and/or less memory consumption)\n\nIn addition, we will wrap up the first half of the course and talk about any issues/challenges you may have run into\n\n\n\n\n\n\n\nNote\n\n\n\nToday’s lecture requires the following Julia packages:\n\nAgents\nBenchmarkTools\nRandom\n\nIt would be a good idea to install them now, if your system does not already have them.\n\n\n\nThe “best practices” bit of today’s session is broken down into three major topics:\n\nAbstract types, inheritance and multiple dispatch\nBenchmarking\nRandom numbers\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "lectures/bestpractices.html#plan",
    "href": "lectures/bestpractices.html#plan",
    "title": "Programming best practices",
    "section": "",
    "text": "This week, we will look at a few practices that have the potential to make your code better\nHere, “better” can mean:\n\nmore logical organization of code\nbetter performance (faster running, and/or less memory consumption)\n\nIn addition, we will wrap up the first half of the course and talk about any issues/challenges you may have run into\n\n\n\n\n\n\n\nNote\n\n\n\nToday’s lecture requires the following Julia packages:\n\nAgents\nBenchmarkTools\nRandom\n\nIt would be a good idea to install them now, if your system does not already have them.\n\n\n\nThe “best practices” bit of today’s session is broken down into three major topics:\n\nAbstract types, inheritance and multiple dispatch\nBenchmarking\nRandom numbers"
  },
  {
    "objectID": "lectures/bestpractices.html#abstract-types-and-inheritance",
    "href": "lectures/bestpractices.html#abstract-types-and-inheritance",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nSome weeks ago, we defined a variational learner type which lives in an unstructured population\nLast week, we defined one that lives in a grid space\n\n\nTwo possible strategies:\n\n\nName both types VariationalLearner\n\npro: we can reuse the functions we’ve written that take VariationalLearner objects as arguments, such as speak, learn! and interact!\ncon 1: we can’t use both types in the same code\ncon 2: Julia does not deal well with type redefinitions, forcing a restart when moving from one definition to the other\n\n\n\nGive the new type a new name, such as GridVL\n\npro: no complaints from Julia\ncon: we can’t reuse our functions, since they’re defined for VariationalLearner objects\n\n\n\nA neat solution to this problem is to start thinking about type hierarchies\nIntuitively: types can have hierarchical relationships, a bit like biological taxonomies\n\n\n\n\n\n\n\n\nflowchart TB\n  A[Mammal] --- B[Human]\n  A[Mammal] --- C[Cat]\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  A[VariationalLearner] --- B[SimpleVL]\n  A[VariationalLearner] --- C[GridVL]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFrom now on, I will use SimpleVL to refer to our original VariationalLearner, i.e. the type that lives in an unstructured population.\nVariationalLearner from now on will denote the supertype of all “variational learnery” things."
  },
  {
    "objectID": "lectures/bestpractices.html#abstract-types-and-inheritance-5",
    "href": "lectures/bestpractices.html#abstract-types-and-inheritance-5",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nThe point of this is: a function can be defined for the supertype, whose subtypes then inherit that function\nE.g. we can define a sleep function for Mammal\nBoth Human and Cat inherit this function, and so we don’t need to define one for them separately\n\n\n\n\n\n\nflowchart TB\nA[\"sleep(x::Mammal)\"] --&gt; B[Human]\nA[\"sleep(x::Mammal)\"] --&gt; C[Cat]\n\n\n\n\n\n\n\nSimilarly, we can define speak for the supertype VariationalLearner\nThen both SimpleVL and GridVL have access to this function\n\n\n\n\n\n\nflowchart TB\nA[\"speak(x::VariationalLearner)\"] --&gt; B[SimpleVL]\nA[\"speak(x::VariationalLearner)\"] --&gt; C[GridVL]\n\n\n\n\n\n\n\nIn Julia such “supertypes” are known as abstract types\nThey have no fields; they only exist to define the type hierarchy\nInheritance relations are defined using a special &lt;: operator\nTo use Agents.jl, our VariationalLearner abstract type itself needs to inherit from AbstractAgent\n\n\n\n\n\n\nflowchart TB\nD[AbstractAgent] --- A[VariationalLearner]\nA[VariationalLearner] --- B[SimpleVL]\nA[VariationalLearner] --- C[GridVL]\n\n\n\n\n\n\n\nabstract type VariationalLearner &lt;: AbstractAgent end\n\nmutable struct SimpleVL &lt;: VariationalLearner\n  # code goes here...\nend\n\n@agent struct GridVL(GridAgent{2}) &lt;: VariationalLearner\n  # code goes here...\nend\n\nfunction speak(x::VariationalLearner)\n  # code goes here...\nend\n\n\nWe can now do things like:\n\n\nbob = SimpleVL(0.1, 0.01, 0.4, 0.1)\n\nspeak(bob)\n\neven though speak wasn’t defined for SimpleVL"
  },
  {
    "objectID": "lectures/bestpractices.html#multiple-dispatch",
    "href": "lectures/bestpractices.html#multiple-dispatch",
    "title": "Programming best practices",
    "section": "Multiple dispatch",
    "text": "Multiple dispatch\n\n\n\n\n\nflowchart TB\n  A[Mammal] --- B[Human]\n  A[Mammal] --- C[Cat]\n\n\n\n\n\n\n\nWhat if Cat needs to sleep differently from other Mammals?\nEasy: we simply define a function sleep(x::Cat)\nOther Mammals will use the default function sleep(x::Mammal)\n\n\nIn Julia, this is called multiple dispatch\nOne and the same function (here, sleep) can have multiple definitions depending on the argument’s type\nThese different definitions are known as methods of the function\nWhen figuring out which method to use, the compiler tries to apply the method that is deepest in the type hierarchy, moving upwards if such a definition isn’t found\n\ne.g. in our example calling sleep on Human will trigger the sleep method defined for Mammal, since no sleep method specific to Human has been defined"
  },
  {
    "objectID": "lectures/bestpractices.html#our-vl-code-so-far",
    "href": "lectures/bestpractices.html#our-vl-code-so-far",
    "title": "Programming best practices",
    "section": "Our VL code so far",
    "text": "Our VL code so far\n\n\n\n\n\n\nTip\n\n\n\nYou can also download this code: VL.jl. To use:\n\ninclude(\"VL.jl\")\nusing .VL\n\nIf VSCode complains about modules, simply delete the first and last lines of the file and include it like so:\n\ninclude(\"VL.jl\")\n\n\n\n\nmodule VL\n\n# Agents.jl functionality\nusing Agents\n\n# we need this package for the sample() function\nusing StatsBase\n\n# we export the following types and functions\nexport VariationalLearner\nexport SimpleVL\nexport GridVL\nexport speak\nexport learn!\nexport interact!\nexport VL_step!\n\n\n# abstract type\nabstract type VariationalLearner &lt;: AbstractAgent end\n\n# variational learner type on a 2D grid\n@agent struct GridVL(GridAgent{2}) &lt;: VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend\n\n# \"simple\" variational learner in unstructured population\nmutable struct SimpleVL &lt;: VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend\n\n# makes variational learner x utter a string\nfunction speak(x::VariationalLearner)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\"\n    return sample([\"S1\", \"S12\"], Weights([x.P1, 1 - x.P1]))\n  else\n    return sample([\"S2\", \"S12\"], Weights([x.P2, 1 - x.P2]))\n  end\nend\n\n# makes variational learner x learn from input string s\nfunction learn!(x::VariationalLearner, s::String)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\n# makes two variational learners interact, with one speaking\n# and the other one learning\nfunction interact!(x::VariationalLearner, y::VariationalLearner)\n  s = speak(x)\n  learn!(y, s)\nend\n\n# steps a model\nfunction VL_step!(agent, model)\n  interlocutor = random_nearby_agent(agent, model)\n  interact!(interlocutor, agent)\nend\n\nend   # this closes the module"
  },
  {
    "objectID": "lectures/bestpractices.html#benchmarking",
    "href": "lectures/bestpractices.html#benchmarking",
    "title": "Programming best practices",
    "section": "Benchmarking",
    "text": "Benchmarking\n\nWhen working on larger simulations, it is often important to know how long some function takes to run\nIt may also be important to know how much memory is consumed\nBoth of these things can be measured using the @benchmark macro defined by BenchmarkTools.jl\n\n\nExample:\n\n\nusing BenchmarkTools\n\n@benchmark sum(1:1_000_000_000)\n\n\nBenchmarkTools.Trial: 10000 samples with 1000 evaluations.\n Range (min … max):  1.300 ns … 28.411 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.497 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.526 ns ±  0.644 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  ▂        ▁    ▃         █     ▁                             \n  █▂▁▁▆▃▁▂▃█▁▁▁▇█▄▁▁▃▄▃▁▁▂█▇▂▁▁▅█▃▁▂▂▄▆▃▂▂▂▂▆▄▃▁▂▁▂▄▃▂▁▁▂▁▇▅ ▃\n  1.3 ns         Histogram: frequency by time        1.76 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "lectures/bestpractices.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast",
    "href": "lectures/bestpractices.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\nSuppose we want to calculate the square root of all numbers between 0 and 100,000 and put them in an array\nOne way of doing this:\n\n\nresult = []   # empty array\nfor x in 0:100_000\n  append!(result, sqrt(x))   # put √x in array\nend\n\n\n@benchmark begin\n  result = []   # empty array\n  for x in 0:100_000\n    append!(result, sqrt(x))   # put √x in array\n  end\nend\n\n\nBenchmarkTools.Trial: 3067 samples with 1 evaluation.\n Range (min … max):  1.224 ms …   5.500 ms  ┊ GC (min … max): 0.00% … 56.43%\n Time  (median):     1.441 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.627 ms ± 558.213 μs  ┊ GC (mean ± σ):  9.11% ± 14.99%\n  ▁▄▄▆█▅▁▁  ▁▄▂                                               ▁\n  ████████▇▅███▆▄▄▄▅▄▁▃▁▁▁▃▄▆▇▅▁▄▇▆▅▃▆▆███▅▇▆█▆▁▃▆▆▄▅▆▄▆▇▇▅▄▅ █\n  1.22 ms      Histogram: log(frequency) by time      4.12 ms &lt;\n Memory estimate: 3.35 MiB, allocs estimate: 100012.\n\n\n\n\nAnother way:\n\n\nresult = zeros(100_000 + 1)\nfor x in 0:100_000\n  result[x+1] = sqrt(x)   # put √x in array\nend\n\n\n@benchmark begin\n  result = zeros(100_000 + 1)\n  for x in 0:100_000\n    result[x+1] = sqrt(x)   # put √x in array\n  end\nend\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  100.215 μs … 681.613 μs  ┊ GC (min … max): 0.00% … 47.87%\n Time  (median):     102.864 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   110.371 μs ±  42.153 μs  ┊ GC (mean ± σ):  4.13% ±  8.80%\n  █                                                             ▁\n  █████▇▇█▇▇█▆▅▆▆▃▄▇▅▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃▁▄▄▅▅▄▄▄▄▅▄▇█ █\n  100 μs        Histogram: log(frequency) by time        383 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2.\n\n\n\n\nA third possibility:\n\n\nresult = [sqrt(x) for x in 0:100_000]\n\n\n@benchmark result = [sqrt(x) for x in 0:100_000]\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  78.318 μs … 691.530 μs  ┊ GC (min … max): 0.00% … 50.18%\n Time  (median):     79.327 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   84.293 μs ±  28.616 μs  ┊ GC (mean ± σ):  3.29% ±  8.27%\n  █▁   ▁       ▁                                               ▁\n  ███▇███▇▇▄▄▅▅█▅▆▁▃▄▆▅▃▁▁▃▃▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆██ █\n  78.3 μs       Histogram: log(frequency) by time       250 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2.\n\n\n\n\nA fourth way:\n\n\nresult = sqrt.(0:100_000)\n\n\n@benchmark result = sqrt.(0:100_000)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  78.201 μs … 685.643 μs  ┊ GC (min … max): 0.00% … 48.30%\n Time  (median):     79.061 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   84.083 μs ±  29.325 μs  ┊ GC (mean ± σ):  3.41% ±  8.34%\n  █▁   ▁                                                       ▁\n  ██████▆█▆▃▄▆█▇▃▃▁▅▆▁▁▃▁▄▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇██ █\n  78.2 μs       Histogram: log(frequency) by time       256 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2."
  },
  {
    "objectID": "lectures/bestpractices.html#summing-up-the-findings",
    "href": "lectures/bestpractices.html#summing-up-the-findings",
    "title": "Programming best practices",
    "section": "Summing up the findings",
    "text": "Summing up the findings\n\n\n\nProcedure\nMedian time\nMem. estimate\n\n\n\n\nGrowing an array\n~1.4 ms\n~3.4 MiB\n\n\nAdding to 0-array\n~0.1 ms\n~0.8 MiB\n\n\nArray comprehension\n~80 µs\n~0.8 MiB\n\n\nBroadcasting\n~80 µs\n~0.8 MiB\n\n\n\n\nLesson: try to avoid growing (and shrinking!) arrays whenever possible\nOf course, sometimes this is practically unavoidable (such as when adding and removing agents from a population)\nAnother lesson: if procedure X gets repeated very many times in a simulation, try to make X as efficient as possible\n\nProcedures which are only carried out once or a few times (such as initializing a population) don’t matter so much"
  },
  {
    "objectID": "lectures/bestpractices.html#random-numbers",
    "href": "lectures/bestpractices.html#random-numbers",
    "title": "Programming best practices",
    "section": "Random numbers",
    "text": "Random numbers\n\nIn the first lecture, we talked about the importance of (pseudo)random numbers in ABM simulations\nE.g. whenever an agent needs to be sampled randomly, the computer needs to generate a random number\nThere are two important issues here:\n\nReproducibility – how to obtain the same sequence of “random” numbers if this is desired\nConsistency – making sure that whenever a random number is drawn, it is drawn using the same generator (i.e. from the same sequence)"
  },
  {
    "objectID": "lectures/bestpractices.html#reproducibility",
    "href": "lectures/bestpractices.html#reproducibility",
    "title": "Programming best practices",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nRecall: a PRNG (pseudorandom number generator) generates a deterministic sequence which appears random\nThe sequence is generated from an initial seed number\nIf you change the seed, you obtain different sequences\nNormally, when Julia is started, the PRNG is seeded with a different seed every time\n\nHence, you obtain different sequences"
  },
  {
    "objectID": "lectures/bestpractices.html#reproducibility-illustration",
    "href": "lectures/bestpractices.html#reproducibility-illustration",
    "title": "Programming best practices",
    "section": "Reproducibility: illustration",
    "text": "Reproducibility: illustration\n\nTo illustrate this, suppose you want to toss a coin 10 times. This is easy:\n\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"heads\"\n\n\n\nNow restart Julia and execute the same thing. You will get a different result:\n\n\n# here, restart Julia...\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\"\n\n\n\nIf you want to make sure the exact same sample is obtained, you can seed the PRNG manually after startup\nFor example, seed with the number 123:\n\n\nusing Random\nRandom.seed!(123)\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"heads\""
  },
  {
    "objectID": "lectures/bestpractices.html#reproducibility-1",
    "href": "lectures/bestpractices.html#reproducibility-1",
    "title": "Programming best practices",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nWhy would you do this? Wasn’t randomness kind of the point?\nSuppose someone (e.g. your supervisor, or an article reviewer) wants to check that your code actually produces the results you have reported\nUsing a manually seeded PRNG makes this possible"
  },
  {
    "objectID": "lectures/bestpractices.html#consistency",
    "href": "lectures/bestpractices.html#consistency",
    "title": "Programming best practices",
    "section": "Consistency",
    "text": "Consistency\n\nIt is possible to have multiple PRNGs running simultaneously in the same code\nThis is rarely desired, but may happen by mistake…\nFor example, when you call StandardABM, Agents.jl will set up a new PRNG by default\nIf your own functions (such as speak or learn!) utilize a different PRNG, you may run into problems\n\nFor one, it will be difficult to ensure reproducibility\n\n\n\nTo avoid this, pass Random.default_rng() as an argument to StandardABM when creating your model:\n\n\nusing Agents\nusing Random\ninclude(\"VL.jl\")\nusing .VL\n\nRandom.seed!(123)\n\nspace = GridSpace((10, 10))\n\nmodel = StandardABM(GridVL, space; agent_step! = VL_step!, \n                    rng = Random.default_rng())"
  },
  {
    "objectID": "lectures/bestpractices.html#reminder-not-all-agents-are-humans",
    "href": "lectures/bestpractices.html#reminder-not-all-agents-are-humans",
    "title": "Programming best practices",
    "section": "Reminder: not all agents are humans!",
    "text": "Reminder: not all agents are humans!"
  },
  {
    "objectID": "lectures/bestpractices.html#looking-ahead",
    "href": "lectures/bestpractices.html#looking-ahead",
    "title": "Programming best practices",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nHomework:\n\nKeep thinking about your project!\nRead Smaldino (2023), chapter 10\n\n\n\nThe following two weeks constitute a break for us: the first one is the lecture-free period, the second one is consolidation week (“Vertiefungswoche”)\nAfter this break, you need to\n\nhave a project team (or have decided to work on your own)\nhave at least an initial idea about your project topic\n\nIf you struggle, I’m happy to help! You can always write me an email, and/or come to see me in my office."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#plan",
    "href": "lectures/bestpractices-slides.html#plan",
    "title": "Programming best practices",
    "section": "Plan",
    "text": "Plan\n\nThis week, we will look at a few practices that have the potential to make your code better\nHere, “better” can mean:\n\nmore logical organization of code\nbetter performance (faster running, and/or less memory consumption)\n\nIn addition, we will wrap up the first half of the course and talk about any issues/challenges you may have run into"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#section",
    "href": "lectures/bestpractices-slides.html#section",
    "title": "Programming best practices",
    "section": "",
    "text": "Note\n\n\nToday’s lecture requires the following Julia packages:\n\nAgents\nBenchmarkTools\nRandom\n\nIt would be a good idea to install them now, if your system does not already have them."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#plan-1",
    "href": "lectures/bestpractices-slides.html#plan-1",
    "title": "Programming best practices",
    "section": "Plan",
    "text": "Plan\n\nThe “best practices” bit of today’s session is broken down into three major topics:\n\nAbstract types, inheritance and multiple dispatch\nBenchmarking\nRandom numbers"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nSome weeks ago, we defined a variational learner type which lives in an unstructured population\nLast week, we defined one that lives in a grid space"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-1",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-1",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nTwo possible strategies:\n\n\nName both types VariationalLearner\n\npro: we can reuse the functions we’ve written that take VariationalLearner objects as arguments, such as speak, learn! and interact!\ncon 1: we can’t use both types in the same code\ncon 2: Julia does not deal well with type redefinitions, forcing a restart when moving from one definition to the other"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-2",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-2",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nTwo possible strategies:\n\n\nGive the new type a new name, such as GridVL\n\npro: no complaints from Julia\ncon: we can’t reuse our functions, since they’re defined for VariationalLearner objects"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-3",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-3",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nA neat solution to this problem is to start thinking about type hierarchies\nIntuitively: types can have hierarchical relationships, a bit like biological taxonomies"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-4",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-4",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\n\n\n\n\n\nImportant\n\n\nFrom now on, I will use SimpleVL to refer to our original VariationalLearner, i.e. the type that lives in an unstructured population.\nVariationalLearner from now on will denote the supertype of all “variational learnery” things."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-5",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-5",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nThe point of this is: a function can be defined for the supertype, whose subtypes then inherit that function\nE.g. we can define a sleep function for Mammal\nBoth Human and Cat inherit this function, and so we don’t need to define one for them separately"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-6",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-6",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nSimilarly, we can define speak for the supertype VariationalLearner\nThen both SimpleVL and GridVL have access to this function"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-7",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-7",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nIn Julia such “supertypes” are known as abstract types\nThey have no fields; they only exist to define the type hierarchy\nInheritance relations are defined using a special &lt;: operator\nTo use Agents.jl, our VariationalLearner abstract type itself needs to inherit from AbstractAgent"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-8",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-8",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-9",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-9",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nabstract type VariationalLearner &lt;: AbstractAgent end\n\nmutable struct SimpleVL &lt;: VariationalLearner\n  # code goes here...\nend\n\n@agent struct GridVL(GridAgent{2}) &lt;: VariationalLearner\n  # code goes here...\nend\n\nfunction speak(x::VariationalLearner)\n  # code goes here...\nend"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-10",
    "href": "lectures/bestpractices-slides.html#abstract-types-and-inheritance-10",
    "title": "Programming best practices",
    "section": "Abstract types and inheritance",
    "text": "Abstract types and inheritance\n\nWe can now do things like:\n\n\nbob = SimpleVL(0.1, 0.01, 0.4, 0.1)\n\nspeak(bob)\n\neven though speak wasn’t defined for SimpleVL"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#multiple-dispatch",
    "href": "lectures/bestpractices-slides.html#multiple-dispatch",
    "title": "Programming best practices",
    "section": "Multiple dispatch",
    "text": "Multiple dispatch\n\n\n\n\n\n\n\n\n\n\n\n\nWhat if Cat needs to sleep differently from other Mammals?\nEasy: we simply define a function sleep(x::Cat)\nOther Mammals will use the default function sleep(x::Mammal)"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#multiple-dispatch-1",
    "href": "lectures/bestpractices-slides.html#multiple-dispatch-1",
    "title": "Programming best practices",
    "section": "Multiple dispatch",
    "text": "Multiple dispatch\n\nIn Julia, this is called multiple dispatch\nOne and the same function (here, sleep) can have multiple definitions depending on the argument’s type\nThese different definitions are known as methods of the function\nWhen figuring out which method to use, the compiler tries to apply the method that is deepest in the type hierarchy, moving upwards if such a definition isn’t found\n\ne.g. in our example calling sleep on Human will trigger the sleep method defined for Mammal, since no sleep method specific to Human has been defined"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#our-vl-code-so-far",
    "href": "lectures/bestpractices-slides.html#our-vl-code-so-far",
    "title": "Programming best practices",
    "section": "Our VL code so far",
    "text": "Our VL code so far\n\nmodule VL\n\n# Agents.jl functionality\nusing Agents\n\n# we need this package for the sample() function\nusing StatsBase\n\n# we export the following types and functions\nexport VariationalLearner\nexport SimpleVL\nexport GridVL\nexport speak\nexport learn!\nexport interact!\nexport VL_step!\n\n\n# abstract type\nabstract type VariationalLearner &lt;: AbstractAgent end\n\n# variational learner type on a 2D grid\n@agent struct GridVL(GridAgent{2}) &lt;: VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend\n\n# \"simple\" variational learner in unstructured population\nmutable struct SimpleVL &lt;: VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend\n\n# makes variational learner x utter a string\nfunction speak(x::VariationalLearner)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\"\n    return sample([\"S1\", \"S12\"], Weights([x.P1, 1 - x.P1]))\n  else\n    return sample([\"S2\", \"S12\"], Weights([x.P2, 1 - x.P2]))\n  end\nend\n\n# makes variational learner x learn from input string s\nfunction learn!(x::VariationalLearner, s::String)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\n# makes two variational learners interact, with one speaking\n# and the other one learning\nfunction interact!(x::VariationalLearner, y::VariationalLearner)\n  s = speak(x)\n  learn!(y, s)\nend\n\n# steps a model\nfunction VL_step!(agent, model)\n  interlocutor = random_nearby_agent(agent, model)\n  interact!(interlocutor, agent)\nend\n\nend   # this closes the module"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#benchmarking",
    "href": "lectures/bestpractices-slides.html#benchmarking",
    "title": "Programming best practices",
    "section": "Benchmarking",
    "text": "Benchmarking\n\nWhen working on larger simulations, it is often important to know how long some function takes to run\nIt may also be important to know how much memory is consumed\nBoth of these things can be measured using the @benchmark macro defined by BenchmarkTools.jl"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#benchmarking-1",
    "href": "lectures/bestpractices-slides.html#benchmarking-1",
    "title": "Programming best practices",
    "section": "Benchmarking",
    "text": "Benchmarking\n\nExample:\n\n\nusing BenchmarkTools\n\n@benchmark sum(1:1_000_000_000)\n\n\nBenchmarkTools.Trial: 10000 samples with 1000 evaluations.\n Range (min … max):  1.303 ns … 29.124 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.497 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.520 ns ±  0.498 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  ▁            ▂ █    ▄    ▃   ▂       █    ▁                 \n  ██▇▂▃▄▅▂▂▂█▂▁█▅█▂▁█▄█▂▁▅██▇▁▂█▅▂▁▁▁▁▁█▅▁▂▅█▂▂▂▂▂▃▄▅▆▃▁▁▃▇▄ ▄\n  1.3 ns         Histogram: frequency by time        1.77 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\nSuppose we want to calculate the square root of all numbers between 0 and 100,000 and put them in an array\nOne way of doing this:\n\n\nresult = []   # empty array\nfor x in 0:100_000\n  append!(result, sqrt(x))   # put √x in array\nend"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-1",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-1",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\n@benchmark begin\n  result = []   # empty array\n  for x in 0:100_000\n    append!(result, sqrt(x))   # put √x in array\n  end\nend\n\n\nBenchmarkTools.Trial: 3337 samples with 1 evaluation.\n Range (min … max):  1.170 ms …   4.004 ms  ┊ GC (min … max): 0.00% … 66.72%\n Time  (median):     1.323 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.496 ms ± 497.756 μs  ┊ GC (mean ± σ):  8.89% ± 14.73%\n  ▁▄▇█▅▂▁   ▂▄▃                                               ▁\n  ████████▅▄████▆▅▅▅▃▄▁▅▄▁▁▁▁▁▄▆▇▇▇▃▁▅▅███▆▇▆▇▅▅▆▆▅▃▁▁▃▇█▆▅▄▆ █\n  1.17 ms      Histogram: log(frequency) by time      3.71 ms &lt;\n Memory estimate: 3.35 MiB, allocs estimate: 100012."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-2",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-2",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\nAnother way:\n\n\nresult = zeros(100_000 + 1)\nfor x in 0:100_000\n  result[x+1] = sqrt(x)   # put √x in array\nend"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-3",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-3",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\n@benchmark begin\n  result = zeros(100_000 + 1)\n  for x in 0:100_000\n    result[x+1] = sqrt(x)   # put √x in array\n  end\nend\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  100.025 μs … 711.973 μs  ┊ GC (min … max): 0.00% … 49.35%\n Time  (median):     103.252 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   112.584 μs ±  45.953 μs  ┊ GC (mean ± σ):  4.29% ±  8.90%\n  █▄▂▁▁                                                         ▁\n  ███████████▇▆█▆▄▇▆▅▆▄▃▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▃▅▃▄▁▅▃▅▄▄▅██ █\n  100 μs        Histogram: log(frequency) by time        400 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-4",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-4",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\nA third possibility:\n\n\nresult = [sqrt(x) for x in 0:100_000]"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-5",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-5",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\n@benchmark result = [sqrt(x) for x in 0:100_000]\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  78.197 μs … 691.092 μs  ┊ GC (min … max): 0.00% … 51.38%\n Time  (median):     79.291 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   84.522 μs ±  29.224 μs  ┊ GC (mean ± σ):  3.40% ±  8.36%\n  █    ▁                                                       ▁\n  ██▇▇██▇█▆▃▅▇██▄▄▃▅▃▁▃▁▁▁▄▁▁▁▁▃▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅██ █\n  78.2 μs       Histogram: log(frequency) by time       255 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-6",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-6",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\nA fourth way:\n\n\nresult = sqrt.(0:100_000)"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-7",
    "href": "lectures/bestpractices-slides.html#all-roads-lead-to-rome-but-theyre-not-all-equally-fast-7",
    "title": "Programming best practices",
    "section": "All roads lead to Rome, but they’re not all equally fast…",
    "text": "All roads lead to Rome, but they’re not all equally fast…\n\n@benchmark result = sqrt.(0:100_000)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  77.890 μs … 698.451 μs  ┊ GC (min … max): 0.00% … 51.61%\n Time  (median):     79.046 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   84.720 μs ±  30.239 μs  ┊ GC (mean ± σ):  3.55% ±  8.50%\n  █    ▁      ▁                                                ▁\n  ██▇█▇█▇▇▆▄▇▆█▇▅▄▅▅▇▆▁▄▅▇▃▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▇██ █\n  77.9 μs       Histogram: log(frequency) by time       263 μs &lt;\n Memory estimate: 781.36 KiB, allocs estimate: 2."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#summing-up-the-findings",
    "href": "lectures/bestpractices-slides.html#summing-up-the-findings",
    "title": "Programming best practices",
    "section": "Summing up the findings",
    "text": "Summing up the findings\n\n\n\nProcedure\nMedian time\nMem. estimate\n\n\n\n\nGrowing an array\n~1.4 ms\n~3.4 MiB\n\n\nAdding to 0-array\n~0.1 ms\n~0.8 MiB\n\n\nArray comprehension\n~80 µs\n~0.8 MiB\n\n\nBroadcasting\n~80 µs\n~0.8 MiB"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#summing-up-the-findings-1",
    "href": "lectures/bestpractices-slides.html#summing-up-the-findings-1",
    "title": "Programming best practices",
    "section": "Summing up the findings",
    "text": "Summing up the findings\n\nLesson: try to avoid growing (and shrinking!) arrays whenever possible\nOf course, sometimes this is practically unavoidable (such as when adding and removing agents from a population)\nAnother lesson: if procedure X gets repeated very many times in a simulation, try to make X as efficient as possible\n\nProcedures which are only carried out once or a few times (such as initializing a population) don’t matter so much"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#random-numbers",
    "href": "lectures/bestpractices-slides.html#random-numbers",
    "title": "Programming best practices",
    "section": "Random numbers",
    "text": "Random numbers\n\nIn the first lecture, we talked about the importance of (pseudo)random numbers in ABM simulations\nE.g. whenever an agent needs to be sampled randomly, the computer needs to generate a random number\nThere are two important issues here:\n\nReproducibility – how to obtain the same sequence of “random” numbers if this is desired\nConsistency – making sure that whenever a random number is drawn, it is drawn using the same generator (i.e. from the same sequence)"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reproducibility",
    "href": "lectures/bestpractices-slides.html#reproducibility",
    "title": "Programming best practices",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nRecall: a PRNG (pseudorandom number generator) generates a deterministic sequence which appears random\nThe sequence is generated from an initial seed number\nIf you change the seed, you obtain different sequences\nNormally, when Julia is started, the PRNG is seeded with a different seed every time\n\nHence, you obtain different sequences"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reproducibility-illustration",
    "href": "lectures/bestpractices-slides.html#reproducibility-illustration",
    "title": "Programming best practices",
    "section": "Reproducibility: illustration",
    "text": "Reproducibility: illustration\n\nTo illustrate this, suppose you want to toss a coin 10 times. This is easy:\n\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"heads\""
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reproducibility-illustration-1",
    "href": "lectures/bestpractices-slides.html#reproducibility-illustration-1",
    "title": "Programming best practices",
    "section": "Reproducibility: illustration",
    "text": "Reproducibility: illustration\n\nNow restart Julia and execute the same thing. You will get a different result:\n\n\n# here, restart Julia...\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\""
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reproducibility-illustration-2",
    "href": "lectures/bestpractices-slides.html#reproducibility-illustration-2",
    "title": "Programming best practices",
    "section": "Reproducibility: illustration",
    "text": "Reproducibility: illustration\n\nIf you want to make sure the exact same sample is obtained, you can seed the PRNG manually after startup\nFor example, seed with the number 123:\n\n\nusing Random\nRandom.seed!(123)\n\nrand([\"heads\", \"tails\"], 10)\n\n10-element Vector{String}:\n \"tails\"\n \"tails\"\n \"tails\"\n \"heads\"\n \"tails\"\n \"heads\"\n \"heads\"\n \"tails\"\n \"tails\"\n \"heads\""
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reproducibility-1",
    "href": "lectures/bestpractices-slides.html#reproducibility-1",
    "title": "Programming best practices",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nWhy would you do this? Wasn’t randomness kind of the point?\nSuppose someone (e.g. your supervisor, or an article reviewer) wants to check that your code actually produces the results you have reported\nUsing a manually seeded PRNG makes this possible"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#consistency",
    "href": "lectures/bestpractices-slides.html#consistency",
    "title": "Programming best practices",
    "section": "Consistency",
    "text": "Consistency\n\nIt is possible to have multiple PRNGs running simultaneously in the same code\nThis is rarely desired, but may happen by mistake…\nFor example, when you call StandardABM, Agents.jl will set up a new PRNG by default\nIf your own functions (such as speak or learn!) utilize a different PRNG, you may run into problems\n\nFor one, it will be difficult to ensure reproducibility"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#consistency-1",
    "href": "lectures/bestpractices-slides.html#consistency-1",
    "title": "Programming best practices",
    "section": "Consistency",
    "text": "Consistency\n\nTo avoid this, pass Random.default_rng() as an argument to StandardABM when creating your model:\n\n\nusing Agents\nusing Random\ninclude(\"VL.jl\")\nusing .VL\n\nRandom.seed!(123)\n\nspace = GridSpace((10, 10))\n\nmodel = StandardABM(GridVL, space; agent_step! = VL_step!, \n                    rng = Random.default_rng())"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#reminder-not-all-agents-are-humans",
    "href": "lectures/bestpractices-slides.html#reminder-not-all-agents-are-humans",
    "title": "Programming best practices",
    "section": "Reminder: not all agents are humans!",
    "text": "Reminder: not all agents are humans!"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#looking-ahead",
    "href": "lectures/bestpractices-slides.html#looking-ahead",
    "title": "Programming best practices",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nHomework:\n\nKeep thinking about your project!\nRead Smaldino (2023), chapter 10"
  },
  {
    "objectID": "lectures/bestpractices-slides.html#looking-ahead-1",
    "href": "lectures/bestpractices-slides.html#looking-ahead-1",
    "title": "Programming best practices",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nThe following two weeks constitute a break for us: the first one is the lecture-free period, the second one is consolidation week (“Vertiefungswoche”)\nAfter this break, you need to\n\nhave a project team (or have decided to work on your own)\nhave at least an initial idea about your project topic\n\nIf you struggle, I’m happy to help! You can always write me an email, and/or come to see me in my office."
  },
  {
    "objectID": "lectures/bestpractices-slides.html#references",
    "href": "lectures/bestpractices-slides.html#references",
    "title": "Programming best practices",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nSmaldino, Paul E. 2023. Modeling Social Behavior: Mathematical and Agent-Based Models of Social Dynamics and Cultural Evolution. Princeton, NJ: Princeton University Press."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Intro to ABMs\n\n\n\n9 April 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgramming basics\n\n\n\n16 April 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA model of language learning\n\n\n\n23 April 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeaking and listening\n\n\n\n30 April 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModels of language change\n\n\n\n7 May 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStructured populations\n\n\n\n14 May 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgramming best practices\n\n\n\n21 May 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions/modules.html",
    "href": "solutions/modules.html",
    "title": "Modules and packages",
    "section": "",
    "text": "Imagine the following scenario: Alice writes some Julia code which defines a function do_cool_stuff() (which does cool stuff), and Bob also writes some Julia code that also defines a function named do_cool_stuff(), which also does cool stuff but some slightly different cool stuff than Alice’s function. In other words, the functions have the same name but do slightly different things.\nNow imagine Carlos has access to both Alice’s and Bob’s code. If Carlos executes the function do_cool_stuff(), what is going to happen? Will Alice’s code run, or will Bob’s code run?\nThe standard solution to this kind of problem is to put code in modules. A module defines a namespace. This makes it possible to use the same function names (as well as names for custom types etc.) in different modules.\nIf Alice has created a module called CodeOfAlice and Bob’s module is called CodeOfBob, then the following commands can be used to distinguish between the two different but homonymous functions:\n\nCodeOfAlice.do_cool_stuff()\nCodeOfBob.do_cool_stuff()\n\nNow we can finally explain the difference between using and import. Both commands can be used to load a module into memory. The difference is:\n\nusing allows the user to refer to a function such as do_cool_stuff() without specifying the module the function comes from. This can cause conflicts, if more than one module is used that defines the same name. In that case, Julia will throw a warning, and it is up to you (or Carlos, in this case) to make sure that you’re not accidentally calling the wrong function!\nimport does not allow the above behaviour. With import, you must specify the module name every time you call a function.\n\nIn summary, you can do either\n\nusing CodeOfAlice\ndo_cool_stuff()\n\nor\n\nimport CodeOfAlice\nCodeOfAlice.do_cool_stuff()\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions/modules.html#using-vs.-import",
    "href": "solutions/modules.html#using-vs.-import",
    "title": "Modules and packages",
    "section": "",
    "text": "Imagine the following scenario: Alice writes some Julia code which defines a function do_cool_stuff() (which does cool stuff), and Bob also writes some Julia code that also defines a function named do_cool_stuff(), which also does cool stuff but some slightly different cool stuff than Alice’s function. In other words, the functions have the same name but do slightly different things.\nNow imagine Carlos has access to both Alice’s and Bob’s code. If Carlos executes the function do_cool_stuff(), what is going to happen? Will Alice’s code run, or will Bob’s code run?\nThe standard solution to this kind of problem is to put code in modules. A module defines a namespace. This makes it possible to use the same function names (as well as names for custom types etc.) in different modules.\nIf Alice has created a module called CodeOfAlice and Bob’s module is called CodeOfBob, then the following commands can be used to distinguish between the two different but homonymous functions:\n\nCodeOfAlice.do_cool_stuff()\nCodeOfBob.do_cool_stuff()\n\nNow we can finally explain the difference between using and import. Both commands can be used to load a module into memory. The difference is:\n\nusing allows the user to refer to a function such as do_cool_stuff() without specifying the module the function comes from. This can cause conflicts, if more than one module is used that defines the same name. In that case, Julia will throw a warning, and it is up to you (or Carlos, in this case) to make sure that you’re not accidentally calling the wrong function!\nimport does not allow the above behaviour. With import, you must specify the module name every time you call a function.\n\nIn summary, you can do either\n\nusing CodeOfAlice\ndo_cool_stuff()\n\nor\n\nimport CodeOfAlice\nCodeOfAlice.do_cool_stuff()"
  },
  {
    "objectID": "solutions/modules.html#include",
    "href": "solutions/modules.html#include",
    "title": "Modules and packages",
    "section": "2. include()",
    "text": "2. include()\nThe command include() is used when you want to import into your session Julia code which lives in an external file (typically, with the .jl file extension) but which is not necessarily organized into a module. We used this before to load the plotting code I had written for the bird agents."
  },
  {
    "objectID": "solutions/modules.html#export",
    "href": "solutions/modules.html#export",
    "title": "Modules and packages",
    "section": "3. export",
    "text": "3. export\nThe command export defines which functions and objects defined inside a module will be visible to outside users. For example, in the above example, both Alice and Bob have included the line export do_cool_stuff in their code, to make the function available to outside users of the module.\nFunctions which are not exported can still be used. However, in that case, the module name must always be specified, regardless of whether the module has been loaded using using or import. In other words, non-exported stuff can only be accessed like this: ModuleName.function_name()."
  },
  {
    "objectID": "solutions/modules.html#the-variationallearning-module",
    "href": "solutions/modules.html#the-variationallearning-module",
    "title": "Modules and packages",
    "section": "4. The VariationalLearning module",
    "text": "4. The VariationalLearning module\nHere, I am following the logic of the lecture on Speaking and listening, omitting the older LearningEnvironment type which we will no longer need. I’ve decided to export every type and function defined by the module. In this case it makes sense, since the external user may conceivably want to make use of all of them. (We will later see examples of so-called “helper” functions which need not be exposed to end-users.)\n\nmodule VariationalLearning\n\n# we need this package for the sample() function\nusing StatsBase\n\n# we export the following types and functions\nexport VariationalLearner\nexport speak\nexport learn!\nexport interact!\n\n# variational learner type\nmutable struct VariationalLearner\n  p::Float64      # prob. of using G1\n  gamma::Float64  # learning rate\n  P1::Float64     # prob. of L1 \\ L2\n  P2::Float64     # prob. of L2 \\ L1\nend\n\n# makes variational learner x utter a string\nfunction speak(x::VariationalLearner)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\"\n    return sample([\"S1\", \"S12\"], Weights([x.P1, 1 - x.P1]))\n  else\n    return sample([\"S2\", \"S12\"], Weights([x.P2, 1 - x.P2]))\n  end\nend\n\n# makes variational learner x learn from input string s\nfunction learn!(x::VariationalLearner, s::String)\n  g = sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\n\n  if g == \"G1\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\n# makes two variational learners interact, with one speaking\n# and the other one learning\nfunction interact!(x::VariationalLearner, y::VariationalLearner)\n  s = speak(x)\n  learn!(y, s)\nend\n\nend   # this closes the module\n\nIt now makes sense to save this code in a file. I’ve saved it in VariationalLearning.jl. This way, we can easily reuse our code in the future and not have to rewrite it again and again."
  },
  {
    "objectID": "solutions/modules.html#bonus",
    "href": "solutions/modules.html#bonus",
    "title": "Modules and packages",
    "section": "Bonus",
    "text": "Bonus\nOkay, so now we know what a module is. What about the other thing mentioned in the title, packages? What is a package?\nEssentially, a package is just a module which is being maintained using a version control system and is offered to the rest of the world, usually (but not always) through the official Julia registry. (These are the things you install with Pkg.add(\"PackageName\").)"
  },
  {
    "objectID": "solutions/vl.html",
    "href": "solutions/vl.html",
    "title": "Variational learning",
    "section": "",
    "text": "Update 7 May 2024\n\n\n\nFixed bug in the learn! function. See the lecture for details.\nFirst, I repeat the definitions of the custom types VariationalLearner and LearningEnvironment and the associated functions we defined in the lecture. (Without these definitions, none of what follows will work!)\nusing Plots       # for drawing plots\nusing StatsBase   # for the sample() function\n\nmutable struct VariationalLearner\n  p::Float64\n  gamma::Float64\nend\n\nstruct LearningEnvironment\n  P1::Float64\n  P12::Float64\n  P2::Float64\nend\n\nfunction sample_string(x::LearningEnvironment)\n  sample([\"S1\", \"S12\", \"S2\"], Weights([x.P1, x.P12, x.P2]))\nend\n\nfunction pick_grammar(x::VariationalLearner)\n  sample([\"G1\", \"G2\"], Weights([x.p, 1 - x.p]))\nend\n\nfunction learn!(x::VariationalLearner, y::LearningEnvironment)\n  s = sample_string(y)\n  g = pick_grammar(x)\n\n  if g == \"G1\" && s != \"S2\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  elseif g == \"G1\" && s == \"S2\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s != \"S1\"\n    x.p = x.p - x.gamma * x.p\n  elseif g == \"G2\" && s == \"S1\"\n    x.p = x.p + x.gamma * (1 - x.p)\n  end\n\n  return x.p\nend\n\nlearn! (generic function with 1 method)\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  },
  {
    "objectID": "solutions/vl.html#five-learners",
    "href": "solutions/vl.html#five-learners",
    "title": "Variational learning",
    "section": "1. Five learners",
    "text": "1. Five learners\n\n# create learning environment\nlondon = LearningEnvironment(0.4, 0.5, 0.1)\n\n# create 5 learners\ngamma = 0.01\nlearner1 = VariationalLearner(0.5, gamma)\nlearner2 = VariationalLearner(0.5, gamma)\nlearner3 = VariationalLearner(0.5, gamma)\nlearner4 = VariationalLearner(0.5, gamma)\nlearner5 = VariationalLearner(0.5, gamma)\n\n# simulate each learner for 1000 steps\ntrajectory1 = [learn!(learner1, london) for t in 1:1000]\ntrajectory2 = [learn!(learner2, london) for t in 1:1000]\ntrajectory3 = [learn!(learner3, london) for t in 1:1000]\ntrajectory4 = [learn!(learner4, london) for t in 1:1000]\ntrajectory5 = [learn!(learner5, london) for t in 1:1000]\n\n# plot\nplot(1:1000, trajectory1)\nplot!(1:1000, trajectory2)\nplot!(1:1000, trajectory3)\nplot!(1:1000, trajectory4)\nplot!(1:1000, trajectory5)"
  },
  {
    "objectID": "solutions/vl.html#different-learning-rates",
    "href": "solutions/vl.html#different-learning-rates",
    "title": "Variational learning",
    "section": "2. Different learning rates",
    "text": "2. Different learning rates\n\n# create learning environment\nlondon = LearningEnvironment(0.4, 0.5, 0.1)\n\n# create 5 learners\ngamma = 0.001\nlearner1 = VariationalLearner(0.5, gamma)\nlearner2 = VariationalLearner(0.5, gamma)\nlearner3 = VariationalLearner(0.5, gamma)\nlearner4 = VariationalLearner(0.5, gamma)\nlearner5 = VariationalLearner(0.5, gamma)\n\n# simulate each learner for 1000 steps\ntrajectory1 = [learn!(learner1, london) for t in 1:1000]\ntrajectory2 = [learn!(learner2, london) for t in 1:1000]\ntrajectory3 = [learn!(learner3, london) for t in 1:1000]\ntrajectory4 = [learn!(learner4, london) for t in 1:1000]\ntrajectory5 = [learn!(learner5, london) for t in 1:1000]\n\n# plot\nplot(1:1000, trajectory1)\nplot!(1:1000, trajectory2)\nplot!(1:1000, trajectory3)\nplot!(1:1000, trajectory4)\nplot!(1:1000, trajectory5)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# create learning environment\nlondon = LearningEnvironment(0.4, 0.5, 0.1)\n\n# create 5 learners\ngamma = 1.0\nlearner1 = VariationalLearner(0.5, gamma)\nlearner2 = VariationalLearner(0.5, gamma)\nlearner3 = VariationalLearner(0.5, gamma)\nlearner4 = VariationalLearner(0.5, gamma)\nlearner5 = VariationalLearner(0.5, gamma)\n\n# simulate each learner for 1000 steps\ntrajectory1 = [learn!(learner1, london) for t in 1:1000]\ntrajectory2 = [learn!(learner2, london) for t in 1:1000]\ntrajectory3 = [learn!(learner3, london) for t in 1:1000]\ntrajectory4 = [learn!(learner4, london) for t in 1:1000]\ntrajectory5 = [learn!(learner5, london) for t in 1:1000]\n\n# plot\nplot(1:1000, trajectory1)\nplot!(1:1000, trajectory2)\nplot!(1:1000, trajectory3)\nplot!(1:1000, trajectory4)\nplot!(1:1000, trajectory5)"
  },
  {
    "objectID": "solutions/vl.html#varying-the-environment",
    "href": "solutions/vl.html#varying-the-environment",
    "title": "Variational learning",
    "section": "3. Varying the environment",
    "text": "3. Varying the environment\nHere I’m only doing this with the value of the learning rate \\(\\gamma = 0.01\\); the principle will be exactly the same for any other value.\n\n# create learning environment\nprague = LearningEnvironment(0.1, 0.5, 0.4)\n\n# create 5 learners\ngamma = 0.01\nlearner1 = VariationalLearner(0.5, gamma)\nlearner2 = VariationalLearner(0.5, gamma)\nlearner3 = VariationalLearner(0.5, gamma)\nlearner4 = VariationalLearner(0.5, gamma)\nlearner5 = VariationalLearner(0.5, gamma)\n\n# simulate each learner for 1000 steps\ntrajectory1 = [learn!(learner1, prague) for t in 1:1000]\ntrajectory2 = [learn!(learner2, prague) for t in 1:1000]\ntrajectory3 = [learn!(learner3, prague) for t in 1:1000]\ntrajectory4 = [learn!(learner4, prague) for t in 1:1000]\ntrajectory5 = [learn!(learner5, prague) for t in 1:1000]\n\n# plot\nplot(1:1000, trajectory1)\nplot!(1:1000, trajectory2)\nplot!(1:1000, trajectory3)\nplot!(1:1000, trajectory4)\nplot!(1:1000, trajectory5)"
  },
  {
    "objectID": "solutions/vl.html#what-does-this-mean",
    "href": "solutions/vl.html#what-does-this-mean",
    "title": "Variational learning",
    "section": "4. What does this mean?",
    "text": "4. What does this mean?\nThe effect of the learning rate parameter \\(\\gamma\\) (gamma) is quite straightforward: the smaller the value of this parameter, the slower learning is. In the extreme case \\(\\gamma = 1\\), learning is in a sense as “fast” as it can possibly be: each learner switches between probability 1 of using \\(G_1\\) and probability 0 of using \\(G_1\\) at parsing failure.\nThe effect of the the probabilities P1, P12 and P2 of the learning environment is a bit less straightforward. In fact, a formula exists that allows one to predict the expected value of \\(p\\) (probability of using \\(G_1\\)) a variational learner ends up with after a long period of learning, and that formula only depends on the environment’s probability parameters. We might look at this in detail later. For now, suffice it to say that the parameters have some such effect. More precisely, in the above simulations we see that\n\nWhen P1 = 0.4 and P2 = 0.1 (environment london), the learners end up with \\(p \\approx 0.8\\).\nWhen P1 = 0.1 and P2 = 0.4 (environment prague), the learners end up with \\(p \\approx 0.2\\)."
  },
  {
    "objectID": "solutions/vl.html#prettifying-the-plots",
    "href": "solutions/vl.html#prettifying-the-plots",
    "title": "Variational learning",
    "section": "5. Prettifying the plots",
    "text": "5. Prettifying the plots\n\n# create learning environment\nprague = LearningEnvironment(0.1, 0.5, 0.4)\n\n# create 5 learners\ngamma = 0.01\nlearner1 = VariationalLearner(0.5, gamma)\nlearner2 = VariationalLearner(0.5, gamma)\nlearner3 = VariationalLearner(0.5, gamma)\nlearner4 = VariationalLearner(0.5, gamma)\nlearner5 = VariationalLearner(0.5, gamma)\n\n# simulate each learner for 1000 steps\ntrajectory1 = [learn!(learner1, prague) for t in 1:1000]\ntrajectory2 = [learn!(learner2, prague) for t in 1:1000]\ntrajectory3 = [learn!(learner3, prague) for t in 1:1000]\ntrajectory4 = [learn!(learner4, prague) for t in 1:1000]\ntrajectory5 = [learn!(learner5, prague) for t in 1:1000]\n\n# plot\nplot(1:1000, trajectory1, seriestype=:scatter)\nplot!(1:1000, trajectory2, seriestype=:scatter)\nplot!(1:1000, trajectory3, seriestype=:scatter)\nplot!(1:1000, trajectory4, seriestype=:scatter)\nplot!(1:1000, trajectory5, seriestype=:scatter)\nxlabel!(\"learning iteration\")\nylabel!(\"probability of G1\")\ntitle!(\"A variational learning trajectory\")"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Rules for projects:\n\nYour team must consist of at least 1 person and at most 2 persons.\nYour project needs to\n\nformulate a question to explore with an ABM\nimplement that ABM in Julia\nillustrate the results (using plots, animations, numbers…)\n\nYour project presentation cannot be longer than 15 minutes\nYour team must meet with me at least once before the course is over (to discuss how the project is coming along, and to see if you have any questions I might be able to answer). This can be either before or after your presentation.\n\nRemarks:\n\nYour project does not have to be complete when it is presented! You are welcome to present work in progress, and also to ask your peers for feedback and suggestions. The final written reports, on the other hand, must represent completed work.\nLook for inspiration by skimming the papers collected in the readings/projects folder on ILIAS.\nAlso look for inspiration on the Agents.jl website.\nYour project can also focus on attempting to replicate the analysis from one of these papers.\nYour research question does not need to be about linguistics!\n\n\n\n\n© 2024 Henri Kauhanen. Reproduction of these materials without written permission from the author is prohibited."
  }
]